{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load simple_convnet.py\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"简单的ConvNet\n",
    "\n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 输入大小（MNIST的情况下为784）\n",
    "    hidden_size_list : 隐藏层的神经元数量的列表（e.g. [100, 100, 100]）\n",
    "    output_size : 输出大小（MNIST的情况下为10）\n",
    "    activation : 'relu' or 'sigmoid'\n",
    "    weight_init_std : 指定权重的标准差（e.g. 0.01）\n",
    "        指定'relu'或'he'的情况下设定“He的初始值”\n",
    "        指定'sigmoid'或'xavier'的情况下设定“Xavier的初始值”\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 初始化权重\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 生成层\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "     #进行识别\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"求损失函数\n",
    "        参数x是输入数据、t是教师标签\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"求各个参数相较于损失函数梯度（数值微分）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 输入数据\n",
    "        t : 教师标签\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        具有各层的梯度的字典变量\n",
    "            grads['W1']、grads['W2']、...是各层的权重的梯度\n",
    "            grads['b1']、grads['b2']、...是各层的偏置的梯度\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"求梯度（误差反向传播法）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 输入数据\n",
    "        t : 教师标签\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        具有各层的梯度的字典变量\n",
    "            grads['W1']、grads['W2']、...是各层的权重的梯度\n",
    "            grads['b1']、grads['b2']、...是各层的偏置的梯度\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 设定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "    \n",
    "       #将程序运行中的对象保存为文件 \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.29973546395\n",
      "=== epoch:1, train acc:0.238, test acc:0.258 ===\n",
      "train loss:2.29821803452\n",
      "train loss:2.29354970511\n",
      "train loss:2.2874567495\n",
      "train loss:2.28182253053\n",
      "train loss:2.26360610298\n",
      "train loss:2.25266817887\n",
      "train loss:2.2421719743\n",
      "train loss:2.2218394938\n",
      "train loss:2.20165269682\n",
      "train loss:2.15958988042\n",
      "train loss:2.12098115631\n",
      "train loss:2.07081824545\n",
      "train loss:2.00797757294\n",
      "train loss:1.95463208133\n",
      "train loss:1.90412990723\n",
      "train loss:1.89689630515\n",
      "train loss:1.83434518498\n",
      "train loss:1.75652624067\n",
      "train loss:1.65839254275\n",
      "train loss:1.51302945668\n",
      "train loss:1.48376207044\n",
      "train loss:1.38726366743\n",
      "train loss:1.30764258525\n",
      "train loss:1.39473648888\n",
      "train loss:1.12594176921\n",
      "train loss:1.20995102427\n",
      "train loss:1.12544675194\n",
      "train loss:1.01559139255\n",
      "train loss:1.03688909699\n",
      "train loss:0.91524209135\n",
      "train loss:0.763939559343\n",
      "train loss:0.69667971385\n",
      "train loss:0.932371011664\n",
      "train loss:0.81206786943\n",
      "train loss:0.556825714679\n",
      "train loss:0.656653143606\n",
      "train loss:0.777361375951\n",
      "train loss:0.784910117018\n",
      "train loss:0.805381075907\n",
      "train loss:0.585971802854\n",
      "train loss:0.838328429104\n",
      "train loss:0.669915733232\n",
      "train loss:0.536521928913\n",
      "train loss:0.564442160558\n",
      "train loss:0.734185162333\n",
      "train loss:0.602102682274\n",
      "train loss:0.616032545826\n",
      "train loss:0.531704770591\n",
      "train loss:0.599826261954\n",
      "train loss:0.761986104385\n",
      "train loss:0.507985746637\n",
      "train loss:0.553166991872\n",
      "train loss:0.507626144521\n",
      "train loss:0.495429785585\n",
      "train loss:0.772053238515\n",
      "train loss:0.571064581121\n",
      "train loss:0.671558135355\n",
      "train loss:0.569600990107\n",
      "train loss:0.524394641282\n",
      "train loss:0.717176345869\n",
      "train loss:0.577085510533\n",
      "train loss:0.471476548821\n",
      "train loss:0.464038356743\n",
      "train loss:0.472592362576\n",
      "train loss:0.522056893148\n",
      "train loss:0.492835851384\n",
      "train loss:0.675120497683\n",
      "train loss:0.48730021967\n",
      "train loss:0.541542456403\n",
      "train loss:0.450703182136\n",
      "train loss:0.453493089327\n",
      "train loss:0.541082600903\n",
      "train loss:0.567731156927\n",
      "train loss:0.490770949519\n",
      "train loss:0.391223023211\n",
      "train loss:0.347753862521\n",
      "train loss:0.345502338171\n",
      "train loss:0.458104925753\n",
      "train loss:0.535612298216\n",
      "train loss:0.551654101902\n",
      "train loss:0.408948625564\n",
      "train loss:0.499052683569\n",
      "train loss:0.311824319497\n",
      "train loss:0.300865464504\n",
      "train loss:0.441156259125\n",
      "train loss:0.418238566268\n",
      "train loss:0.437190241683\n",
      "train loss:0.423705009669\n",
      "train loss:0.536965775126\n",
      "train loss:0.48148536157\n",
      "train loss:0.542822303976\n",
      "train loss:0.34570098111\n",
      "train loss:0.422244688084\n",
      "train loss:0.345988519463\n",
      "train loss:0.315563519157\n",
      "train loss:0.490566858345\n",
      "train loss:0.420311812308\n",
      "train loss:0.416809703276\n",
      "train loss:0.500313712956\n",
      "train loss:0.376632309432\n",
      "train loss:0.581654493315\n",
      "train loss:0.356145344456\n",
      "train loss:0.512322835482\n",
      "train loss:0.34763611226\n",
      "train loss:0.46612978206\n",
      "train loss:0.509410766685\n",
      "train loss:0.262936806101\n",
      "train loss:0.347728613428\n",
      "train loss:0.426290819719\n",
      "train loss:0.460935391153\n",
      "train loss:0.302327520147\n",
      "train loss:0.247170038168\n",
      "train loss:0.442749923319\n",
      "train loss:0.426561065349\n",
      "train loss:0.251279491961\n",
      "train loss:0.241834966612\n",
      "train loss:0.475120413103\n",
      "train loss:0.339761233485\n",
      "train loss:0.447526978015\n",
      "train loss:0.483229392977\n",
      "train loss:0.191964381588\n",
      "train loss:0.259844035324\n",
      "train loss:0.364774502493\n",
      "train loss:0.401607297943\n",
      "train loss:0.320013798911\n",
      "train loss:0.38920147615\n",
      "train loss:0.462659768532\n",
      "train loss:0.295560320339\n",
      "train loss:0.378731494559\n",
      "train loss:0.348968033516\n",
      "train loss:0.313295556258\n",
      "train loss:0.449305433672\n",
      "train loss:0.231695467397\n",
      "train loss:0.394523471408\n",
      "train loss:0.396783806701\n",
      "train loss:0.343249091004\n",
      "train loss:0.319977137146\n",
      "train loss:0.355165646866\n",
      "train loss:0.390730907857\n",
      "train loss:0.301660049802\n",
      "train loss:0.325219541079\n",
      "train loss:0.374942059318\n",
      "train loss:0.375037558288\n",
      "train loss:0.434752805786\n",
      "train loss:0.321148980794\n",
      "train loss:0.255437859645\n",
      "train loss:0.296436027346\n",
      "train loss:0.327973557479\n",
      "train loss:0.326302993616\n",
      "train loss:0.241729975046\n",
      "train loss:0.326358530754\n",
      "train loss:0.291269227551\n",
      "train loss:0.297272797607\n",
      "train loss:0.213639481655\n",
      "train loss:0.255965738857\n",
      "train loss:0.421707916828\n",
      "train loss:0.228094735557\n",
      "train loss:0.311101524695\n",
      "train loss:0.399920238282\n",
      "train loss:0.350012612331\n",
      "train loss:0.508630846113\n",
      "train loss:0.336176288196\n",
      "train loss:0.500428867517\n",
      "train loss:0.384325152618\n",
      "train loss:0.538790400658\n",
      "train loss:0.26833958658\n",
      "train loss:0.196178223969\n",
      "train loss:0.376535207199\n",
      "train loss:0.276573409966\n",
      "train loss:0.241401733555\n",
      "train loss:0.168554478605\n",
      "train loss:0.275580630376\n",
      "train loss:0.375357710223\n",
      "train loss:0.375725840969\n",
      "train loss:0.303318083677\n",
      "train loss:0.579051599495\n",
      "train loss:0.346743980709\n",
      "train loss:0.308592502242\n",
      "train loss:0.255008645807\n",
      "train loss:0.684137801575\n",
      "train loss:0.329110091144\n",
      "train loss:0.425175100407\n",
      "train loss:0.278927028754\n",
      "train loss:0.354081553074\n",
      "train loss:0.272161094024\n",
      "train loss:0.25482626228\n",
      "train loss:0.4209252531\n",
      "train loss:0.302453211063\n",
      "train loss:0.235996264045\n",
      "train loss:0.26112469151\n",
      "train loss:0.473863830107\n",
      "train loss:0.375715535228\n",
      "train loss:0.273464675802\n",
      "train loss:0.359418040555\n",
      "train loss:0.387938103648\n",
      "train loss:0.400381543317\n",
      "train loss:0.145729253854\n",
      "train loss:0.355889800229\n",
      "train loss:0.313200122764\n",
      "train loss:0.240132548841\n",
      "train loss:0.212096650972\n",
      "train loss:0.33465391958\n",
      "train loss:0.190614038623\n",
      "train loss:0.296304297087\n",
      "train loss:0.231920603269\n",
      "train loss:0.328040001275\n",
      "train loss:0.241956884955\n",
      "train loss:0.224376805619\n",
      "train loss:0.538401053997\n",
      "train loss:0.375535909002\n",
      "train loss:0.30844742175\n",
      "train loss:0.187116470591\n",
      "train loss:0.31807822868\n",
      "train loss:0.441214966841\n",
      "train loss:0.230401944123\n",
      "train loss:0.325808221339\n",
      "train loss:0.404591195592\n",
      "train loss:0.322493183616\n",
      "train loss:0.340157636689\n",
      "train loss:0.432168448721\n",
      "train loss:0.152726311099\n",
      "train loss:0.25555679597\n",
      "train loss:0.259586812718\n",
      "train loss:0.291378726071\n",
      "train loss:0.163064884041\n",
      "train loss:0.195729060342\n",
      "train loss:0.252470142016\n",
      "train loss:0.429064372325\n",
      "train loss:0.308659327942\n",
      "train loss:0.449615559373\n",
      "train loss:0.158852885138\n",
      "train loss:0.325037238588\n",
      "train loss:0.168962657806\n",
      "train loss:0.213966784294\n",
      "train loss:0.269973072338\n",
      "train loss:0.269477669608\n",
      "train loss:0.320794633564\n",
      "train loss:0.20225492881\n",
      "train loss:0.352942287674\n",
      "train loss:0.256771430514\n",
      "train loss:0.217670939156\n",
      "train loss:0.234473824157\n",
      "train loss:0.20966911319\n",
      "train loss:0.194893635075\n",
      "train loss:0.215312745462\n",
      "train loss:0.154119451677\n",
      "train loss:0.249233532103\n",
      "train loss:0.177333919359\n",
      "train loss:0.310393365732\n",
      "train loss:0.216915425652\n",
      "train loss:0.158027162727\n",
      "train loss:0.335704036015\n",
      "train loss:0.231087653339\n",
      "train loss:0.21237758195\n",
      "train loss:0.182842925288\n",
      "train loss:0.229233946168\n",
      "train loss:0.300106608788\n",
      "train loss:0.204697877395\n",
      "train loss:0.312690299912\n",
      "train loss:0.280886011142\n",
      "train loss:0.167174691739\n",
      "train loss:0.219096718741\n",
      "train loss:0.345049805268\n",
      "train loss:0.290099390547\n",
      "train loss:0.276728297023\n",
      "train loss:0.397275247403\n",
      "train loss:0.185496185334\n",
      "train loss:0.331224735559\n",
      "train loss:0.258851124539\n",
      "train loss:0.272683096248\n",
      "train loss:0.237446650113\n",
      "train loss:0.208321076586\n",
      "train loss:0.263192587398\n",
      "train loss:0.188439260421\n",
      "train loss:0.268147048081\n",
      "train loss:0.242360503065\n",
      "train loss:0.237948833174\n",
      "train loss:0.226986756377\n",
      "train loss:0.125132642026\n",
      "train loss:0.161167932803\n",
      "train loss:0.224437536704\n",
      "train loss:0.175190022852\n",
      "train loss:0.130503401358\n",
      "train loss:0.166547893969\n",
      "train loss:0.286074001411\n",
      "train loss:0.168253268283\n",
      "train loss:0.12048503737\n",
      "train loss:0.425098743135\n",
      "train loss:0.420684144862\n",
      "train loss:0.222354379665\n",
      "train loss:0.301340928287\n",
      "train loss:0.300702812547\n",
      "train loss:0.257515638112\n",
      "train loss:0.279568671409\n",
      "train loss:0.192009557806\n",
      "train loss:0.15955666043\n",
      "train loss:0.288603591685\n",
      "train loss:0.241340157479\n",
      "train loss:0.256553312304\n",
      "train loss:0.165389981171\n",
      "train loss:0.352263265269\n",
      "train loss:0.235340605575\n",
      "train loss:0.263807401675\n",
      "train loss:0.215542707552\n",
      "train loss:0.294126411741\n",
      "train loss:0.329558950226\n",
      "train loss:0.233300822223\n",
      "train loss:0.264802037591\n",
      "train loss:0.111808290572\n",
      "train loss:0.154116723961\n",
      "train loss:0.152328978209\n",
      "train loss:0.203002904141\n",
      "train loss:0.200763684742\n",
      "train loss:0.224839490201\n",
      "train loss:0.124852095142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.208402933329\n",
      "train loss:0.190472282753\n",
      "train loss:0.193574236612\n",
      "train loss:0.256212008337\n",
      "train loss:0.190495472253\n",
      "train loss:0.265529999018\n",
      "train loss:0.285806945647\n",
      "train loss:0.179191514524\n",
      "train loss:0.306628555097\n",
      "train loss:0.269191360603\n",
      "train loss:0.333689088871\n",
      "train loss:0.266399687119\n",
      "train loss:0.250609322099\n",
      "train loss:0.174269890696\n",
      "train loss:0.234112260935\n",
      "train loss:0.194849146198\n",
      "train loss:0.169603167275\n",
      "train loss:0.228406084017\n",
      "train loss:0.21748189662\n",
      "train loss:0.209082877797\n",
      "train loss:0.269623207971\n",
      "train loss:0.104694929782\n",
      "train loss:0.262725667711\n",
      "train loss:0.206061680129\n",
      "train loss:0.135679972483\n",
      "train loss:0.180168045708\n",
      "train loss:0.173150516533\n",
      "train loss:0.132481273529\n",
      "train loss:0.279467578318\n",
      "train loss:0.211628515523\n",
      "train loss:0.237256370794\n",
      "train loss:0.144790729881\n",
      "train loss:0.129928004652\n",
      "train loss:0.102893951664\n",
      "train loss:0.16135336358\n",
      "train loss:0.234071081335\n",
      "train loss:0.277171198116\n",
      "train loss:0.224328075783\n",
      "train loss:0.301521886815\n",
      "train loss:0.188876588625\n",
      "train loss:0.183880293601\n",
      "train loss:0.20985087019\n",
      "train loss:0.168686932035\n",
      "train loss:0.262432538404\n",
      "train loss:0.154551750081\n",
      "train loss:0.101871806062\n",
      "train loss:0.157885235449\n",
      "train loss:0.0903992998267\n",
      "train loss:0.139232586665\n",
      "train loss:0.170357295954\n",
      "train loss:0.104406271215\n",
      "train loss:0.206752236978\n",
      "train loss:0.0949535349066\n",
      "train loss:0.128708225704\n",
      "train loss:0.29733164557\n",
      "train loss:0.202184922251\n",
      "train loss:0.156547642204\n",
      "train loss:0.153429300749\n",
      "train loss:0.19401749506\n",
      "train loss:0.158664974315\n",
      "train loss:0.189376787869\n",
      "train loss:0.176183936171\n",
      "train loss:0.102308619363\n",
      "train loss:0.116274618896\n",
      "train loss:0.147201308143\n",
      "train loss:0.260310108944\n",
      "train loss:0.166289299904\n",
      "train loss:0.303679674323\n",
      "train loss:0.162162761695\n",
      "train loss:0.143959833002\n",
      "train loss:0.217982635093\n",
      "train loss:0.207449559576\n",
      "train loss:0.203239424586\n",
      "train loss:0.10680966608\n",
      "train loss:0.20172627869\n",
      "train loss:0.271259963722\n",
      "train loss:0.199121407042\n",
      "train loss:0.320356683402\n",
      "train loss:0.126301946485\n",
      "train loss:0.24726121457\n",
      "train loss:0.478703027145\n",
      "train loss:0.316860084051\n",
      "train loss:0.146794972898\n",
      "train loss:0.159838554595\n",
      "train loss:0.165629688597\n",
      "train loss:0.203037346128\n",
      "train loss:0.173933257878\n",
      "train loss:0.150065091534\n",
      "train loss:0.122013160276\n",
      "train loss:0.27013710384\n",
      "train loss:0.196671672301\n",
      "train loss:0.0949620517817\n",
      "train loss:0.127498021847\n",
      "train loss:0.165628142846\n",
      "train loss:0.119151927473\n",
      "train loss:0.149309279338\n",
      "train loss:0.182846410873\n",
      "train loss:0.19474445106\n",
      "train loss:0.14678025899\n",
      "train loss:0.123432944873\n",
      "train loss:0.187605334921\n",
      "train loss:0.20403047729\n",
      "train loss:0.138496658274\n",
      "train loss:0.0818200757444\n",
      "train loss:0.114000384885\n",
      "train loss:0.160120579924\n",
      "train loss:0.139108073052\n",
      "train loss:0.197300417695\n",
      "train loss:0.204353122373\n",
      "train loss:0.158635274029\n",
      "train loss:0.12195241465\n",
      "train loss:0.194286199723\n",
      "train loss:0.234657875319\n",
      "train loss:0.229651031053\n",
      "train loss:0.152109546458\n",
      "train loss:0.132840944072\n",
      "train loss:0.168479310217\n",
      "train loss:0.120807346859\n",
      "train loss:0.13755314341\n",
      "train loss:0.123210033836\n",
      "train loss:0.133090505442\n",
      "train loss:0.198832802285\n",
      "train loss:0.243072080819\n",
      "train loss:0.175019201599\n",
      "train loss:0.0642434364358\n",
      "train loss:0.145215647245\n",
      "train loss:0.267042953882\n",
      "train loss:0.226135473968\n",
      "train loss:0.226119612255\n",
      "train loss:0.138766257132\n",
      "train loss:0.167623681567\n",
      "train loss:0.295670486056\n",
      "train loss:0.128865887407\n",
      "train loss:0.136202406049\n",
      "train loss:0.177352869914\n",
      "train loss:0.207891434387\n",
      "train loss:0.155021133195\n",
      "train loss:0.109564154751\n",
      "train loss:0.13998261486\n",
      "train loss:0.10216763463\n",
      "train loss:0.227075797604\n",
      "train loss:0.165697838751\n",
      "train loss:0.163352524816\n",
      "train loss:0.0693102800592\n",
      "train loss:0.1188044395\n",
      "train loss:0.168988194311\n",
      "train loss:0.210324964198\n",
      "train loss:0.12607483299\n",
      "train loss:0.154322943556\n",
      "train loss:0.112032040159\n",
      "train loss:0.147774140103\n",
      "train loss:0.125700343571\n",
      "train loss:0.153364375371\n",
      "train loss:0.0776442200935\n",
      "train loss:0.09993552898\n",
      "train loss:0.149597642581\n",
      "train loss:0.158268807555\n",
      "train loss:0.199481162787\n",
      "train loss:0.0710704378182\n",
      "train loss:0.177802091061\n",
      "train loss:0.180323231679\n",
      "train loss:0.12068161374\n",
      "train loss:0.0875835588331\n",
      "train loss:0.162755022768\n",
      "train loss:0.213648884837\n",
      "train loss:0.283914479645\n",
      "train loss:0.0842086802625\n",
      "train loss:0.111890031543\n",
      "train loss:0.127951617385\n",
      "train loss:0.152729193335\n",
      "train loss:0.147438187641\n",
      "train loss:0.208801375206\n",
      "train loss:0.155508655712\n",
      "train loss:0.0868628564353\n",
      "train loss:0.102544716992\n",
      "train loss:0.121663002201\n",
      "train loss:0.0889982339948\n",
      "train loss:0.193813921724\n",
      "train loss:0.142939608408\n",
      "train loss:0.0613748901616\n",
      "train loss:0.175836382823\n",
      "train loss:0.206304823798\n",
      "train loss:0.143345962592\n",
      "train loss:0.190633027584\n",
      "train loss:0.101448872276\n",
      "train loss:0.102863518397\n",
      "train loss:0.124737696176\n",
      "train loss:0.23116752747\n",
      "train loss:0.311857980185\n",
      "train loss:0.314697412214\n",
      "train loss:0.166857115106\n",
      "train loss:0.164635132333\n",
      "train loss:0.150562173675\n",
      "train loss:0.127575137309\n",
      "train loss:0.216298717437\n",
      "train loss:0.0971624927091\n",
      "train loss:0.109669067907\n",
      "train loss:0.176598070885\n",
      "train loss:0.0954477299246\n",
      "train loss:0.310424004959\n",
      "train loss:0.153595507568\n",
      "train loss:0.326793346052\n",
      "train loss:0.113346333403\n",
      "train loss:0.162511752627\n",
      "train loss:0.122967295396\n",
      "train loss:0.139316938279\n",
      "train loss:0.125477561448\n",
      "train loss:0.133121691973\n",
      "train loss:0.101369893586\n",
      "train loss:0.273140141012\n",
      "train loss:0.175170551321\n",
      "train loss:0.203404857239\n",
      "train loss:0.18579682675\n",
      "train loss:0.219288475408\n",
      "train loss:0.104300826703\n",
      "train loss:0.113160849922\n",
      "train loss:0.172121237661\n",
      "train loss:0.188176924542\n",
      "train loss:0.125339588717\n",
      "train loss:0.115956825695\n",
      "train loss:0.101218166094\n",
      "train loss:0.118639435806\n",
      "train loss:0.174102183167\n",
      "train loss:0.16413590447\n",
      "train loss:0.17050929555\n",
      "train loss:0.173758076067\n",
      "train loss:0.14512696434\n",
      "train loss:0.242853858452\n",
      "train loss:0.132598325465\n",
      "train loss:0.107862170022\n",
      "train loss:0.0882074525997\n",
      "train loss:0.149842527636\n",
      "train loss:0.134462738876\n",
      "train loss:0.116199331294\n",
      "train loss:0.24402369113\n",
      "train loss:0.117051649648\n",
      "train loss:0.139245754276\n",
      "train loss:0.113865957788\n",
      "train loss:0.0924329289433\n",
      "train loss:0.116344943657\n",
      "train loss:0.0880618959614\n",
      "train loss:0.191397716969\n",
      "train loss:0.148921876542\n",
      "train loss:0.115458626441\n",
      "train loss:0.093500162962\n",
      "train loss:0.101559120136\n",
      "train loss:0.219636987499\n",
      "train loss:0.227188634355\n",
      "train loss:0.128910961099\n",
      "train loss:0.14994297664\n",
      "train loss:0.123850073175\n",
      "train loss:0.0879765991943\n",
      "train loss:0.186948077666\n",
      "train loss:0.172805230549\n",
      "train loss:0.162718143346\n",
      "train loss:0.158125766831\n",
      "train loss:0.146014796742\n",
      "train loss:0.162733421404\n",
      "train loss:0.1709765751\n",
      "train loss:0.140877703376\n",
      "train loss:0.152822442025\n",
      "train loss:0.14776689515\n",
      "train loss:0.176531122102\n",
      "train loss:0.10827278249\n",
      "train loss:0.13449563592\n",
      "train loss:0.12560114123\n",
      "train loss:0.0767544505501\n",
      "train loss:0.130870884936\n",
      "train loss:0.0888871153105\n",
      "train loss:0.166640579641\n",
      "train loss:0.146137508655\n",
      "train loss:0.123423749135\n",
      "train loss:0.144724892616\n",
      "train loss:0.0804094513459\n",
      "train loss:0.240742802179\n",
      "train loss:0.0938263677112\n",
      "train loss:0.182086864115\n",
      "train loss:0.172699890001\n",
      "train loss:0.0918631982737\n",
      "train loss:0.189697844541\n",
      "train loss:0.172373903813\n",
      "train loss:0.0657612291818\n",
      "train loss:0.104440977066\n",
      "train loss:0.251606156143\n",
      "train loss:0.176547024485\n",
      "=== epoch:2, train acc:0.959, test acc:0.961 ===\n",
      "train loss:0.143820839397\n",
      "train loss:0.210621108687\n",
      "train loss:0.143115275012\n",
      "train loss:0.132704594958\n",
      "train loss:0.0744805073822\n",
      "train loss:0.154794365704\n",
      "train loss:0.186915646477\n",
      "train loss:0.12588501986\n",
      "train loss:0.150310030871\n",
      "train loss:0.0768632906404\n",
      "train loss:0.168669131774\n",
      "train loss:0.0548595981596\n",
      "train loss:0.161006061212\n",
      "train loss:0.19545597771\n",
      "train loss:0.0573288711514\n",
      "train loss:0.044492893214\n",
      "train loss:0.139592039701\n",
      "train loss:0.151530426258\n",
      "train loss:0.180059072943\n",
      "train loss:0.21151355948\n",
      "train loss:0.108904417467\n",
      "train loss:0.0759413574091\n",
      "train loss:0.219659054979\n",
      "train loss:0.0750749991887\n",
      "train loss:0.0912154157222\n",
      "train loss:0.191672094552\n",
      "train loss:0.0738944338363\n",
      "train loss:0.151789278472\n",
      "train loss:0.207640317658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.164603087548\n",
      "train loss:0.0790832165611\n",
      "train loss:0.104689381081\n",
      "train loss:0.063031859832\n",
      "train loss:0.170751228949\n",
      "train loss:0.0536158225606\n",
      "train loss:0.196784096313\n",
      "train loss:0.194266371198\n",
      "train loss:0.146648449356\n",
      "train loss:0.120068466695\n",
      "train loss:0.129519507218\n",
      "train loss:0.102100676668\n",
      "train loss:0.0767102904201\n",
      "train loss:0.158662687043\n",
      "train loss:0.14592312815\n",
      "train loss:0.135058511445\n",
      "train loss:0.144691837249\n",
      "train loss:0.130152546337\n",
      "train loss:0.131133200704\n",
      "train loss:0.205688925509\n",
      "train loss:0.0520124497502\n",
      "train loss:0.069852572209\n",
      "train loss:0.123045857811\n",
      "train loss:0.129526403601\n",
      "train loss:0.0957267127999\n",
      "train loss:0.0905360772105\n",
      "train loss:0.0910777218286\n",
      "train loss:0.133195608053\n",
      "train loss:0.0603762623957\n",
      "train loss:0.106913409553\n",
      "train loss:0.218340158303\n",
      "train loss:0.108954926598\n",
      "train loss:0.127511762049\n",
      "train loss:0.061217798081\n",
      "train loss:0.11230536638\n",
      "train loss:0.0941894795494\n",
      "train loss:0.16333950276\n",
      "train loss:0.0737695173071\n",
      "train loss:0.153590730792\n",
      "train loss:0.163115910689\n",
      "train loss:0.211884580191\n",
      "train loss:0.0967829329699\n",
      "train loss:0.271680699022\n",
      "train loss:0.131092186847\n",
      "train loss:0.0424064307114\n",
      "train loss:0.140319200933\n",
      "train loss:0.0928463995501\n",
      "train loss:0.0525527147989\n",
      "train loss:0.109678377489\n",
      "train loss:0.0995343397817\n",
      "train loss:0.0749728957625\n",
      "train loss:0.0937077877077\n",
      "train loss:0.200798115015\n",
      "train loss:0.0928117580434\n",
      "train loss:0.092119581863\n",
      "train loss:0.0792255955334\n",
      "train loss:0.0614903036564\n",
      "train loss:0.17513310498\n",
      "train loss:0.189705028314\n",
      "train loss:0.091303314218\n",
      "train loss:0.0848273703081\n",
      "train loss:0.0754860918439\n",
      "train loss:0.0741288322946\n",
      "train loss:0.0761612523309\n",
      "train loss:0.0914753391753\n",
      "train loss:0.0725751982021\n",
      "train loss:0.109705149654\n",
      "train loss:0.0871235492914\n",
      "train loss:0.115053779747\n",
      "train loss:0.0709157584417\n",
      "train loss:0.0992091783667\n",
      "train loss:0.0695698782385\n",
      "train loss:0.199743702565\n",
      "train loss:0.146087270057\n",
      "train loss:0.0911157582809\n",
      "train loss:0.0683041616751\n",
      "train loss:0.0736651673098\n",
      "train loss:0.0884905625423\n",
      "train loss:0.138931810055\n",
      "train loss:0.141730143421\n",
      "train loss:0.0772701363787\n",
      "train loss:0.109806835808\n",
      "train loss:0.168695580475\n",
      "train loss:0.0622799346394\n",
      "train loss:0.146180463918\n",
      "train loss:0.0659690877153\n",
      "train loss:0.111369567533\n",
      "train loss:0.110766723003\n",
      "train loss:0.135314753634\n",
      "train loss:0.211577167767\n",
      "train loss:0.0409135128143\n",
      "train loss:0.0966243634942\n",
      "train loss:0.0809551204392\n",
      "train loss:0.104282269041\n",
      "train loss:0.0812084842155\n",
      "train loss:0.108201258401\n",
      "train loss:0.0406592458006\n",
      "train loss:0.0872407511122\n",
      "train loss:0.125376922088\n",
      "train loss:0.176652252146\n",
      "train loss:0.0764921340351\n",
      "train loss:0.14296971844\n",
      "train loss:0.0634518555951\n",
      "train loss:0.159502881615\n",
      "train loss:0.0899001853009\n",
      "train loss:0.155524956651\n",
      "train loss:0.180853868347\n",
      "train loss:0.180352113748\n",
      "train loss:0.0890745178096\n",
      "train loss:0.137958593883\n",
      "train loss:0.106448239147\n",
      "train loss:0.0899749870415\n",
      "train loss:0.0529273381873\n",
      "train loss:0.10183175397\n",
      "train loss:0.0465029702712\n",
      "train loss:0.120333592481\n",
      "train loss:0.176168869318\n",
      "train loss:0.114779722899\n",
      "train loss:0.0669973011833\n",
      "train loss:0.0986659528325\n",
      "train loss:0.181644024124\n",
      "train loss:0.0666684594468\n",
      "train loss:0.0826964443899\n",
      "train loss:0.118843040737\n",
      "train loss:0.121407872398\n",
      "train loss:0.035809795654\n",
      "train loss:0.0872961666747\n",
      "train loss:0.215999760912\n",
      "train loss:0.0275926193469\n",
      "train loss:0.0974116797623\n",
      "train loss:0.114543402239\n",
      "train loss:0.0328658832296\n",
      "train loss:0.0789863474509\n",
      "train loss:0.070461694455\n",
      "train loss:0.114906446377\n",
      "train loss:0.0563620408933\n",
      "train loss:0.0663932206229\n",
      "train loss:0.0831121827307\n",
      "train loss:0.0452540589048\n",
      "train loss:0.0491020392245\n",
      "train loss:0.0774674846132\n",
      "train loss:0.0770468436287\n",
      "train loss:0.179328970907\n",
      "train loss:0.0764142123682\n",
      "train loss:0.130437399106\n",
      "train loss:0.0766959185767\n",
      "train loss:0.0670529072322\n",
      "train loss:0.0923520744733\n",
      "train loss:0.0674257047919\n",
      "train loss:0.110879032941\n",
      "train loss:0.0497799633072\n",
      "train loss:0.0769519939858\n",
      "train loss:0.0435932050708\n",
      "train loss:0.13561558456\n",
      "train loss:0.0681732920879\n",
      "train loss:0.0222014887152\n",
      "train loss:0.0558322973936\n",
      "train loss:0.117945042211\n",
      "train loss:0.0642305848017\n",
      "train loss:0.134332357813\n",
      "train loss:0.1317513494\n",
      "train loss:0.104933566834\n",
      "train loss:0.0910621299649\n",
      "train loss:0.0647514260016\n",
      "train loss:0.0615921132488\n",
      "train loss:0.0716811855352\n",
      "train loss:0.0733173410369\n",
      "train loss:0.0641192785334\n",
      "train loss:0.0506279918343\n",
      "train loss:0.0441639931634\n",
      "train loss:0.0684747593256\n",
      "train loss:0.0978864169298\n",
      "train loss:0.0543144864268\n",
      "train loss:0.129116679417\n",
      "train loss:0.0683599786698\n",
      "train loss:0.115842884981\n",
      "train loss:0.0772446381885\n",
      "train loss:0.20613423714\n",
      "train loss:0.0891354297865\n",
      "train loss:0.12182958669\n",
      "train loss:0.0807040478975\n",
      "train loss:0.0833740212135\n",
      "train loss:0.267555107179\n",
      "train loss:0.112558915902\n",
      "train loss:0.122797168408\n",
      "train loss:0.0947316768054\n",
      "train loss:0.0830213967555\n",
      "train loss:0.028274494714\n",
      "train loss:0.263319330195\n",
      "train loss:0.0969166913069\n",
      "train loss:0.0266407323803\n",
      "train loss:0.166183327987\n",
      "train loss:0.0597008875457\n",
      "train loss:0.0649433962342\n",
      "train loss:0.10060536426\n",
      "train loss:0.141927122018\n",
      "train loss:0.273972665249\n",
      "train loss:0.217789334537\n",
      "train loss:0.12999076852\n",
      "train loss:0.0756843880484\n",
      "train loss:0.0722912847251\n",
      "train loss:0.0295298239375\n",
      "train loss:0.280328021948\n",
      "train loss:0.176266878426\n",
      "train loss:0.124628302611\n",
      "train loss:0.0795203537038\n",
      "train loss:0.0947337587394\n",
      "train loss:0.0451491347588\n",
      "train loss:0.185754620028\n",
      "train loss:0.214735218942\n",
      "train loss:0.188775750369\n",
      "train loss:0.0429233696296\n",
      "train loss:0.106535254144\n",
      "train loss:0.142842634151\n",
      "train loss:0.0816033036054\n",
      "train loss:0.0975031329755\n",
      "train loss:0.121599488453\n",
      "train loss:0.061146003904\n",
      "train loss:0.131311385812\n",
      "train loss:0.119667866745\n",
      "train loss:0.0812086341268\n",
      "train loss:0.0669889869832\n",
      "train loss:0.0558875128021\n",
      "train loss:0.100145752264\n",
      "train loss:0.0609291533814\n",
      "train loss:0.101405981799\n",
      "train loss:0.101044175707\n",
      "train loss:0.116029309134\n",
      "train loss:0.0645056318244\n",
      "train loss:0.0780889729409\n",
      "train loss:0.0994432353787\n",
      "train loss:0.0654217909142\n",
      "train loss:0.141286797548\n",
      "train loss:0.0656114899885\n",
      "train loss:0.070404262623\n",
      "train loss:0.0522260159191\n",
      "train loss:0.0472043905802\n",
      "train loss:0.0554608390696\n",
      "train loss:0.0651617397877\n",
      "train loss:0.0779504350477\n",
      "train loss:0.077333476591\n",
      "train loss:0.0559828036067\n",
      "train loss:0.141581142519\n",
      "train loss:0.214780817669\n",
      "train loss:0.061623175519\n",
      "train loss:0.0614273539547\n",
      "train loss:0.0937168222458\n",
      "train loss:0.0869963283186\n",
      "train loss:0.0418965467526\n",
      "train loss:0.0446033245714\n",
      "train loss:0.0906900549159\n",
      "train loss:0.146364209929\n",
      "train loss:0.0761872470308\n",
      "train loss:0.0906308617386\n",
      "train loss:0.060561309484\n",
      "train loss:0.0737852105726\n",
      "train loss:0.0760167675937\n",
      "train loss:0.0323674560878\n",
      "train loss:0.0661652059261\n",
      "train loss:0.0519894115634\n",
      "train loss:0.110125326858\n",
      "train loss:0.0730413437676\n",
      "train loss:0.0550298450346\n",
      "train loss:0.0629710858337\n",
      "train loss:0.0897061687664\n",
      "train loss:0.0951782667206\n",
      "train loss:0.0783721990593\n",
      "train loss:0.0544882828689\n",
      "train loss:0.0727080019081\n",
      "train loss:0.0406346163851\n",
      "train loss:0.131979667165\n",
      "train loss:0.112917513964\n",
      "train loss:0.0728075213842\n",
      "train loss:0.0709740722581\n",
      "train loss:0.0977869072022\n",
      "train loss:0.153804822444\n",
      "train loss:0.137232141514\n",
      "train loss:0.0772047316394\n",
      "train loss:0.11137535962\n",
      "train loss:0.0847640713368\n",
      "train loss:0.162125047357\n",
      "train loss:0.0821476457199\n",
      "train loss:0.0797611002262\n",
      "train loss:0.0405243364199\n",
      "train loss:0.0640745447056\n",
      "train loss:0.0433737932494\n",
      "train loss:0.0245424965683\n",
      "train loss:0.164925702745\n",
      "train loss:0.0970390311546\n",
      "train loss:0.108287536132\n",
      "train loss:0.0859364111821\n",
      "train loss:0.069128156061\n",
      "train loss:0.0275497692109\n",
      "train loss:0.0632246246749\n",
      "train loss:0.0746573521136\n",
      "train loss:0.100157760528\n",
      "train loss:0.124111296264\n",
      "train loss:0.0549551265732\n",
      "train loss:0.0740602611881\n",
      "train loss:0.204807222111\n",
      "train loss:0.0503925643287\n",
      "train loss:0.0599603435029\n",
      "train loss:0.10845661907\n",
      "train loss:0.0566101981914\n",
      "train loss:0.120384718895\n",
      "train loss:0.122124768745\n",
      "train loss:0.120953232506\n",
      "train loss:0.154896454854\n",
      "train loss:0.0607795593058\n",
      "train loss:0.0874324250162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0330070124843\n",
      "train loss:0.0563067426742\n",
      "train loss:0.0760022846703\n",
      "train loss:0.0592684402386\n",
      "train loss:0.0948058990467\n",
      "train loss:0.105335000593\n",
      "train loss:0.141475318158\n",
      "train loss:0.0803312551188\n",
      "train loss:0.0976738029654\n",
      "train loss:0.0761803044787\n",
      "train loss:0.0918771377233\n",
      "train loss:0.076478344655\n",
      "train loss:0.0808996001853\n",
      "train loss:0.0252407859457\n",
      "train loss:0.0960797492082\n",
      "train loss:0.0839805962954\n",
      "train loss:0.129390795229\n",
      "train loss:0.0618506702331\n",
      "train loss:0.118414650855\n",
      "train loss:0.0528659168188\n",
      "train loss:0.0256976375696\n",
      "train loss:0.101168614041\n",
      "train loss:0.081583405175\n",
      "train loss:0.0316641783206\n",
      "train loss:0.0943507480854\n",
      "train loss:0.102917392357\n",
      "train loss:0.0656672120044\n",
      "train loss:0.053518083962\n",
      "train loss:0.0855076138867\n",
      "train loss:0.0902469737898\n",
      "train loss:0.0715506310258\n",
      "train loss:0.0266284660204\n",
      "train loss:0.0679039521041\n",
      "train loss:0.076086387943\n",
      "train loss:0.0562101196874\n",
      "train loss:0.0977970244948\n",
      "train loss:0.0915045026659\n",
      "train loss:0.0380331790203\n",
      "train loss:0.0372835161355\n",
      "train loss:0.0238574866524\n",
      "train loss:0.0486763367757\n",
      "train loss:0.0346214350739\n",
      "train loss:0.0569469313441\n",
      "train loss:0.0806460673515\n",
      "train loss:0.0921667380517\n",
      "train loss:0.143701496142\n",
      "train loss:0.0736312767573\n",
      "train loss:0.148797872042\n",
      "train loss:0.0804779846517\n",
      "train loss:0.0487194339605\n",
      "train loss:0.0321429773248\n",
      "train loss:0.0368656418438\n",
      "train loss:0.0769836802236\n",
      "train loss:0.10715534859\n",
      "train loss:0.0675826725995\n",
      "train loss:0.0284635811354\n",
      "train loss:0.0676639569348\n",
      "train loss:0.0870745597217\n",
      "train loss:0.0847235787203\n",
      "train loss:0.0135018157354\n",
      "train loss:0.147132239847\n",
      "train loss:0.133879053794\n",
      "train loss:0.189250851743\n",
      "train loss:0.0208282617115\n",
      "train loss:0.0573005078938\n",
      "train loss:0.0981920664371\n",
      "train loss:0.0317615983075\n",
      "train loss:0.0542910514487\n",
      "train loss:0.0655314024179\n",
      "train loss:0.136527243726\n",
      "train loss:0.248438684415\n",
      "train loss:0.0590903515631\n",
      "train loss:0.0543854970978\n",
      "train loss:0.103114074693\n",
      "train loss:0.0654383761597\n",
      "train loss:0.0369279232951\n",
      "train loss:0.062670093307\n",
      "train loss:0.0418666167895\n",
      "train loss:0.0992010257295\n",
      "train loss:0.101378759061\n",
      "train loss:0.0522731450871\n",
      "train loss:0.170039803718\n",
      "train loss:0.0903278128622\n",
      "train loss:0.0472940927694\n",
      "train loss:0.0711147977383\n",
      "train loss:0.0918132761822\n",
      "train loss:0.0209971208834\n",
      "train loss:0.0728517353107\n",
      "train loss:0.0399077240704\n",
      "train loss:0.152167769937\n",
      "train loss:0.0531709130266\n",
      "train loss:0.0698405387239\n",
      "train loss:0.169992844155\n",
      "train loss:0.0425148651427\n",
      "train loss:0.0571906749059\n",
      "train loss:0.170061117567\n",
      "train loss:0.0311676376895\n",
      "train loss:0.0535960338077\n",
      "train loss:0.0278328490771\n",
      "train loss:0.0528479268734\n",
      "train loss:0.0597186419768\n",
      "train loss:0.119892087943\n",
      "train loss:0.0936234531494\n",
      "train loss:0.0757153780233\n",
      "train loss:0.115277974165\n",
      "train loss:0.062379337712\n",
      "train loss:0.0420992391711\n",
      "train loss:0.0475914962583\n",
      "train loss:0.0836879726509\n",
      "train loss:0.0658512624365\n",
      "train loss:0.0510202005332\n",
      "train loss:0.0491556600505\n",
      "train loss:0.0284989694777\n",
      "train loss:0.0896915934699\n",
      "train loss:0.0937673441364\n",
      "train loss:0.150925052732\n",
      "train loss:0.0771276117689\n",
      "train loss:0.0482969819298\n",
      "train loss:0.0229106252208\n",
      "train loss:0.0992513928927\n",
      "train loss:0.118953780522\n",
      "train loss:0.081288944634\n",
      "train loss:0.0425513787781\n",
      "train loss:0.0132873545211\n",
      "train loss:0.0198669182314\n",
      "train loss:0.0448233398817\n",
      "train loss:0.125520146959\n",
      "train loss:0.132084158469\n",
      "train loss:0.0604027142917\n",
      "train loss:0.0601886905462\n",
      "train loss:0.131009742199\n",
      "train loss:0.0593203547571\n",
      "train loss:0.117944111478\n",
      "train loss:0.0572035839832\n",
      "train loss:0.0603760172444\n",
      "train loss:0.0882815801216\n",
      "train loss:0.140366829334\n",
      "train loss:0.0784044044161\n",
      "train loss:0.0526266725071\n",
      "train loss:0.156511747265\n",
      "train loss:0.0800185653537\n",
      "train loss:0.0324210268175\n",
      "train loss:0.0357781771451\n",
      "train loss:0.109779058957\n",
      "train loss:0.0878562220942\n",
      "train loss:0.0321405252939\n",
      "train loss:0.0834664685643\n",
      "train loss:0.0510860089624\n",
      "train loss:0.061407944259\n",
      "train loss:0.0737788901123\n",
      "train loss:0.119675529312\n",
      "train loss:0.109929518388\n",
      "train loss:0.081688619262\n",
      "train loss:0.0678317166589\n",
      "train loss:0.0936050313888\n",
      "train loss:0.156531514774\n",
      "train loss:0.0376599211899\n",
      "train loss:0.0544502763017\n",
      "train loss:0.0370009237864\n",
      "train loss:0.0545069385951\n",
      "train loss:0.19278902052\n",
      "train loss:0.0640153322723\n",
      "train loss:0.0560089442671\n",
      "train loss:0.0678961151587\n",
      "train loss:0.0662203531824\n",
      "train loss:0.0947637306654\n",
      "train loss:0.0762757813881\n",
      "train loss:0.0876741523869\n",
      "train loss:0.109133483669\n",
      "train loss:0.0636459070557\n",
      "train loss:0.0406197805774\n",
      "train loss:0.0890073758511\n",
      "train loss:0.0321075090463\n",
      "train loss:0.0971320750914\n",
      "train loss:0.0411512311776\n",
      "train loss:0.0684798978609\n",
      "train loss:0.0996469488091\n",
      "train loss:0.059141589827\n",
      "train loss:0.0638105527739\n",
      "train loss:0.0320088439535\n",
      "train loss:0.110611277859\n",
      "train loss:0.0758673904593\n",
      "train loss:0.0625189515412\n",
      "train loss:0.0716970085956\n",
      "train loss:0.0519734343016\n",
      "train loss:0.0408408702453\n",
      "train loss:0.1194972865\n",
      "train loss:0.144021685724\n",
      "train loss:0.0858364466482\n",
      "train loss:0.0387650483344\n",
      "train loss:0.0506105052739\n",
      "train loss:0.0828207239105\n",
      "train loss:0.113146368086\n",
      "train loss:0.06077547361\n",
      "train loss:0.0833647814451\n",
      "train loss:0.0958226400004\n",
      "train loss:0.111810230141\n",
      "train loss:0.0570604457435\n",
      "train loss:0.127731420726\n",
      "train loss:0.0299834970065\n",
      "train loss:0.0991318856373\n",
      "train loss:0.0577918548469\n",
      "train loss:0.0556205255602\n",
      "train loss:0.0243129077288\n",
      "train loss:0.0621376804153\n",
      "train loss:0.0890220020477\n",
      "train loss:0.0725193507037\n",
      "train loss:0.0630581579976\n",
      "train loss:0.0450938892695\n",
      "train loss:0.0595131924423\n",
      "train loss:0.0340668761048\n",
      "train loss:0.0688062231797\n",
      "train loss:0.0384697199344\n",
      "train loss:0.135920980003\n",
      "train loss:0.0474682092755\n",
      "train loss:0.0893150080598\n",
      "train loss:0.0354866305361\n",
      "train loss:0.105205141139\n",
      "train loss:0.0510643160209\n",
      "train loss:0.0183718418353\n",
      "train loss:0.0227833682477\n",
      "train loss:0.043212759782\n",
      "train loss:0.120969252332\n",
      "train loss:0.207653757775\n",
      "train loss:0.0410014133088\n",
      "train loss:0.0343897974403\n",
      "train loss:0.0691944794538\n",
      "train loss:0.0701947104577\n",
      "train loss:0.0596755625539\n",
      "train loss:0.144754225612\n",
      "train loss:0.0411950782376\n",
      "train loss:0.122673329684\n",
      "train loss:0.041739653399\n",
      "train loss:0.0969297090396\n",
      "train loss:0.0385346118688\n",
      "train loss:0.0946939550761\n",
      "train loss:0.0198123211605\n",
      "train loss:0.0600043643299\n",
      "train loss:0.0499026659388\n",
      "train loss:0.0846368899468\n",
      "train loss:0.110330099883\n",
      "train loss:0.0734410242822\n",
      "train loss:0.0440192365686\n",
      "train loss:0.0211158292206\n",
      "train loss:0.0734087700759\n",
      "train loss:0.0602446730397\n",
      "train loss:0.0149219756274\n",
      "train loss:0.0774127475422\n",
      "train loss:0.0292713613046\n",
      "train loss:0.0968415709585\n",
      "train loss:0.0461567923536\n",
      "train loss:0.214721035451\n",
      "train loss:0.017096996327\n",
      "train loss:0.0212127251019\n",
      "train loss:0.0674607424635\n",
      "train loss:0.0864343324065\n",
      "train loss:0.0272254520432\n",
      "train loss:0.0551696166643\n",
      "train loss:0.0863993655245\n",
      "train loss:0.112986045663\n",
      "train loss:0.108102538835\n",
      "=== epoch:3, train acc:0.981, test acc:0.976 ===\n",
      "train loss:0.0390502618049\n",
      "train loss:0.0894453209414\n",
      "train loss:0.0630429342139\n",
      "train loss:0.0622436388701\n",
      "train loss:0.0698045694639\n",
      "train loss:0.0640651790501\n",
      "train loss:0.0304408740217\n",
      "train loss:0.0604241714292\n",
      "train loss:0.03098310449\n",
      "train loss:0.0599357991128\n",
      "train loss:0.102302762674\n",
      "train loss:0.0262456444227\n",
      "train loss:0.0273121363722\n",
      "train loss:0.0744701646697\n",
      "train loss:0.0724834526645\n",
      "train loss:0.0234560677227\n",
      "train loss:0.140223193112\n",
      "train loss:0.0228823436704\n",
      "train loss:0.042257171371\n",
      "train loss:0.157616866587\n",
      "train loss:0.172903164028\n",
      "train loss:0.104491558337\n",
      "train loss:0.064058339989\n",
      "train loss:0.0284259951199\n",
      "train loss:0.131335263351\n",
      "train loss:0.0364810036342\n",
      "train loss:0.152736220066\n",
      "train loss:0.0493658660243\n",
      "train loss:0.030354347629\n",
      "train loss:0.06620888418\n",
      "train loss:0.0299386232292\n",
      "train loss:0.0387438176713\n",
      "train loss:0.100358534071\n",
      "train loss:0.13281077288\n",
      "train loss:0.020923782533\n",
      "train loss:0.0310590419225\n",
      "train loss:0.099250361376\n",
      "train loss:0.105281558382\n",
      "train loss:0.0468361195259\n",
      "train loss:0.0537658624892\n",
      "train loss:0.065855366048\n",
      "train loss:0.0121432539163\n",
      "train loss:0.0492067490107\n",
      "train loss:0.0969574499956\n",
      "train loss:0.039694329927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0526966932622\n",
      "train loss:0.179261297426\n",
      "train loss:0.0627238433429\n",
      "train loss:0.0543009394243\n",
      "train loss:0.0581089345645\n",
      "train loss:0.0559033981607\n",
      "train loss:0.0211986717289\n",
      "train loss:0.0345455071372\n",
      "train loss:0.0597929017101\n",
      "train loss:0.0363836809202\n",
      "train loss:0.0320741439289\n",
      "train loss:0.0652642253584\n",
      "train loss:0.118254665287\n",
      "train loss:0.0887712132014\n",
      "train loss:0.0579751739819\n",
      "train loss:0.0418917511007\n",
      "train loss:0.0313487869838\n",
      "train loss:0.0498271423172\n",
      "train loss:0.121040188547\n",
      "train loss:0.0192674652157\n",
      "train loss:0.0589100638582\n",
      "train loss:0.0659989301937\n",
      "train loss:0.0231456625758\n",
      "train loss:0.0920816988756\n",
      "train loss:0.025827785594\n",
      "train loss:0.0410394615684\n",
      "train loss:0.031693875787\n",
      "train loss:0.0676452661913\n",
      "train loss:0.114625776915\n",
      "train loss:0.115493232678\n",
      "train loss:0.0359880019415\n",
      "train loss:0.0653831905994\n",
      "train loss:0.107625868623\n",
      "train loss:0.0746749679939\n",
      "train loss:0.017988314271\n",
      "train loss:0.0939328245214\n",
      "train loss:0.0450524553623\n",
      "train loss:0.060670321064\n",
      "train loss:0.0818878558092\n",
      "train loss:0.0505009548719\n",
      "train loss:0.0665514247397\n",
      "train loss:0.0957550786075\n",
      "train loss:0.0437033186526\n",
      "train loss:0.0848751580497\n",
      "train loss:0.0530026507111\n",
      "train loss:0.016801121074\n",
      "train loss:0.0291682293355\n",
      "train loss:0.0570282236657\n",
      "train loss:0.0114659310995\n",
      "train loss:0.0210607251875\n",
      "train loss:0.105032307474\n",
      "train loss:0.152160419569\n",
      "train loss:0.0897826374863\n",
      "train loss:0.0349374643049\n",
      "train loss:0.0381450398307\n",
      "train loss:0.0583735646489\n",
      "train loss:0.0802134276966\n",
      "train loss:0.0866612559063\n",
      "train loss:0.038909576584\n",
      "train loss:0.101108146884\n",
      "train loss:0.0659235908184\n",
      "train loss:0.0424748598476\n",
      "train loss:0.0333668553649\n",
      "train loss:0.0568747543798\n",
      "train loss:0.0522655449859\n",
      "train loss:0.0393524457611\n",
      "train loss:0.0372230622417\n",
      "train loss:0.0595919770036\n",
      "train loss:0.0106934106864\n",
      "train loss:0.0468220097551\n",
      "train loss:0.0355643371851\n",
      "train loss:0.134343223629\n",
      "train loss:0.0882934643359\n",
      "train loss:0.0138800954128\n",
      "train loss:0.0395585921432\n",
      "train loss:0.0139689552325\n",
      "train loss:0.0372893082535\n",
      "train loss:0.0632688878233\n",
      "train loss:0.0263206385025\n",
      "train loss:0.0286913310036\n",
      "train loss:0.054474614628\n",
      "train loss:0.0917174253464\n",
      "train loss:0.0601455920578\n",
      "train loss:0.146892908177\n",
      "train loss:0.0463505479363\n",
      "train loss:0.0964212531347\n",
      "train loss:0.0455580446966\n",
      "train loss:0.0559622804934\n",
      "train loss:0.096979619952\n",
      "train loss:0.0862762814581\n",
      "train loss:0.0774475786565\n",
      "train loss:0.0167819730143\n",
      "train loss:0.109210611622\n",
      "train loss:0.0524634517632\n",
      "train loss:0.0342966908542\n",
      "train loss:0.0537061510975\n",
      "train loss:0.0616704555131\n",
      "train loss:0.115921167246\n",
      "train loss:0.0558590815653\n",
      "train loss:0.0467845743881\n",
      "train loss:0.06161531675\n",
      "train loss:0.134400283153\n",
      "train loss:0.0421076736289\n",
      "train loss:0.0656767734255\n",
      "train loss:0.0481106215053\n",
      "train loss:0.0699106499544\n",
      "train loss:0.0853172809758\n",
      "train loss:0.0965970332691\n",
      "train loss:0.0598371131349\n",
      "train loss:0.0531265175296\n",
      "train loss:0.0342585518928\n",
      "train loss:0.0387207450976\n",
      "train loss:0.0271882098624\n",
      "train loss:0.0310911949574\n",
      "train loss:0.0438550749374\n",
      "train loss:0.0594524560103\n",
      "train loss:0.131622949394\n",
      "train loss:0.068135945667\n",
      "train loss:0.0679324351618\n",
      "train loss:0.0127503068335\n",
      "train loss:0.0321221742923\n",
      "train loss:0.0282465546458\n",
      "train loss:0.0142036335698\n",
      "train loss:0.0244989599878\n",
      "train loss:0.0639552482557\n",
      "train loss:0.0267245419339\n",
      "train loss:0.0887712170751\n",
      "train loss:0.00722436229174\n",
      "train loss:0.0430254361552\n",
      "train loss:0.036652949117\n",
      "train loss:0.0394574910698\n",
      "train loss:0.0614259857783\n",
      "train loss:0.0144939024303\n",
      "train loss:0.0225146024691\n",
      "train loss:0.0268929515451\n",
      "train loss:0.0371043636945\n",
      "train loss:0.102972938101\n",
      "train loss:0.0904941086993\n",
      "train loss:0.0347955034424\n",
      "train loss:0.237530986178\n",
      "train loss:0.0393243065915\n",
      "train loss:0.0546961446559\n",
      "train loss:0.0708073357596\n",
      "train loss:0.0226233092922\n",
      "train loss:0.032686928186\n",
      "train loss:0.157248278762\n",
      "train loss:0.0567176669152\n",
      "train loss:0.0392848303639\n",
      "train loss:0.0777998827196\n",
      "train loss:0.0512178775106\n",
      "train loss:0.0434414661321\n",
      "train loss:0.0137147673154\n",
      "train loss:0.0306890252607\n",
      "train loss:0.046350218442\n",
      "train loss:0.0873260651339\n",
      "train loss:0.0541280281687\n",
      "train loss:0.0643452391524\n",
      "train loss:0.021355192006\n",
      "train loss:0.18276665802\n",
      "train loss:0.118291064766\n",
      "train loss:0.0354101419043\n",
      "train loss:0.0556396120456\n",
      "train loss:0.0788283010325\n",
      "train loss:0.0902412581848\n",
      "train loss:0.0309673696574\n",
      "train loss:0.0351175380465\n",
      "train loss:0.06519221839\n",
      "train loss:0.0271210639677\n",
      "train loss:0.0537715033356\n",
      "train loss:0.0207995676293\n",
      "train loss:0.0493242772993\n",
      "train loss:0.0644862440093\n",
      "train loss:0.0400532090028\n",
      "train loss:0.0221337218005\n",
      "train loss:0.075572274421\n",
      "train loss:0.082976055786\n",
      "train loss:0.0271351963573\n",
      "train loss:0.037369130369\n",
      "train loss:0.0698524171089\n",
      "train loss:0.0315831235802\n",
      "train loss:0.0457686698294\n",
      "train loss:0.0722254658462\n",
      "train loss:0.0253746905627\n",
      "train loss:0.0131701187388\n",
      "train loss:0.00566816520615\n",
      "train loss:0.0470019894252\n",
      "train loss:0.0191878110178\n",
      "train loss:0.0757546406577\n",
      "train loss:0.0376782790347\n",
      "train loss:0.0274769622415\n",
      "train loss:0.0983238100005\n",
      "train loss:0.0515293814912\n",
      "train loss:0.071548219797\n",
      "train loss:0.0412555794894\n",
      "train loss:0.0396063963113\n",
      "train loss:0.0434321411213\n",
      "train loss:0.0139831429677\n",
      "train loss:0.0200329185755\n",
      "train loss:0.0318724613237\n",
      "train loss:0.0693682061113\n",
      "train loss:0.065646780216\n",
      "train loss:0.0378628011498\n",
      "train loss:0.0530295169823\n",
      "train loss:0.0279205756136\n",
      "train loss:0.124738929122\n",
      "train loss:0.0474540997365\n",
      "train loss:0.0401782692856\n",
      "train loss:0.022323782065\n",
      "train loss:0.0322334927691\n",
      "train loss:0.0425434618452\n",
      "train loss:0.0364866035664\n",
      "train loss:0.0215051622373\n",
      "train loss:0.0237588191611\n",
      "train loss:0.0265262142295\n",
      "train loss:0.118630191618\n",
      "train loss:0.0269744203057\n",
      "train loss:0.111064340219\n",
      "train loss:0.0293585791008\n",
      "train loss:0.0684975314904\n",
      "train loss:0.0481379752399\n",
      "train loss:0.0275656988626\n",
      "train loss:0.0609985709852\n",
      "train loss:0.0630048818688\n",
      "train loss:0.047047898076\n",
      "train loss:0.07955188051\n",
      "train loss:0.0450815241442\n",
      "train loss:0.0460084868027\n",
      "train loss:0.0731784426082\n",
      "train loss:0.0924624546739\n",
      "train loss:0.107549295525\n",
      "train loss:0.0829298569583\n",
      "train loss:0.0825400074405\n",
      "train loss:0.149670952873\n",
      "train loss:0.0312970303219\n",
      "train loss:0.0603530701067\n",
      "train loss:0.0494986698688\n",
      "train loss:0.0717585210955\n",
      "train loss:0.117511482249\n",
      "train loss:0.0516092574547\n",
      "train loss:0.0550415578257\n",
      "train loss:0.0183023331707\n",
      "train loss:0.0201700320967\n",
      "train loss:0.0222608517261\n",
      "train loss:0.0942498978482\n",
      "train loss:0.147800807686\n",
      "train loss:0.0286855745725\n",
      "train loss:0.0129433188761\n",
      "train loss:0.0212928331202\n",
      "train loss:0.0184335008547\n",
      "train loss:0.0232391673448\n",
      "train loss:0.0217007515664\n",
      "train loss:0.0623047525435\n",
      "train loss:0.0584409443025\n",
      "train loss:0.0296096936549\n",
      "train loss:0.0388932493323\n",
      "train loss:0.0682152188363\n",
      "train loss:0.0230618872442\n",
      "train loss:0.0199900393269\n",
      "train loss:0.0819851369378\n",
      "train loss:0.0585164559122\n",
      "train loss:0.0367175063385\n",
      "train loss:0.0218691173719\n",
      "train loss:0.0686928287136\n",
      "train loss:0.045847083204\n",
      "train loss:0.0401112318402\n",
      "train loss:0.0494805412229\n",
      "train loss:0.0299796736312\n",
      "train loss:0.0682237258378\n",
      "train loss:0.065278701509\n",
      "train loss:0.011096565151\n",
      "train loss:0.0912932203158\n",
      "train loss:0.0530221395357\n",
      "train loss:0.0723275176245\n",
      "train loss:0.0627168852697\n",
      "train loss:0.0344449668089\n",
      "train loss:0.0678061021884\n",
      "train loss:0.0528637149972\n",
      "train loss:0.0452046924086\n",
      "train loss:0.0249069598472\n",
      "train loss:0.0655971791317\n",
      "train loss:0.0797314354118\n",
      "train loss:0.0280480991541\n",
      "train loss:0.0108826446608\n",
      "train loss:0.01344254743\n",
      "train loss:0.0348813826743\n",
      "train loss:0.0745748683389\n",
      "train loss:0.0448254592349\n",
      "train loss:0.0369334472029\n",
      "train loss:0.0279388218334\n",
      "train loss:0.0301745498122\n",
      "train loss:0.0310747385754\n",
      "train loss:0.0933498205393\n",
      "train loss:0.128996583542\n",
      "train loss:0.0410214303788\n",
      "train loss:0.0304157597723\n",
      "train loss:0.0878798306348\n",
      "train loss:0.0489203370302\n",
      "train loss:0.0414774549403\n",
      "train loss:0.0152782170256\n",
      "train loss:0.143381928167\n",
      "train loss:0.077181411648\n",
      "train loss:0.0342125149296\n",
      "train loss:0.12274807216\n",
      "train loss:0.0228450207887\n",
      "train loss:0.00972996611431\n",
      "train loss:0.0614562769347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0612894340408\n",
      "train loss:0.0641508191606\n",
      "train loss:0.162204785878\n",
      "train loss:0.0367429530396\n",
      "train loss:0.0103496755362\n",
      "train loss:0.0466658393725\n",
      "train loss:0.116949608249\n",
      "train loss:0.00667181808479\n",
      "train loss:0.0171226982983\n",
      "train loss:0.116672843099\n",
      "train loss:0.0129114922609\n",
      "train loss:0.0314848094152\n",
      "train loss:0.0801394986353\n",
      "train loss:0.025159490241\n",
      "train loss:0.045209122618\n",
      "train loss:0.0569658139401\n",
      "train loss:0.0248624817358\n",
      "train loss:0.0329079806646\n",
      "train loss:0.110033304674\n",
      "train loss:0.0554424898937\n",
      "train loss:0.0367228940376\n",
      "train loss:0.0257914589558\n",
      "train loss:0.0772669974893\n",
      "train loss:0.0566241722906\n",
      "train loss:0.0620889582977\n",
      "train loss:0.0471617681281\n",
      "train loss:0.0737981009472\n",
      "train loss:0.0202586004539\n",
      "train loss:0.0403448542791\n",
      "train loss:0.0429094322303\n",
      "train loss:0.0537518373735\n",
      "train loss:0.0307622695139\n",
      "train loss:0.0548316990294\n",
      "train loss:0.0484996303747\n",
      "train loss:0.0104964023629\n",
      "train loss:0.0468621150978\n",
      "train loss:0.0154453569414\n",
      "train loss:0.0302585208052\n",
      "train loss:0.0131023656039\n",
      "train loss:0.0643392862438\n",
      "train loss:0.0477037441159\n",
      "train loss:0.0320263249893\n",
      "train loss:0.0309894260345\n",
      "train loss:0.0482975345926\n",
      "train loss:0.0314908303196\n",
      "train loss:0.0251362594602\n",
      "train loss:0.0185577303554\n",
      "train loss:0.12798525547\n",
      "train loss:0.00935391034849\n",
      "train loss:0.0305907094524\n",
      "train loss:0.0352066797898\n",
      "train loss:0.0410055926001\n",
      "train loss:0.0623367729778\n",
      "train loss:0.0559211633217\n",
      "train loss:0.0125434513177\n",
      "train loss:0.0355195310481\n",
      "train loss:0.0563032440134\n",
      "train loss:0.0818042619574\n",
      "train loss:0.0394635731188\n",
      "train loss:0.058331623689\n",
      "train loss:0.0119103150174\n",
      "train loss:0.0669557352331\n",
      "train loss:0.0531458322163\n",
      "train loss:0.0320202468136\n",
      "train loss:0.00587160038724\n",
      "train loss:0.026089093536\n",
      "train loss:0.0832887267541\n",
      "train loss:0.0363840147076\n",
      "train loss:0.0273590421126\n",
      "train loss:0.0277044401223\n",
      "train loss:0.0889052721438\n",
      "train loss:0.0733516150299\n",
      "train loss:0.0129353957318\n",
      "train loss:0.0194917750669\n",
      "train loss:0.0316353063911\n",
      "train loss:0.0205812239849\n",
      "train loss:0.00879701842189\n",
      "train loss:0.0359524180108\n",
      "train loss:0.039853964506\n",
      "train loss:0.0185034773611\n",
      "train loss:0.0722600504329\n",
      "train loss:0.0254732858316\n",
      "train loss:0.0362827721689\n",
      "train loss:0.0614076229636\n",
      "train loss:0.034358972879\n",
      "train loss:0.0214512873137\n",
      "train loss:0.0518665111341\n",
      "train loss:0.0863104844618\n",
      "train loss:0.0418287817532\n",
      "train loss:0.0322793889799\n",
      "train loss:0.0368149854968\n",
      "train loss:0.0249654553701\n",
      "train loss:0.0273159141048\n",
      "train loss:0.00880484558708\n",
      "train loss:0.125330370713\n",
      "train loss:0.108489952596\n",
      "train loss:0.0546073517323\n",
      "train loss:0.0422084886159\n",
      "train loss:0.0313152618898\n",
      "train loss:0.0792301204435\n",
      "train loss:0.0915465267988\n",
      "train loss:0.0370481928269\n",
      "train loss:0.0223938085114\n",
      "train loss:0.0722632316176\n",
      "train loss:0.0471907630182\n",
      "train loss:0.0316525437743\n",
      "train loss:0.0890333694945\n",
      "train loss:0.0335238356557\n",
      "train loss:0.00525013939024\n",
      "train loss:0.0184627713907\n",
      "train loss:0.0662099292742\n",
      "train loss:0.0267387196036\n",
      "train loss:0.113786299118\n",
      "train loss:0.0400385836794\n",
      "train loss:0.00757758302309\n",
      "train loss:0.0340876626221\n",
      "train loss:0.0313573283774\n",
      "train loss:0.0549942317506\n",
      "train loss:0.133292501276\n",
      "train loss:0.019286745844\n",
      "train loss:0.0196103099966\n",
      "train loss:0.0821370203309\n",
      "train loss:0.0418538718041\n",
      "train loss:0.136991425138\n",
      "train loss:0.0484126433051\n",
      "train loss:0.0243108224628\n",
      "train loss:0.0256646562944\n",
      "train loss:0.031242685265\n",
      "train loss:0.0137528655745\n",
      "train loss:0.0257527118139\n",
      "train loss:0.0159089508369\n",
      "train loss:0.132397822054\n",
      "train loss:0.0445123013961\n",
      "train loss:0.0591236354386\n",
      "train loss:0.0796118288165\n",
      "train loss:0.0281293709338\n",
      "train loss:0.0259861209104\n",
      "train loss:0.0501222591404\n",
      "train loss:0.0307093673174\n",
      "train loss:0.0227286873109\n",
      "train loss:0.0223984307845\n",
      "train loss:0.0835635057908\n",
      "train loss:0.0894520524589\n",
      "train loss:0.0144821419207\n",
      "train loss:0.0936250472555\n",
      "train loss:0.0508005577283\n",
      "train loss:0.0508682808255\n",
      "train loss:0.0453708650245\n",
      "train loss:0.0414616932161\n",
      "train loss:0.0421051900785\n",
      "train loss:0.0392566925723\n",
      "train loss:0.0261266487207\n",
      "train loss:0.0121561614155\n",
      "train loss:0.0551391974888\n",
      "train loss:0.0141680928647\n",
      "train loss:0.0641829859165\n",
      "train loss:0.0712899470423\n",
      "train loss:0.0716572623687\n",
      "train loss:0.0504175764915\n",
      "train loss:0.0343434485539\n",
      "train loss:0.073327510769\n",
      "train loss:0.0108275304646\n",
      "train loss:0.0496617550896\n",
      "train loss:0.0310306909361\n",
      "train loss:0.0187870360001\n",
      "train loss:0.0395390414754\n",
      "train loss:0.0167505634275\n",
      "train loss:0.073063780841\n",
      "train loss:0.0393123685012\n",
      "train loss:0.0216354931969\n",
      "train loss:0.0284530717342\n",
      "train loss:0.0944745464473\n",
      "train loss:0.0395282189419\n",
      "train loss:0.0204494670915\n",
      "train loss:0.0580488791433\n",
      "train loss:0.0308512201229\n",
      "train loss:0.045813867396\n",
      "train loss:0.0637154200956\n",
      "train loss:0.0382912578654\n",
      "train loss:0.0364563015817\n",
      "train loss:0.0838949141351\n",
      "train loss:0.0434027601171\n",
      "train loss:0.0746248953031\n",
      "train loss:0.0354451077398\n",
      "train loss:0.0537565350702\n",
      "train loss:0.0455853344037\n",
      "train loss:0.0344465505625\n",
      "train loss:0.0166895625332\n",
      "train loss:0.0377906933492\n",
      "train loss:0.0563734769543\n",
      "train loss:0.0160789309872\n",
      "train loss:0.0340000761251\n",
      "train loss:0.0394679427255\n",
      "train loss:0.0682562904535\n",
      "train loss:0.0216766503874\n",
      "train loss:0.0448033262743\n",
      "train loss:0.0724526968959\n",
      "train loss:0.041122635071\n",
      "train loss:0.0734553266962\n",
      "train loss:0.0146179339053\n",
      "train loss:0.0292275947647\n",
      "train loss:0.0563932737422\n",
      "train loss:0.0108581517637\n",
      "train loss:0.0182880951222\n",
      "train loss:0.0205699325037\n",
      "train loss:0.0777833829756\n",
      "train loss:0.0689258371948\n",
      "train loss:0.0822933193912\n",
      "train loss:0.037635508234\n",
      "train loss:0.151381571608\n",
      "train loss:0.0323383552717\n",
      "train loss:0.0503419404845\n",
      "train loss:0.01320934629\n",
      "train loss:0.0261803133609\n",
      "train loss:0.0777187827031\n",
      "train loss:0.0580560034238\n",
      "train loss:0.0442613812409\n",
      "train loss:0.0142511883181\n",
      "train loss:0.0285009752295\n",
      "train loss:0.0907944968271\n",
      "train loss:0.0384759199664\n",
      "train loss:0.0328739242305\n",
      "train loss:0.0393022790595\n",
      "train loss:0.0234464013969\n",
      "train loss:0.0903144644926\n",
      "train loss:0.00984603047478\n",
      "train loss:0.0233790837252\n",
      "train loss:0.0125167223796\n",
      "train loss:0.0193573303429\n",
      "train loss:0.0140346511027\n",
      "train loss:0.0973979103969\n",
      "train loss:0.0414484597293\n",
      "train loss:0.0411980581669\n",
      "train loss:0.0246624442422\n",
      "train loss:0.0369927566596\n",
      "train loss:0.0337771746854\n",
      "train loss:0.0385744612578\n",
      "train loss:0.0734623282957\n",
      "train loss:0.0322686337721\n",
      "train loss:0.0205199675192\n",
      "train loss:0.0398896684944\n",
      "train loss:0.0238941608547\n",
      "train loss:0.0220585665008\n",
      "train loss:0.0353253323811\n",
      "train loss:0.0175396488145\n",
      "train loss:0.0696513583168\n",
      "train loss:0.0839849640821\n",
      "train loss:0.0291564091695\n",
      "train loss:0.0429570359506\n",
      "=== epoch:4, train acc:0.986, test acc:0.982 ===\n",
      "train loss:0.0579630983306\n",
      "train loss:0.0564943870008\n",
      "train loss:0.0633471127174\n",
      "train loss:0.0574211769904\n",
      "train loss:0.00767045230295\n",
      "train loss:0.0631033967308\n",
      "train loss:0.0247497812008\n",
      "train loss:0.0356729225687\n",
      "train loss:0.02994010351\n",
      "train loss:0.0527556562706\n",
      "train loss:0.0845169731361\n",
      "train loss:0.0208337528767\n",
      "train loss:0.0809244115705\n",
      "train loss:0.01542897608\n",
      "train loss:0.0158877991368\n",
      "train loss:0.0457514688331\n",
      "train loss:0.0563553301482\n",
      "train loss:0.0105540789424\n",
      "train loss:0.0915159152442\n",
      "train loss:0.0283530229249\n",
      "train loss:0.0169017203948\n",
      "train loss:0.0361772592146\n",
      "train loss:0.0461346612175\n",
      "train loss:0.0341717088372\n",
      "train loss:0.0166676658074\n",
      "train loss:0.125703097908\n",
      "train loss:0.00982792665551\n",
      "train loss:0.0436207257795\n",
      "train loss:0.0926712962694\n",
      "train loss:0.0192920861954\n",
      "train loss:0.0156413158697\n",
      "train loss:0.0123665697517\n",
      "train loss:0.00877117114895\n",
      "train loss:0.0430960742649\n",
      "train loss:0.0235919824818\n",
      "train loss:0.0531228911277\n",
      "train loss:0.0652762090842\n",
      "train loss:0.0146085303748\n",
      "train loss:0.10278072634\n",
      "train loss:0.175517508032\n",
      "train loss:0.0249973249926\n",
      "train loss:0.0207487622082\n",
      "train loss:0.0344891108313\n",
      "train loss:0.0332191645692\n",
      "train loss:0.0166234085141\n",
      "train loss:0.0506239908252\n",
      "train loss:0.0145808343877\n",
      "train loss:0.0562647517608\n",
      "train loss:0.0484021345211\n",
      "train loss:0.069201610368\n",
      "train loss:0.0430975081757\n",
      "train loss:0.0104860284092\n",
      "train loss:0.054028723003\n",
      "train loss:0.0311953398591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0371647978309\n",
      "train loss:0.121714011804\n",
      "train loss:0.0396888434715\n",
      "train loss:0.0777512539405\n",
      "train loss:0.0280967956278\n",
      "train loss:0.104662474167\n",
      "train loss:0.0668411642294\n",
      "train loss:0.0363503275259\n",
      "train loss:0.0865723338587\n",
      "train loss:0.123119712962\n",
      "train loss:0.0438744219744\n",
      "train loss:0.0215648956374\n",
      "train loss:0.0343385383383\n",
      "train loss:0.0361272294658\n",
      "train loss:0.0790778258405\n",
      "train loss:0.0729327920413\n",
      "train loss:0.053392777515\n",
      "train loss:0.0289360176729\n",
      "train loss:0.0123905236479\n",
      "train loss:0.026785993527\n",
      "train loss:0.0194236982287\n",
      "train loss:0.0133568232139\n",
      "train loss:0.0105850341733\n",
      "train loss:0.0440406429543\n",
      "train loss:0.061819541988\n",
      "train loss:0.00558365416029\n",
      "train loss:0.0203596481697\n",
      "train loss:0.0404651996791\n",
      "train loss:0.0751424185911\n",
      "train loss:0.0392884770047\n",
      "train loss:0.0268543454855\n",
      "train loss:0.0293271133324\n",
      "train loss:0.0652178880303\n",
      "train loss:0.0395512236643\n",
      "train loss:0.0207695148049\n",
      "train loss:0.0830188793144\n",
      "train loss:0.042937260749\n",
      "train loss:0.0382773757437\n",
      "train loss:0.0375359553822\n",
      "train loss:0.0806524532001\n",
      "train loss:0.0229813067706\n",
      "train loss:0.0701634049686\n",
      "train loss:0.0303592475804\n",
      "train loss:0.0694031230656\n",
      "train loss:0.0323661570432\n",
      "train loss:0.0581456399354\n",
      "train loss:0.0209343474549\n",
      "train loss:0.0303758728418\n",
      "train loss:0.0934183516285\n",
      "train loss:0.053134358442\n",
      "train loss:0.023164704384\n",
      "train loss:0.0182087398049\n",
      "train loss:0.0978155364901\n",
      "train loss:0.0850377855589\n",
      "train loss:0.0840942707899\n",
      "train loss:0.0674471598809\n",
      "train loss:0.0106940813482\n",
      "train loss:0.0247175815518\n",
      "train loss:0.0612851445252\n",
      "train loss:0.0190677177249\n",
      "train loss:0.0390318238772\n",
      "train loss:0.012087532383\n",
      "train loss:0.0122595651283\n",
      "train loss:0.0256414208914\n",
      "train loss:0.0284652134383\n",
      "train loss:0.0152513518975\n",
      "train loss:0.0668662427799\n",
      "train loss:0.00694865102052\n",
      "train loss:0.0335035720569\n",
      "train loss:0.017270859536\n",
      "train loss:0.0194663354151\n",
      "train loss:0.0210592682792\n",
      "train loss:0.00696814197601\n",
      "train loss:0.0673427347027\n",
      "train loss:0.00598850604913\n",
      "train loss:0.0176809152813\n",
      "train loss:0.0268392489616\n",
      "train loss:0.0362043759997\n",
      "train loss:0.0203684729563\n",
      "train loss:0.0726962291729\n",
      "train loss:0.083172963046\n",
      "train loss:0.0138884267664\n",
      "train loss:0.0125435484982\n",
      "train loss:0.0249883142516\n",
      "train loss:0.0492180253786\n",
      "train loss:0.0131699647116\n",
      "train loss:0.0344644930905\n",
      "train loss:0.0315813601428\n",
      "train loss:0.0187195761147\n",
      "train loss:0.00923386286717\n",
      "train loss:0.00541366512552\n",
      "train loss:0.0235504762361\n",
      "train loss:0.0424189741293\n",
      "train loss:0.036251188244\n",
      "train loss:0.0355904681057\n",
      "train loss:0.00937399577762\n",
      "train loss:0.0232955904742\n",
      "train loss:0.010268654967\n",
      "train loss:0.0186020234974\n",
      "train loss:0.0767373030495\n",
      "train loss:0.012707954008\n",
      "train loss:0.135175744737\n",
      "train loss:0.0667231974982\n",
      "train loss:0.0166764575582\n",
      "train loss:0.0143673958467\n",
      "train loss:0.0716171871217\n",
      "train loss:0.00843771111083\n",
      "train loss:0.0168009140869\n",
      "train loss:0.077747370867\n",
      "train loss:0.0116722160664\n",
      "train loss:0.0495033826241\n",
      "train loss:0.0417217931594\n",
      "train loss:0.0977230237949\n",
      "train loss:0.0157684172649\n",
      "train loss:0.129494335439\n",
      "train loss:0.0330969379488\n",
      "train loss:0.0298645061693\n",
      "train loss:0.0165346948514\n",
      "train loss:0.01787551205\n",
      "train loss:0.0115416769374\n",
      "train loss:0.0454955342986\n",
      "train loss:0.0319923452825\n",
      "train loss:0.0476529186177\n",
      "train loss:0.017269355078\n",
      "train loss:0.0291408077414\n",
      "train loss:0.0310573022136\n",
      "train loss:0.0388715358413\n",
      "train loss:0.0428264166914\n",
      "train loss:0.0193423369447\n",
      "train loss:0.0617481359156\n",
      "train loss:0.0971738388746\n",
      "train loss:0.0505662332667\n",
      "train loss:0.0142318703175\n",
      "train loss:0.0376486580897\n",
      "train loss:0.0439975051957\n",
      "train loss:0.064256110235\n",
      "train loss:0.0247838313843\n",
      "train loss:0.0127173256951\n",
      "train loss:0.0713641881672\n",
      "train loss:0.062385380044\n",
      "train loss:0.0155364657925\n",
      "train loss:0.026268469343\n",
      "train loss:0.0342877899865\n",
      "train loss:0.0202861095495\n",
      "train loss:0.0326521369905\n",
      "train loss:0.0359625089762\n",
      "train loss:0.0133772842086\n",
      "train loss:0.0133437372424\n",
      "train loss:0.0200170860854\n",
      "train loss:0.0858306583597\n",
      "train loss:0.0517784459643\n",
      "train loss:0.00675745069779\n",
      "train loss:0.0949424280184\n",
      "train loss:0.0427919017505\n",
      "train loss:0.0145515268566\n",
      "train loss:0.139579260786\n",
      "train loss:0.0508705045495\n",
      "train loss:0.0214288839565\n",
      "train loss:0.0678065732512\n",
      "train loss:0.0193895667792\n",
      "train loss:0.0489206682677\n",
      "train loss:0.0490951329303\n",
      "train loss:0.0349543478877\n",
      "train loss:0.0323373599003\n",
      "train loss:0.0202911287342\n",
      "train loss:0.0267947881373\n",
      "train loss:0.0108047971142\n",
      "train loss:0.0301431172846\n",
      "train loss:0.0295203779878\n",
      "train loss:0.0221122393981\n",
      "train loss:0.0491750194339\n",
      "train loss:0.0212855394635\n",
      "train loss:0.109789175014\n",
      "train loss:0.0130705882906\n",
      "train loss:0.041094745027\n",
      "train loss:0.0594272201864\n",
      "train loss:0.0332335962917\n",
      "train loss:0.169913071584\n",
      "train loss:0.0314310500017\n",
      "train loss:0.0336743140117\n",
      "train loss:0.0109485664776\n",
      "train loss:0.0206615723619\n",
      "train loss:0.0382504244811\n",
      "train loss:0.0527979118726\n",
      "train loss:0.0693078118876\n",
      "train loss:0.0528450063809\n",
      "train loss:0.108714366743\n",
      "train loss:0.0117384687338\n",
      "train loss:0.0427183824949\n",
      "train loss:0.0538461291276\n",
      "train loss:0.0497991811837\n",
      "train loss:0.0141809485229\n",
      "train loss:0.107188007014\n",
      "train loss:0.0319959474186\n",
      "train loss:0.0458234472132\n",
      "train loss:0.0149275782698\n",
      "train loss:0.0652949799006\n",
      "train loss:0.040892049866\n",
      "train loss:0.0447147664898\n",
      "train loss:0.0818259483187\n",
      "train loss:0.0249267506894\n",
      "train loss:0.151411825031\n",
      "train loss:0.0530479843095\n",
      "train loss:0.00889401219765\n",
      "train loss:0.059032556267\n",
      "train loss:0.0534101068738\n",
      "train loss:0.0180013929423\n",
      "train loss:0.0219412866351\n",
      "train loss:0.0336243601365\n",
      "train loss:0.0446618168345\n",
      "train loss:0.027744236747\n",
      "train loss:0.0578419535997\n",
      "train loss:0.0322573535301\n",
      "train loss:0.0180542753193\n",
      "train loss:0.0311440898484\n",
      "train loss:0.0195887235809\n",
      "train loss:0.00635183536803\n",
      "train loss:0.0238087358912\n",
      "train loss:0.0252251184226\n",
      "train loss:0.0638873618281\n",
      "train loss:0.0090578198686\n",
      "train loss:0.0659694355182\n",
      "train loss:0.0426749514804\n",
      "train loss:0.0588654285357\n",
      "train loss:0.0394005864814\n",
      "train loss:0.037175421958\n",
      "train loss:0.06937287739\n",
      "train loss:0.037814806246\n",
      "train loss:0.0307640380782\n",
      "train loss:0.0626860256999\n",
      "train loss:0.0169017706222\n",
      "train loss:0.0430488542575\n",
      "train loss:0.105831147053\n",
      "train loss:0.0785183686261\n",
      "train loss:0.0067677404488\n",
      "train loss:0.0248878782144\n",
      "train loss:0.0150966892389\n",
      "train loss:0.0111373923851\n",
      "train loss:0.024842081084\n",
      "train loss:0.036520113531\n",
      "train loss:0.0921377926969\n",
      "train loss:0.0692989377406\n",
      "train loss:0.0192513406065\n",
      "train loss:0.0133145797612\n",
      "train loss:0.117435998569\n",
      "train loss:0.0233682470777\n",
      "train loss:0.0381107885043\n",
      "train loss:0.0362028787907\n",
      "train loss:0.0569399397477\n",
      "train loss:0.0164591296203\n",
      "train loss:0.0317649678077\n",
      "train loss:0.0493838924622\n",
      "train loss:0.0486756292736\n",
      "train loss:0.016033894353\n",
      "train loss:0.0534860234298\n",
      "train loss:0.0117908912172\n",
      "train loss:0.0475711090591\n",
      "train loss:0.10257257577\n",
      "train loss:0.0506763552617\n",
      "train loss:0.0912495528896\n",
      "train loss:0.0289580425267\n",
      "train loss:0.0564553100637\n",
      "train loss:0.0433653522258\n",
      "train loss:0.0161137480283\n",
      "train loss:0.0116109108982\n",
      "train loss:0.0381990747464\n",
      "train loss:0.0653212741597\n",
      "train loss:0.0301199663672\n",
      "train loss:0.034842040282\n",
      "train loss:0.0195295633374\n",
      "train loss:0.0257338937038\n",
      "train loss:0.0394576816203\n",
      "train loss:0.102860600405\n",
      "train loss:0.109065258611\n",
      "train loss:0.0149343386973\n",
      "train loss:0.02176974462\n",
      "train loss:0.0483458298239\n",
      "train loss:0.035890229571\n",
      "train loss:0.015953337041\n",
      "train loss:0.0296565638448\n",
      "train loss:0.0408707492273\n",
      "train loss:0.0144752309307\n",
      "train loss:0.0304911308769\n",
      "train loss:0.119733718783\n",
      "train loss:0.0216689792319\n",
      "train loss:0.0134663915057\n",
      "train loss:0.0309210865923\n",
      "train loss:0.0159482133949\n",
      "train loss:0.010731857168\n",
      "train loss:0.0160635980587\n",
      "train loss:0.0576000857909\n",
      "train loss:0.0598167429349\n",
      "train loss:0.00724196616983\n",
      "train loss:0.0712506012282\n",
      "train loss:0.037705735963\n",
      "train loss:0.066295242279\n",
      "train loss:0.0634000411911\n",
      "train loss:0.0909371057338\n",
      "train loss:0.0251560850294\n",
      "train loss:0.0488570628629\n",
      "train loss:0.0327753897447\n",
      "train loss:0.0465178162803\n",
      "train loss:0.0286297945057\n",
      "train loss:0.0505569470992\n",
      "train loss:0.0107037653317\n",
      "train loss:0.0119429870444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.147012067458\n",
      "train loss:0.0245708544539\n",
      "train loss:0.0808429730517\n",
      "train loss:0.057782389831\n",
      "train loss:0.0199260208214\n",
      "train loss:0.0441799994596\n",
      "train loss:0.0485863019933\n",
      "train loss:0.0563287715413\n",
      "train loss:0.0578160826426\n",
      "train loss:0.0756314388476\n",
      "train loss:0.02853989614\n",
      "train loss:0.00466229915471\n",
      "train loss:0.00605279395564\n",
      "train loss:0.0168096930206\n",
      "train loss:0.0623481776987\n",
      "train loss:0.0115275649312\n",
      "train loss:0.0576571172627\n",
      "train loss:0.011097131531\n",
      "train loss:0.0113433948907\n",
      "train loss:0.083461414993\n",
      "train loss:0.024640242252\n",
      "train loss:0.0632629693532\n",
      "train loss:0.0105552184707\n",
      "train loss:0.0329402143712\n",
      "train loss:0.0398028245961\n",
      "train loss:0.0113936950738\n",
      "train loss:0.0126285218136\n",
      "train loss:0.0281396370421\n",
      "train loss:0.0175044445751\n",
      "train loss:0.0132314392423\n",
      "train loss:0.0304900462466\n",
      "train loss:0.0235161452912\n",
      "train loss:0.0273546524768\n",
      "train loss:0.00950789807327\n",
      "train loss:0.0316044056371\n",
      "train loss:0.0343780084996\n",
      "train loss:0.00529379154456\n",
      "train loss:0.0424628378152\n",
      "train loss:0.0705316297506\n",
      "train loss:0.0440812749879\n",
      "train loss:0.192187178205\n",
      "train loss:0.00766989981383\n",
      "train loss:0.0200408375861\n",
      "train loss:0.0587112390785\n",
      "train loss:0.0269440076015\n",
      "train loss:0.0110989237424\n",
      "train loss:0.0399904878035\n",
      "train loss:0.0172029673195\n",
      "train loss:0.0118305940692\n",
      "train loss:0.0108293590737\n",
      "train loss:0.015945370662\n",
      "train loss:0.0108581266248\n",
      "train loss:0.0342869308835\n",
      "train loss:0.0253984562931\n",
      "train loss:0.0216739759456\n",
      "train loss:0.00491791967393\n",
      "train loss:0.01412203535\n",
      "train loss:0.027093653209\n",
      "train loss:0.0534690449724\n",
      "train loss:0.0305461738321\n",
      "train loss:0.0526617561815\n",
      "train loss:0.0683096360828\n",
      "train loss:0.0230585811089\n",
      "train loss:0.0179109152992\n",
      "train loss:0.0161846034945\n",
      "train loss:0.018457003236\n",
      "train loss:0.0520929377269\n",
      "train loss:0.128407682907\n",
      "train loss:0.0223374620399\n",
      "train loss:0.0456724835458\n",
      "train loss:0.0209709661168\n",
      "train loss:0.0173193343276\n",
      "train loss:0.0191462735056\n",
      "train loss:0.00968701091855\n",
      "train loss:0.0136078712012\n",
      "train loss:0.0101365615826\n",
      "train loss:0.0113270018857\n",
      "train loss:0.059703746525\n",
      "train loss:0.0141431258329\n",
      "train loss:0.0451822583192\n",
      "train loss:0.0443267411816\n",
      "train loss:0.0144038489596\n",
      "train loss:0.0214380923541\n",
      "train loss:0.0278760406174\n",
      "train loss:0.0114877461586\n",
      "train loss:0.0773955623937\n",
      "train loss:0.0112753695065\n",
      "train loss:0.0189920218099\n",
      "train loss:0.0175245621428\n",
      "train loss:0.0505539005319\n",
      "train loss:0.0304787901477\n",
      "train loss:0.0411600360315\n",
      "train loss:0.0153814500173\n",
      "train loss:0.00742800192219\n",
      "train loss:0.0500639407306\n",
      "train loss:0.0242421828542\n",
      "train loss:0.0158270908159\n",
      "train loss:0.0450091605674\n",
      "train loss:0.0578103715993\n",
      "train loss:0.0460888545687\n",
      "train loss:0.0218516020568\n",
      "train loss:0.00934037044973\n",
      "train loss:0.0501996969956\n",
      "train loss:0.005980527371\n",
      "train loss:0.0114370471145\n",
      "train loss:0.0264097644447\n",
      "train loss:0.0725564269323\n",
      "train loss:0.0481084780525\n",
      "train loss:0.0128883439123\n",
      "train loss:0.0549510590735\n",
      "train loss:0.0433022294401\n",
      "train loss:0.00937797253008\n",
      "train loss:0.0107741713906\n",
      "train loss:0.0230667700627\n",
      "train loss:0.0368974184732\n",
      "train loss:0.0413076896595\n",
      "train loss:0.0208792811671\n",
      "train loss:0.0365235324581\n",
      "train loss:0.018198439201\n",
      "train loss:0.00616091729419\n",
      "train loss:0.00689845185078\n",
      "train loss:0.0246366331431\n",
      "train loss:0.0699637993493\n",
      "train loss:0.0184429930212\n",
      "train loss:0.0325297651577\n",
      "train loss:0.0134336845334\n",
      "train loss:0.012116675254\n",
      "train loss:0.0220001719493\n",
      "train loss:0.0165903334243\n",
      "train loss:0.0540366944752\n",
      "train loss:0.0464591019187\n",
      "train loss:0.0561322076543\n",
      "train loss:0.0499553297225\n",
      "train loss:0.0447893246988\n",
      "train loss:0.0147882526019\n",
      "train loss:0.0105553205606\n",
      "train loss:0.0143204753088\n",
      "train loss:0.00432111263983\n",
      "train loss:0.0237919121013\n",
      "train loss:0.00966200690285\n",
      "train loss:0.0664939250029\n",
      "train loss:0.0531872337601\n",
      "train loss:0.0177180580527\n",
      "train loss:0.0471389177208\n",
      "train loss:0.0159372808872\n",
      "train loss:0.0336222092119\n",
      "train loss:0.0297274373154\n",
      "train loss:0.0103285824997\n",
      "train loss:0.0141317332084\n",
      "train loss:0.0116800416134\n",
      "train loss:0.0107394490262\n",
      "train loss:0.0200183878391\n",
      "train loss:0.0157632762093\n",
      "train loss:0.00672745450078\n",
      "train loss:0.0149832854678\n",
      "train loss:0.0229816573056\n",
      "train loss:0.01274156607\n",
      "train loss:0.0156191654125\n",
      "train loss:0.00655174663572\n",
      "train loss:0.0181898072551\n",
      "train loss:0.0439333871514\n",
      "train loss:0.0890644092622\n",
      "train loss:0.0450845970047\n",
      "train loss:0.0364466105697\n",
      "train loss:0.0571261827531\n",
      "train loss:0.0231401945492\n",
      "train loss:0.0650045209361\n",
      "train loss:0.0238798434888\n",
      "train loss:0.0849501030547\n",
      "train loss:0.0424463520746\n",
      "train loss:0.041552720661\n",
      "train loss:0.019841387853\n",
      "train loss:0.0101702816508\n",
      "train loss:0.0193008259921\n",
      "train loss:0.0782469046003\n",
      "train loss:0.0283196532321\n",
      "train loss:0.0394886834155\n",
      "train loss:0.0200278374941\n",
      "train loss:0.0225502194606\n",
      "train loss:0.0517218399081\n",
      "train loss:0.0174679643889\n",
      "train loss:0.0450095073703\n",
      "train loss:0.00808850378138\n",
      "train loss:0.0172310701374\n",
      "train loss:0.0345523555951\n",
      "train loss:0.00427861423527\n",
      "train loss:0.0305759239183\n",
      "train loss:0.037009562415\n",
      "train loss:0.00764158572929\n",
      "train loss:0.0118241434284\n",
      "train loss:0.0203569828646\n",
      "train loss:0.0769888981972\n",
      "train loss:0.022427831416\n",
      "train loss:0.0193126826384\n",
      "train loss:0.00875462925243\n",
      "train loss:0.0126395973119\n",
      "train loss:0.0300105210234\n",
      "train loss:0.00858924090345\n",
      "train loss:0.0307821062435\n",
      "train loss:0.00909397433092\n",
      "train loss:0.0328385252645\n",
      "train loss:0.0119954962079\n",
      "train loss:0.106076867713\n",
      "train loss:0.00854812229446\n",
      "train loss:0.0124213383367\n",
      "train loss:0.0234930392838\n",
      "train loss:0.0299927903593\n",
      "train loss:0.0373602044465\n",
      "train loss:0.0631407460577\n",
      "train loss:0.0126099658378\n",
      "train loss:0.0440113868378\n",
      "train loss:0.0801946463327\n",
      "train loss:0.00450545731938\n",
      "train loss:0.0335550079588\n",
      "train loss:0.119466028994\n",
      "train loss:0.0113522413552\n",
      "train loss:0.0972253647576\n",
      "train loss:0.00794270037768\n",
      "train loss:0.0281467695666\n",
      "train loss:0.0154724940576\n",
      "train loss:0.0217636300911\n",
      "train loss:0.0286942814204\n",
      "train loss:0.0535324238921\n",
      "train loss:0.0147171772878\n",
      "train loss:0.0345772585277\n",
      "train loss:0.0197610310749\n",
      "train loss:0.0366601801208\n",
      "train loss:0.0663161130343\n",
      "train loss:0.0339996880075\n",
      "train loss:0.0115404745325\n",
      "train loss:0.210081444399\n",
      "train loss:0.0682011473188\n",
      "train loss:0.0238758540911\n",
      "train loss:0.026319719326\n",
      "train loss:0.0567107274263\n",
      "train loss:0.0342385162983\n",
      "train loss:0.00776837180383\n",
      "train loss:0.0498348483178\n",
      "train loss:0.0236585780142\n",
      "train loss:0.0370135143207\n",
      "=== epoch:5, train acc:0.982, test acc:0.983 ===\n",
      "train loss:0.0135858911032\n",
      "train loss:0.0526393345772\n",
      "train loss:0.0195248822198\n",
      "train loss:0.0160832780331\n",
      "train loss:0.0229024564753\n",
      "train loss:0.0283572587345\n",
      "train loss:0.0490196950629\n",
      "train loss:0.0330532980728\n",
      "train loss:0.0331206087451\n",
      "train loss:0.0371147473284\n",
      "train loss:0.00453899404139\n",
      "train loss:0.0214750993112\n",
      "train loss:0.0161791285054\n",
      "train loss:0.0347349401121\n",
      "train loss:0.017011341321\n",
      "train loss:0.0211744956577\n",
      "train loss:0.0879539629602\n",
      "train loss:0.0315493521561\n",
      "train loss:0.0205597357702\n",
      "train loss:0.0525056950279\n",
      "train loss:0.0251262225092\n",
      "train loss:0.120947434313\n",
      "train loss:0.0586873431249\n",
      "train loss:0.0300475299584\n",
      "train loss:0.0188241584013\n",
      "train loss:0.0328355796257\n",
      "train loss:0.0317827555066\n",
      "train loss:0.00741981471692\n",
      "train loss:0.00966016138609\n",
      "train loss:0.00956693000736\n",
      "train loss:0.0312986687569\n",
      "train loss:0.0199858481856\n",
      "train loss:0.0355818890112\n",
      "train loss:0.0165406563505\n",
      "train loss:0.0269107787653\n",
      "train loss:0.0314431720322\n",
      "train loss:0.0447469138291\n",
      "train loss:0.0697226227916\n",
      "train loss:0.0138201708059\n",
      "train loss:0.0200320312878\n",
      "train loss:0.041115788598\n",
      "train loss:0.00656338253276\n",
      "train loss:0.0087559338823\n",
      "train loss:0.0554952969188\n",
      "train loss:0.0134350135311\n",
      "train loss:0.00827229141846\n",
      "train loss:0.0134590897494\n",
      "train loss:0.0327305666749\n",
      "train loss:0.0472602182556\n",
      "train loss:0.00965975019873\n",
      "train loss:0.014287564385\n",
      "train loss:0.0233301852862\n",
      "train loss:0.043631897512\n",
      "train loss:0.0165413904868\n",
      "train loss:0.0381474327713\n",
      "train loss:0.0865502375636\n",
      "train loss:0.0369975742042\n",
      "train loss:0.0162504156743\n",
      "train loss:0.00202378228157\n",
      "train loss:0.021609693289\n",
      "train loss:0.00803011631585\n",
      "train loss:0.0197311067174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00877550652035\n",
      "train loss:0.0391211805845\n",
      "train loss:0.0210646800354\n",
      "train loss:0.0270357874355\n",
      "train loss:0.0128878953928\n",
      "train loss:0.0297283815014\n",
      "train loss:0.031045973719\n",
      "train loss:0.0119290168124\n",
      "train loss:0.019214335237\n",
      "train loss:0.0505166666984\n",
      "train loss:0.0286139937895\n",
      "train loss:0.0136930976922\n",
      "train loss:0.0176412644874\n",
      "train loss:0.0283310606862\n",
      "train loss:0.00772584133046\n",
      "train loss:0.0200788778828\n",
      "train loss:0.015717191304\n",
      "train loss:0.0334036956909\n",
      "train loss:0.0121638886162\n",
      "train loss:0.00163418098004\n",
      "train loss:0.031330788869\n",
      "train loss:0.0239782228421\n",
      "train loss:0.0171111456645\n",
      "train loss:0.0214513443186\n",
      "train loss:0.0102410489574\n",
      "train loss:0.0249243134975\n",
      "train loss:0.00481097243543\n",
      "train loss:0.0638947951491\n",
      "train loss:0.0557597364766\n",
      "train loss:0.0615439448492\n",
      "train loss:0.00525830994346\n",
      "train loss:0.0431774916384\n",
      "train loss:0.0102141820839\n",
      "train loss:0.00558985962199\n",
      "train loss:0.0138869075197\n",
      "train loss:0.0142210350227\n",
      "train loss:0.0630513498951\n",
      "train loss:0.047045837878\n",
      "train loss:0.0197891770778\n",
      "train loss:0.0179299112999\n",
      "train loss:0.00882416617543\n",
      "train loss:0.00831830293857\n",
      "train loss:0.00348300801427\n",
      "train loss:0.0216515727495\n",
      "train loss:0.0110271308206\n",
      "train loss:0.0933170634157\n",
      "train loss:0.00876782194287\n",
      "train loss:0.0194521117979\n",
      "train loss:0.0903759367397\n",
      "train loss:0.0414306254151\n",
      "train loss:0.0271195670499\n",
      "train loss:0.010355526818\n",
      "train loss:0.0202815791372\n",
      "train loss:0.013650769238\n",
      "train loss:0.0169616321262\n",
      "train loss:0.0509053404815\n",
      "train loss:0.0282583176867\n",
      "train loss:0.0473895104816\n",
      "train loss:0.0560376574271\n",
      "train loss:0.0096822048013\n",
      "train loss:0.0403109122696\n",
      "train loss:0.00570300970876\n",
      "train loss:0.0169749238965\n",
      "train loss:0.0362217561456\n",
      "train loss:0.0188707013193\n",
      "train loss:0.0725538533679\n",
      "train loss:0.0445980670441\n",
      "train loss:0.0154458408498\n",
      "train loss:0.0160468694381\n",
      "train loss:0.0336553308878\n",
      "train loss:0.0198248042335\n",
      "train loss:0.0173509509271\n",
      "train loss:0.0107419123142\n",
      "train loss:0.0160490360674\n",
      "train loss:0.0300412432747\n",
      "train loss:0.00376840940864\n",
      "train loss:0.00826753141834\n",
      "train loss:0.0297994734395\n",
      "train loss:0.0580931406424\n",
      "train loss:0.124811445293\n",
      "train loss:0.144328032939\n",
      "train loss:0.0500919838402\n",
      "train loss:0.0388131806424\n",
      "train loss:0.00661105425654\n",
      "train loss:0.0402832339236\n",
      "train loss:0.010490843736\n",
      "train loss:0.0342492158855\n",
      "train loss:0.0642968608508\n",
      "train loss:0.034923227034\n",
      "train loss:0.0373977330593\n",
      "train loss:0.0966796416743\n",
      "train loss:0.0466043591281\n",
      "train loss:0.0565222595504\n",
      "train loss:0.0146634143967\n",
      "train loss:0.0574564103341\n",
      "train loss:0.0895628246818\n",
      "train loss:0.0785049423804\n",
      "train loss:0.00974424435286\n",
      "train loss:0.0619093115099\n",
      "train loss:0.024862318499\n",
      "train loss:0.0396878775608\n",
      "train loss:0.0635320865862\n",
      "train loss:0.00599721109117\n",
      "train loss:0.0246659726317\n",
      "train loss:0.0917540074568\n",
      "train loss:0.0149780647378\n",
      "train loss:0.0374712519428\n",
      "train loss:0.0656116920489\n",
      "train loss:0.0438036345794\n",
      "train loss:0.0271951947837\n",
      "train loss:0.0283585425386\n",
      "train loss:0.0140627842237\n",
      "train loss:0.0324788174542\n",
      "train loss:0.0275080368921\n",
      "train loss:0.00823198138386\n",
      "train loss:0.00653220519293\n",
      "train loss:0.0452181052756\n",
      "train loss:0.0238413955901\n",
      "train loss:0.0242595042861\n",
      "train loss:0.0789740428316\n",
      "train loss:0.0537093395451\n",
      "train loss:0.0399483753723\n",
      "train loss:0.0473064275014\n",
      "train loss:0.0420301374131\n",
      "train loss:0.00877372036739\n",
      "train loss:0.016544586489\n",
      "train loss:0.00747063410444\n",
      "train loss:0.00797516338285\n",
      "train loss:0.0438338400035\n",
      "train loss:0.131161268513\n",
      "train loss:0.0217251395897\n",
      "train loss:0.0165295238734\n",
      "train loss:0.0370589454338\n",
      "train loss:0.0406084498045\n",
      "train loss:0.0118661831253\n",
      "train loss:0.0483580375231\n",
      "train loss:0.0191145367932\n",
      "train loss:0.0190771098965\n",
      "train loss:0.00990189200037\n",
      "train loss:0.0466576470455\n",
      "train loss:0.0408709460106\n",
      "train loss:0.0682660044938\n",
      "train loss:0.0251173252548\n",
      "train loss:0.00972175999292\n",
      "train loss:0.0250120538485\n",
      "train loss:0.0210003630952\n",
      "train loss:0.0423680802707\n",
      "train loss:0.020876193179\n",
      "train loss:0.0156737539436\n",
      "train loss:0.0366990487169\n",
      "train loss:0.00826723139566\n",
      "train loss:0.00912549983126\n",
      "train loss:0.0129627114723\n",
      "train loss:0.00639140944463\n",
      "train loss:0.00932191248046\n",
      "train loss:0.0295578152485\n",
      "train loss:0.0453899156581\n",
      "train loss:0.0334468725435\n",
      "train loss:0.0277975164678\n",
      "train loss:0.0131334980813\n",
      "train loss:0.0109169140447\n",
      "train loss:0.0340596652889\n",
      "train loss:0.112910275251\n",
      "train loss:0.0166925546574\n",
      "train loss:0.0224041334086\n",
      "train loss:0.00514935721681\n",
      "train loss:0.0418885882646\n",
      "train loss:0.0204078590062\n",
      "train loss:0.0491691178285\n",
      "train loss:0.0968350364653\n",
      "train loss:0.0393009918776\n",
      "train loss:0.0164371755026\n",
      "train loss:0.0169246828556\n",
      "train loss:0.0188309007164\n",
      "train loss:0.0239336216618\n",
      "train loss:0.00666757703371\n",
      "train loss:0.0679914270696\n",
      "train loss:0.014000675106\n",
      "train loss:0.0704812093105\n",
      "train loss:0.0362145716897\n",
      "train loss:0.0289253533119\n",
      "train loss:0.013507149721\n",
      "train loss:0.0069511429781\n",
      "train loss:0.0262321060269\n",
      "train loss:0.0242513311637\n",
      "train loss:0.0373747206854\n",
      "train loss:0.11217471396\n",
      "train loss:0.0250724212369\n",
      "train loss:0.0287595845511\n",
      "train loss:0.0154797956384\n",
      "train loss:0.0206394685928\n",
      "train loss:0.00631060309165\n",
      "train loss:0.0271815246876\n",
      "train loss:0.0326773649218\n",
      "train loss:0.0283785532573\n",
      "train loss:0.0514352359403\n",
      "train loss:0.0160228017436\n",
      "train loss:0.0387849270056\n",
      "train loss:0.0260297466669\n",
      "train loss:0.00933183700749\n",
      "train loss:0.0388613605482\n",
      "train loss:0.025550986175\n",
      "train loss:0.0971794589176\n",
      "train loss:0.00729892384266\n",
      "train loss:0.0614939805624\n",
      "train loss:0.00808475367507\n",
      "train loss:0.0310799912035\n",
      "train loss:0.0418967921307\n",
      "train loss:0.0104701544933\n",
      "train loss:0.0528634562477\n",
      "train loss:0.0591341101473\n",
      "train loss:0.0177708836159\n",
      "train loss:0.00887930852649\n",
      "train loss:0.0808492177403\n",
      "train loss:0.171147419146\n",
      "train loss:0.046688200265\n",
      "train loss:0.0113243242233\n",
      "train loss:0.0414011533879\n",
      "train loss:0.0217816848397\n",
      "train loss:0.0651765205813\n",
      "train loss:0.0187979089092\n",
      "train loss:0.0099618827179\n",
      "train loss:0.0343560704786\n",
      "train loss:0.0339821550083\n",
      "train loss:0.0200391761978\n",
      "train loss:0.0162398673537\n",
      "train loss:0.0220868570435\n",
      "train loss:0.133560316643\n",
      "train loss:0.0776872270109\n",
      "train loss:0.0243556870573\n",
      "train loss:0.017238743152\n",
      "train loss:0.018280375684\n",
      "train loss:0.0315312255145\n",
      "train loss:0.156973870192\n",
      "train loss:0.0328840894142\n",
      "train loss:0.017746624932\n",
      "train loss:0.0250417902481\n",
      "train loss:0.0177924543077\n",
      "train loss:0.0413053314017\n",
      "train loss:0.056254849506\n",
      "train loss:0.0203413665489\n",
      "train loss:0.0537201074242\n",
      "train loss:0.0531628815129\n",
      "train loss:0.0132670715125\n",
      "train loss:0.0136949542635\n",
      "train loss:0.030914190083\n",
      "train loss:0.00651660290508\n",
      "train loss:0.0115058773059\n",
      "train loss:0.0206182836857\n",
      "train loss:0.0358990563544\n",
      "train loss:0.0155489013937\n",
      "train loss:0.010071580687\n",
      "train loss:0.0788035916013\n",
      "train loss:0.0175956986211\n",
      "train loss:0.00380159280381\n",
      "train loss:0.00954872792345\n",
      "train loss:0.0294693525612\n",
      "train loss:0.0131966149663\n",
      "train loss:0.0303010362182\n",
      "train loss:0.0164215717253\n",
      "train loss:0.022657842032\n",
      "train loss:0.0150886679254\n",
      "train loss:0.0176882601924\n",
      "train loss:0.0156032096823\n",
      "train loss:0.0249151841481\n",
      "train loss:0.0390367598577\n",
      "train loss:0.00660783063785\n",
      "train loss:0.0105688519869\n",
      "train loss:0.0145496723678\n",
      "train loss:0.00955733593767\n",
      "train loss:0.00570904020925\n",
      "train loss:0.012783782971\n",
      "train loss:0.0161603220554\n",
      "train loss:0.0076945878409\n",
      "train loss:0.00315642690366\n",
      "train loss:0.132312136526\n",
      "train loss:0.017987520458\n",
      "train loss:0.0279172951275\n",
      "train loss:0.029154253707\n",
      "train loss:0.0397634583257\n",
      "train loss:0.0440860440864\n",
      "train loss:0.00336475453385\n",
      "train loss:0.0887011720535\n",
      "train loss:0.0727807334173\n",
      "train loss:0.0287102505447\n",
      "train loss:0.00948242808446\n",
      "train loss:0.0202308067483\n",
      "train loss:0.0251373975987\n",
      "train loss:0.0412957800414\n",
      "train loss:0.00961133612951\n",
      "train loss:0.00957432231893\n",
      "train loss:0.0104343543943\n",
      "train loss:0.0280931179029\n",
      "train loss:0.00779444648404\n",
      "train loss:0.0122881135439\n",
      "train loss:0.0200129385859\n",
      "train loss:0.0219747009072\n",
      "train loss:0.00457869458294\n",
      "train loss:0.019307092021\n",
      "train loss:0.00636556680449\n",
      "train loss:0.0275072937626\n",
      "train loss:0.0295325001631\n",
      "train loss:0.0396861476113\n",
      "train loss:0.0234010585594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0165921535446\n",
      "train loss:0.00457625040304\n",
      "train loss:0.00384097918399\n",
      "train loss:0.0192887256153\n",
      "train loss:0.00989261731984\n",
      "train loss:0.043404601668\n",
      "train loss:0.0221650650586\n",
      "train loss:0.0229054222017\n",
      "train loss:0.0691196878094\n",
      "train loss:0.0245092546716\n",
      "train loss:0.00185666579381\n",
      "train loss:0.0166197562809\n",
      "train loss:0.0420696178969\n",
      "train loss:0.016641205447\n",
      "train loss:0.0615564039837\n",
      "train loss:0.0187218957476\n",
      "train loss:0.0200744023297\n",
      "train loss:0.0581813897118\n",
      "train loss:0.0189127073354\n",
      "train loss:0.0361622484942\n",
      "train loss:0.011299040338\n",
      "train loss:0.0216422864045\n",
      "train loss:0.0239131846826\n",
      "train loss:0.0064607027401\n",
      "train loss:0.0299845533816\n",
      "train loss:0.00822789220501\n",
      "train loss:0.0228974960981\n",
      "train loss:0.0138201778244\n",
      "train loss:0.00616503742814\n",
      "train loss:0.0162192968172\n",
      "train loss:0.0197434238159\n",
      "train loss:0.0286389972712\n",
      "train loss:0.0264591387066\n",
      "train loss:0.0050715342818\n",
      "train loss:0.0473825894068\n",
      "train loss:0.0175761743574\n",
      "train loss:0.0187617549985\n",
      "train loss:0.0193801279044\n",
      "train loss:0.0353056594286\n",
      "train loss:0.0231592518296\n",
      "train loss:0.0175259428198\n",
      "train loss:0.0323507094539\n",
      "train loss:0.0228970596304\n",
      "train loss:0.0232668643057\n",
      "train loss:0.00507568939851\n",
      "train loss:0.0584197159232\n",
      "train loss:0.0254226430447\n",
      "train loss:0.00687567458504\n",
      "train loss:0.00465216722831\n",
      "train loss:0.0239971737506\n",
      "train loss:0.00787977337264\n",
      "train loss:0.0106125409232\n",
      "train loss:0.0195623443472\n",
      "train loss:0.0251037143297\n",
      "train loss:0.0671852226888\n",
      "train loss:0.0703294792061\n",
      "train loss:0.0186416976997\n",
      "train loss:0.0428185963701\n",
      "train loss:0.00279421752713\n",
      "train loss:0.0283164310988\n",
      "train loss:0.0202805231442\n",
      "train loss:0.0607270630131\n",
      "train loss:0.0156321448394\n",
      "train loss:0.0179304178488\n",
      "train loss:0.00806959227294\n",
      "train loss:0.0158285094947\n",
      "train loss:0.00369264804223\n",
      "train loss:0.0818766538697\n",
      "train loss:0.0374024085641\n",
      "train loss:0.0547952595834\n",
      "train loss:0.0218545352649\n",
      "train loss:0.0115842689163\n",
      "train loss:0.00520126998132\n",
      "train loss:0.0193302133577\n",
      "train loss:0.0278146016792\n",
      "train loss:0.0289253680565\n",
      "train loss:0.0323357726705\n",
      "train loss:0.00585559168115\n",
      "train loss:0.00772520423549\n",
      "train loss:0.0151921705476\n",
      "train loss:0.0519969976351\n",
      "train loss:0.0179818388889\n",
      "train loss:0.0209497935436\n",
      "train loss:0.0136166940754\n",
      "train loss:0.0395637692445\n",
      "train loss:0.0363252158093\n",
      "train loss:0.0243753892924\n",
      "train loss:0.0229246772377\n",
      "train loss:0.00807529761\n",
      "train loss:0.0246605027958\n",
      "train loss:0.031758349183\n",
      "train loss:0.0535395558685\n",
      "train loss:0.0289004508627\n",
      "train loss:0.00699124011727\n",
      "train loss:0.0165074096611\n",
      "train loss:0.0119831362416\n",
      "train loss:0.0140465245864\n",
      "train loss:0.00514588073016\n",
      "train loss:0.0490752748465\n",
      "train loss:0.00516258001622\n",
      "train loss:0.00533002181416\n",
      "train loss:0.0266418955304\n",
      "train loss:0.0214786499389\n",
      "train loss:0.0144965755743\n",
      "train loss:0.00937714853825\n",
      "train loss:0.0129094527357\n",
      "train loss:0.0376309653607\n",
      "train loss:0.0846562006766\n",
      "train loss:0.0336126310475\n",
      "train loss:0.0169220325314\n",
      "train loss:0.0180886846898\n",
      "train loss:0.00406947082245\n",
      "train loss:0.0112062419611\n",
      "train loss:0.00921583523156\n",
      "train loss:0.101489138681\n",
      "train loss:0.0420563466764\n",
      "train loss:0.010528262709\n",
      "train loss:0.0096148480996\n",
      "train loss:0.00353875109745\n",
      "train loss:0.0120809192812\n",
      "train loss:0.0164534795902\n",
      "train loss:0.0234631643647\n",
      "train loss:0.00458313503449\n",
      "train loss:0.00994317193472\n",
      "train loss:0.00657900764661\n",
      "train loss:0.0112226852275\n",
      "train loss:0.00992322324569\n",
      "train loss:0.0384832915464\n",
      "train loss:0.0272214803347\n",
      "train loss:0.0386579765477\n",
      "train loss:0.022174568401\n",
      "train loss:0.013032187868\n",
      "train loss:0.0229837841912\n",
      "train loss:0.094595267362\n",
      "train loss:0.00845191490651\n",
      "train loss:0.00860261295181\n",
      "train loss:0.0199313236613\n",
      "train loss:0.011637177831\n",
      "train loss:0.074150896605\n",
      "train loss:0.0606442603619\n",
      "train loss:0.0285015611909\n",
      "train loss:0.0741402233371\n",
      "train loss:0.0362545705086\n",
      "train loss:0.0204732850274\n",
      "train loss:0.0312690086009\n",
      "train loss:0.0613416913641\n",
      "train loss:0.0113568483725\n",
      "train loss:0.0235053675882\n",
      "train loss:0.0407009589042\n",
      "train loss:0.0365682652952\n",
      "train loss:0.011562315838\n",
      "train loss:0.0177563774386\n",
      "train loss:0.0155821462217\n",
      "train loss:0.0324718896468\n",
      "train loss:0.0155804670378\n",
      "train loss:0.0229191256605\n",
      "train loss:0.01745027192\n",
      "train loss:0.0115955574281\n",
      "train loss:0.0145034342938\n",
      "train loss:0.0104479238378\n",
      "train loss:0.0411581027635\n",
      "train loss:0.0747526166545\n",
      "train loss:0.00761920306384\n",
      "train loss:0.0453020484904\n",
      "train loss:0.00654030863209\n",
      "train loss:0.00930198139846\n",
      "train loss:0.0226370134072\n",
      "train loss:0.02901978657\n",
      "train loss:0.00848525656427\n",
      "train loss:0.0180764762243\n",
      "train loss:0.00936115142752\n",
      "train loss:0.0105783335321\n",
      "train loss:0.0119161936799\n",
      "train loss:0.0164104479754\n",
      "train loss:0.00509167478203\n",
      "train loss:0.0113883879131\n",
      "train loss:0.00979216862329\n",
      "train loss:0.0134503547492\n",
      "train loss:0.0071014124307\n",
      "train loss:0.00807677656104\n",
      "train loss:0.00758517759136\n",
      "train loss:0.0269278691803\n",
      "train loss:0.0496762613164\n",
      "train loss:0.0326288337139\n",
      "train loss:0.0247008391748\n",
      "train loss:0.0182369109688\n",
      "train loss:0.0567768564314\n",
      "train loss:0.0214554885592\n",
      "train loss:0.0224735114105\n",
      "train loss:0.0143850334484\n",
      "train loss:0.0173558512196\n",
      "train loss:0.0117102230699\n",
      "train loss:0.0174219773619\n",
      "train loss:0.0275897609964\n",
      "train loss:0.0093623993526\n",
      "train loss:0.00228798415044\n",
      "train loss:0.0366834732292\n",
      "train loss:0.0219081942237\n",
      "train loss:0.0220827985002\n",
      "train loss:0.00431737186313\n",
      "train loss:0.00608172326954\n",
      "train loss:0.0148105254426\n",
      "train loss:0.0184225165353\n",
      "train loss:0.0186588060957\n",
      "train loss:0.0138666723263\n",
      "train loss:0.0177873246709\n",
      "train loss:0.00386501979837\n",
      "train loss:0.0354903175199\n",
      "train loss:0.00996985148819\n",
      "train loss:0.0131467231103\n",
      "train loss:0.0362210662408\n",
      "train loss:0.0142622358173\n",
      "train loss:0.00613070314681\n",
      "train loss:0.0720323753554\n",
      "train loss:0.0265848629346\n",
      "train loss:0.0270080789755\n",
      "train loss:0.0139991029797\n",
      "train loss:0.0100860375088\n",
      "train loss:0.0551548889754\n",
      "train loss:0.0704040662919\n",
      "train loss:0.00589278238823\n",
      "train loss:0.0380144751329\n",
      "train loss:0.0467280309561\n",
      "train loss:0.0419377994624\n",
      "train loss:0.0827568909585\n",
      "train loss:0.036962665471\n",
      "train loss:0.00455038230859\n",
      "train loss:0.0161580242795\n",
      "train loss:0.00635825494361\n",
      "train loss:0.0179664738809\n",
      "train loss:0.00881583589704\n",
      "train loss:0.0194062653825\n",
      "train loss:0.0176479420388\n",
      "train loss:0.0395660369109\n",
      "=== epoch:6, train acc:0.987, test acc:0.98 ===\n",
      "train loss:0.0240792259192\n",
      "train loss:0.0217507204714\n",
      "train loss:0.0162568900078\n",
      "train loss:0.00782800580578\n",
      "train loss:0.0457725237992\n",
      "train loss:0.0096869856284\n",
      "train loss:0.00587093275655\n",
      "train loss:0.0367692737604\n",
      "train loss:0.00409712638992\n",
      "train loss:0.0495646586506\n",
      "train loss:0.012922661631\n",
      "train loss:0.0112230566326\n",
      "train loss:0.0375349138978\n",
      "train loss:0.0575311428136\n",
      "train loss:0.00850204609445\n",
      "train loss:0.0531475162452\n",
      "train loss:0.0214916876065\n",
      "train loss:0.0156263419794\n",
      "train loss:0.0179922437738\n",
      "train loss:0.0190512784458\n",
      "train loss:0.00818709370497\n",
      "train loss:0.00681951484493\n",
      "train loss:0.00845862717604\n",
      "train loss:0.0074772961842\n",
      "train loss:0.00626199563019\n",
      "train loss:0.00565639031676\n",
      "train loss:0.0117846391197\n",
      "train loss:0.04808112943\n",
      "train loss:0.00711673258694\n",
      "train loss:0.00519180138998\n",
      "train loss:0.00763337899646\n",
      "train loss:0.00995365260464\n",
      "train loss:0.0217510912212\n",
      "train loss:0.0769581122691\n",
      "train loss:0.0254180451078\n",
      "train loss:0.0135238441484\n",
      "train loss:0.0179653961767\n",
      "train loss:0.00716542586789\n",
      "train loss:0.0163003169052\n",
      "train loss:0.0534268293157\n",
      "train loss:0.0128534072406\n",
      "train loss:0.120716897007\n",
      "train loss:0.00761680315621\n",
      "train loss:0.0830595023971\n",
      "train loss:0.00925448600726\n",
      "train loss:0.00769641104333\n",
      "train loss:0.0040996770846\n",
      "train loss:0.0632168330032\n",
      "train loss:0.0425123888788\n",
      "train loss:0.025548729432\n",
      "train loss:0.00757664179386\n",
      "train loss:0.0311067232759\n",
      "train loss:0.0774836991302\n",
      "train loss:0.0483286128392\n",
      "train loss:0.0148949276835\n",
      "train loss:0.00339724679183\n",
      "train loss:0.0306266925539\n",
      "train loss:0.0297151849562\n",
      "train loss:0.0294294822156\n",
      "train loss:0.0476709624949\n",
      "train loss:0.0267138864156\n",
      "train loss:0.0275473937182\n",
      "train loss:0.0404393866901\n",
      "train loss:0.0152054161452\n",
      "train loss:0.0272884095866\n",
      "train loss:0.00352654418452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0254224135565\n",
      "train loss:0.0360718876193\n",
      "train loss:0.0170789634292\n",
      "train loss:0.00968171788952\n",
      "train loss:0.0225426338936\n",
      "train loss:0.011864556051\n",
      "train loss:0.0333653185587\n",
      "train loss:0.0133328281544\n",
      "train loss:0.0292563393667\n",
      "train loss:0.0154489194614\n",
      "train loss:0.0206837351523\n",
      "train loss:0.0152835771408\n",
      "train loss:0.0185109849698\n",
      "train loss:0.00428708610325\n",
      "train loss:0.0277307796383\n",
      "train loss:0.0103523807324\n",
      "train loss:0.0612041507604\n",
      "train loss:0.0327825326134\n",
      "train loss:0.0133146290031\n",
      "train loss:0.0141994646243\n",
      "train loss:0.0150938713931\n",
      "train loss:0.0122072819817\n",
      "train loss:0.00651639512529\n",
      "train loss:0.00633291819073\n",
      "train loss:0.00422401429466\n",
      "train loss:0.0177014790905\n",
      "train loss:0.00442920178361\n",
      "train loss:0.00732471683497\n",
      "train loss:0.0207234263411\n",
      "train loss:0.00642170470959\n",
      "train loss:0.00964221682382\n",
      "train loss:0.00798528081459\n",
      "train loss:0.0195081231147\n",
      "train loss:0.0177677507616\n",
      "train loss:0.0126523699644\n",
      "train loss:0.0814644887758\n",
      "train loss:0.0226172717457\n",
      "train loss:0.0476780721566\n",
      "train loss:0.0472116660721\n",
      "train loss:0.0151182658897\n",
      "train loss:0.022297224811\n",
      "train loss:0.0627100321114\n",
      "train loss:0.00702283800019\n",
      "train loss:0.0183006818133\n",
      "train loss:0.00599703444578\n",
      "train loss:0.0197890910721\n",
      "train loss:0.0315763122053\n",
      "train loss:0.00655079708798\n",
      "train loss:0.00426878586279\n",
      "train loss:0.0091603108859\n",
      "train loss:0.0865838702849\n",
      "train loss:0.0080010481226\n",
      "train loss:0.00351603877361\n",
      "train loss:0.0285519377167\n",
      "train loss:0.00170883335448\n",
      "train loss:0.0183136552163\n",
      "train loss:0.0119161461822\n",
      "train loss:0.00251578450768\n",
      "train loss:0.0106904040128\n",
      "train loss:0.0164498443754\n",
      "train loss:0.0055965695167\n",
      "train loss:0.00753989763101\n",
      "train loss:0.0192594417961\n",
      "train loss:0.101629472302\n",
      "train loss:0.0388196263735\n",
      "train loss:0.00458335210822\n",
      "train loss:0.012270408353\n",
      "train loss:0.0204837030643\n",
      "train loss:0.0821089720503\n",
      "train loss:0.00820461787853\n",
      "train loss:0.0329427787727\n",
      "train loss:0.016610023264\n",
      "train loss:0.0763005681821\n",
      "train loss:0.010466159599\n",
      "train loss:0.00350829638325\n",
      "train loss:0.0156409149873\n",
      "train loss:0.0157853156136\n",
      "train loss:0.0402356024703\n",
      "train loss:0.0280889767265\n",
      "train loss:0.00589812939237\n",
      "train loss:0.0202438585808\n",
      "train loss:0.0676690772822\n",
      "train loss:0.0344669934561\n",
      "train loss:0.0336913454112\n",
      "train loss:0.00934668776399\n",
      "train loss:0.0137589512037\n",
      "train loss:0.0234959795737\n",
      "train loss:0.036404895202\n",
      "train loss:0.00676798529208\n",
      "train loss:0.0110983693442\n",
      "train loss:0.0369216273312\n",
      "train loss:0.0164735752495\n",
      "train loss:0.0251337014904\n",
      "train loss:0.0345610933498\n",
      "train loss:0.00696417826969\n",
      "train loss:0.0129092968106\n",
      "train loss:0.0141825671997\n",
      "train loss:0.00528414216094\n",
      "train loss:0.0105445754435\n",
      "train loss:0.0147293202012\n",
      "train loss:0.016888505527\n",
      "train loss:0.00411834048757\n",
      "train loss:0.016635213668\n",
      "train loss:0.0259894664177\n",
      "train loss:0.0233449579578\n",
      "train loss:0.0431421834781\n",
      "train loss:0.0689294805068\n",
      "train loss:0.0261099038928\n",
      "train loss:0.0108994733869\n",
      "train loss:0.00933815651299\n",
      "train loss:0.00581840387626\n",
      "train loss:0.0299615940133\n",
      "train loss:0.0378167123272\n",
      "train loss:0.0147054867297\n",
      "train loss:0.00778310260502\n",
      "train loss:0.00487487976925\n",
      "train loss:0.0209427779668\n",
      "train loss:0.00355013833305\n",
      "train loss:0.00960603322444\n",
      "train loss:0.00987091596783\n",
      "train loss:0.01583848503\n",
      "train loss:0.01393607816\n",
      "train loss:0.0304447758557\n",
      "train loss:0.0196066978943\n",
      "train loss:0.0163824116029\n",
      "train loss:0.0272790537395\n",
      "train loss:0.0176431174794\n",
      "train loss:0.00913530744187\n",
      "train loss:0.00837658511861\n",
      "train loss:0.0261205482003\n",
      "train loss:0.047990964183\n",
      "train loss:0.00240890879929\n",
      "train loss:0.00868529638458\n",
      "train loss:0.01872780106\n",
      "train loss:0.0230652257381\n",
      "train loss:0.0101735371667\n",
      "train loss:0.019784221154\n",
      "train loss:0.0228552473253\n",
      "train loss:0.00443008921226\n",
      "train loss:0.00480123385943\n",
      "train loss:0.00833515008904\n",
      "train loss:0.0126100627906\n",
      "train loss:0.0284419531637\n",
      "train loss:0.00552798748666\n",
      "train loss:0.0282834962294\n",
      "train loss:0.0232881889414\n",
      "train loss:0.00535635402616\n",
      "train loss:0.0155547857917\n",
      "train loss:0.000684943098109\n",
      "train loss:0.019860175194\n",
      "train loss:0.0138670340363\n",
      "train loss:0.00863427847588\n",
      "train loss:0.0305811673657\n",
      "train loss:0.00499282302489\n",
      "train loss:0.0359804110063\n",
      "train loss:0.00507104926862\n",
      "train loss:0.00744418089151\n",
      "train loss:0.0404252391385\n",
      "train loss:0.0376080772632\n",
      "train loss:0.033268826673\n",
      "train loss:0.0179043209027\n",
      "train loss:0.010326245766\n",
      "train loss:0.0131405962675\n",
      "train loss:0.0313139268818\n",
      "train loss:0.0184748557974\n",
      "train loss:0.0188113012803\n",
      "train loss:0.0364726242489\n",
      "train loss:0.028286303723\n",
      "train loss:0.0399248297664\n",
      "train loss:0.0379440621298\n",
      "train loss:0.0355015314818\n",
      "train loss:0.0110457781483\n",
      "train loss:0.0130381537641\n",
      "train loss:0.0202952111501\n",
      "train loss:0.104688632755\n",
      "train loss:0.00401055359418\n",
      "train loss:0.0197103502\n",
      "train loss:0.150914325031\n",
      "train loss:0.0234491378036\n",
      "train loss:0.0135896513177\n",
      "train loss:0.0280349740362\n",
      "train loss:0.0116179274151\n",
      "train loss:0.00282429711995\n",
      "train loss:0.00927474140184\n",
      "train loss:0.0212565401885\n",
      "train loss:0.0018308495425\n",
      "train loss:0.0120702894782\n",
      "train loss:0.00290222212954\n",
      "train loss:0.0272216814915\n",
      "train loss:0.0290069966166\n",
      "train loss:0.00921161249939\n",
      "train loss:0.0210643920774\n",
      "train loss:0.0787221022124\n",
      "train loss:0.00520824560412\n",
      "train loss:0.0194031056784\n",
      "train loss:0.0141653348886\n",
      "train loss:0.0116895076565\n",
      "train loss:0.00341286958204\n",
      "train loss:0.00323869536622\n",
      "train loss:0.00373873432448\n",
      "train loss:0.0103145770335\n",
      "train loss:0.0021059474519\n",
      "train loss:0.00858527233346\n",
      "train loss:0.0347884865142\n",
      "train loss:0.013887406218\n",
      "train loss:0.0242782881565\n",
      "train loss:0.05451863089\n",
      "train loss:0.00390776200168\n",
      "train loss:0.0295517929569\n",
      "train loss:0.0340646871984\n",
      "train loss:0.0150319021442\n",
      "train loss:0.0103227792159\n",
      "train loss:0.00499463154977\n",
      "train loss:0.00323479442789\n",
      "train loss:0.0290557029396\n",
      "train loss:0.00604442980048\n",
      "train loss:0.0150560509837\n",
      "train loss:0.0317988398771\n",
      "train loss:0.0113581129563\n",
      "train loss:0.0739432618432\n",
      "train loss:0.0154216433405\n",
      "train loss:0.00594695763632\n",
      "train loss:0.0425674119479\n",
      "train loss:0.094880147624\n",
      "train loss:0.0150576242627\n",
      "train loss:0.0111835340177\n",
      "train loss:0.00610419378559\n",
      "train loss:0.00226810748709\n",
      "train loss:0.0998381678259\n",
      "train loss:0.0143248032078\n",
      "train loss:0.0528903901239\n",
      "train loss:0.0228567106694\n",
      "train loss:0.0248650494967\n",
      "train loss:0.00775862389707\n",
      "train loss:0.021139315717\n",
      "train loss:0.0402373612888\n",
      "train loss:0.0253734562901\n",
      "train loss:0.00602018251808\n",
      "train loss:0.0313304155115\n",
      "train loss:0.00885602569985\n",
      "train loss:0.0165981775225\n",
      "train loss:0.00160202952508\n",
      "train loss:0.0294062959283\n",
      "train loss:0.00995601122659\n",
      "train loss:0.0125010142113\n",
      "train loss:0.02644409269\n",
      "train loss:0.00689895951648\n",
      "train loss:0.026912843782\n",
      "train loss:0.0332503315306\n",
      "train loss:0.00487765658631\n",
      "train loss:0.0362377231684\n",
      "train loss:0.00908828113065\n",
      "train loss:0.00863457810056\n",
      "train loss:0.00964169506096\n",
      "train loss:0.00847301164418\n",
      "train loss:0.00666080159783\n",
      "train loss:0.0505330778283\n",
      "train loss:0.00711838370201\n",
      "train loss:0.155481275982\n",
      "train loss:0.0147760098466\n",
      "train loss:0.0262977476033\n",
      "train loss:0.0820660102315\n",
      "train loss:0.010395408161\n",
      "train loss:0.0320934746845\n",
      "train loss:0.00458600841026\n",
      "train loss:0.00394422611528\n",
      "train loss:0.00785808992124\n",
      "train loss:0.0417024763951\n",
      "train loss:0.0114584081304\n",
      "train loss:0.0110722795854\n",
      "train loss:0.00993692218165\n",
      "train loss:0.00947491067042\n",
      "train loss:0.0151707074534\n",
      "train loss:0.0260311043406\n",
      "train loss:0.00151311643858\n",
      "train loss:0.00952780299278\n",
      "train loss:0.0082909720381\n",
      "train loss:0.0787325919631\n",
      "train loss:0.0105361263118\n",
      "train loss:0.0259498395195\n",
      "train loss:0.0244054762396\n",
      "train loss:0.0221893951204\n",
      "train loss:0.00481279418661\n",
      "train loss:0.0464085648292\n",
      "train loss:0.0172741939204\n",
      "train loss:0.0309101058841\n",
      "train loss:0.116041731994\n",
      "train loss:0.13014893622\n",
      "train loss:0.0223133755251\n",
      "train loss:0.00692867197331\n",
      "train loss:0.00950000004212\n",
      "train loss:0.0175431585714\n",
      "train loss:0.0552164835845\n",
      "train loss:0.0203273319117\n",
      "train loss:0.0370520243644\n",
      "train loss:0.0148990537907\n",
      "train loss:0.00374749571124\n",
      "train loss:0.0337003208418\n",
      "train loss:0.0085137118686\n",
      "train loss:0.0243061396679\n",
      "train loss:0.0169466390186\n",
      "train loss:0.015708903661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0144645649701\n",
      "train loss:0.0207065558521\n",
      "train loss:0.010025870013\n",
      "train loss:0.00645815030844\n",
      "train loss:0.021128509847\n",
      "train loss:0.00304528686077\n",
      "train loss:0.0305244352083\n",
      "train loss:0.0615235750137\n",
      "train loss:0.0318181178231\n",
      "train loss:0.0496787890561\n",
      "train loss:0.00633899673802\n",
      "train loss:0.173349449496\n",
      "train loss:0.0119929473214\n",
      "train loss:0.00991011941639\n",
      "train loss:0.0497996296447\n",
      "train loss:0.00555602687862\n",
      "train loss:0.0292644963104\n",
      "train loss:0.0148824198335\n",
      "train loss:0.00384657521779\n",
      "train loss:0.0149104313403\n",
      "train loss:0.0135895452402\n",
      "train loss:0.0103097329017\n",
      "train loss:0.0106255196604\n",
      "train loss:0.0193388530138\n",
      "train loss:0.0706236495479\n",
      "train loss:0.0380932138775\n",
      "train loss:0.0143641993174\n",
      "train loss:0.0483639742998\n",
      "train loss:0.0129642862034\n",
      "train loss:0.0124542791023\n",
      "train loss:0.031513346144\n",
      "train loss:0.0270940685455\n",
      "train loss:0.00413744841267\n",
      "train loss:0.00835231416456\n",
      "train loss:0.0549125154448\n",
      "train loss:0.0552408656041\n",
      "train loss:0.00477966005262\n",
      "train loss:0.0105929048635\n",
      "train loss:0.00358821818399\n",
      "train loss:0.0249749847283\n",
      "train loss:0.0167275089741\n",
      "train loss:0.00780792412574\n",
      "train loss:0.052254088486\n",
      "train loss:0.00440409349062\n",
      "train loss:0.00642516057956\n",
      "train loss:0.0105944313866\n",
      "train loss:0.0140011925921\n",
      "train loss:0.0217624358458\n",
      "train loss:0.0253909902951\n",
      "train loss:0.00699044573963\n",
      "train loss:0.00694850351586\n",
      "train loss:0.0127312014991\n",
      "train loss:0.011327360875\n",
      "train loss:0.0027575111561\n",
      "train loss:0.0678323113341\n",
      "train loss:0.0193635578837\n",
      "train loss:0.0100308270116\n",
      "train loss:0.0322407298832\n",
      "train loss:0.0293586898757\n",
      "train loss:0.00755885781377\n",
      "train loss:0.00399030622124\n",
      "train loss:0.00147511572353\n",
      "train loss:0.0107924892859\n",
      "train loss:0.0129847697289\n",
      "train loss:0.00794238524962\n",
      "train loss:0.0208536778111\n",
      "train loss:0.00506608880122\n",
      "train loss:0.0220374856628\n",
      "train loss:0.00296588844709\n",
      "train loss:0.0293068849732\n",
      "train loss:0.00560979303997\n",
      "train loss:0.0924855017323\n",
      "train loss:0.00643083228362\n",
      "train loss:0.00544285585194\n",
      "train loss:0.0109908983241\n",
      "train loss:0.0144111085129\n",
      "train loss:0.0227255788828\n",
      "train loss:0.0120888675905\n",
      "train loss:0.01941909069\n",
      "train loss:0.0585253265166\n",
      "train loss:0.0744057118344\n",
      "train loss:0.00871233623315\n",
      "train loss:0.00537044048245\n",
      "train loss:0.0331104067282\n",
      "train loss:0.0471930987927\n",
      "train loss:0.00325253884831\n",
      "train loss:0.0201730078572\n",
      "train loss:0.062411234847\n",
      "train loss:0.0136551180348\n",
      "train loss:0.0301746521519\n",
      "train loss:0.0369786668793\n",
      "train loss:0.0072400053326\n",
      "train loss:0.0510072074749\n",
      "train loss:0.0388229203293\n",
      "train loss:0.0210608705316\n",
      "train loss:0.0186241516442\n",
      "train loss:0.0645785751714\n",
      "train loss:0.0308247423482\n",
      "train loss:0.00243421999939\n",
      "train loss:0.0020330446885\n",
      "train loss:0.0234725499388\n",
      "train loss:0.0106634620122\n",
      "train loss:0.0290095762678\n",
      "train loss:0.00408693648421\n",
      "train loss:0.00992027613773\n",
      "train loss:0.0521369897255\n",
      "train loss:0.0442387079227\n",
      "train loss:0.0209062389557\n",
      "train loss:0.0612332804765\n",
      "train loss:0.0122165477627\n",
      "train loss:0.0241022709524\n",
      "train loss:0.0243928519095\n",
      "train loss:0.016219244673\n",
      "train loss:0.0122474704603\n",
      "train loss:0.0440021179652\n",
      "train loss:0.0050088994122\n",
      "train loss:0.00863871142715\n",
      "train loss:0.0360903910229\n",
      "train loss:0.0028580283127\n",
      "train loss:0.0286239994727\n",
      "train loss:0.0210570131756\n",
      "train loss:0.0433624468431\n",
      "train loss:0.0369605430098\n",
      "train loss:0.00786195438844\n",
      "train loss:0.0105266186346\n",
      "train loss:0.0365424779631\n",
      "train loss:0.0115844729036\n",
      "train loss:0.0196853494154\n",
      "train loss:0.0495291781342\n",
      "train loss:0.0544948389063\n",
      "train loss:0.0360173013504\n",
      "train loss:0.0103944281491\n",
      "train loss:0.0302217515686\n",
      "train loss:0.0152198928638\n",
      "train loss:0.00701991667169\n",
      "train loss:0.0175059050142\n",
      "train loss:0.0144013840317\n",
      "train loss:0.00870970198554\n",
      "train loss:0.038428907313\n",
      "train loss:0.0183797187164\n",
      "train loss:0.0360519421205\n",
      "train loss:0.00774736588529\n",
      "train loss:0.0206478186114\n",
      "train loss:0.0247485865498\n",
      "train loss:0.0281888046162\n",
      "train loss:0.0115920428833\n",
      "train loss:0.0185529979266\n",
      "train loss:0.00507906805452\n",
      "train loss:0.00577372250299\n",
      "train loss:0.0408198778417\n",
      "train loss:0.00698590141489\n",
      "train loss:0.0362341070987\n",
      "train loss:0.00438476136606\n",
      "train loss:0.018743666139\n",
      "train loss:0.00835778721182\n",
      "train loss:0.00699354061217\n",
      "train loss:0.0104791811498\n",
      "train loss:0.00342734763983\n",
      "train loss:0.00459960187262\n",
      "train loss:0.0469692787482\n",
      "train loss:0.00580407358978\n",
      "train loss:0.00509765898143\n",
      "train loss:0.0194336642561\n",
      "train loss:0.00627993373029\n",
      "train loss:0.015373410179\n",
      "train loss:0.00847568227214\n",
      "train loss:0.0173107275142\n",
      "train loss:0.035718751087\n",
      "train loss:0.00500726403907\n",
      "train loss:0.00781429791018\n",
      "train loss:0.0252199209795\n",
      "train loss:0.0112549654443\n",
      "train loss:0.0148077976384\n",
      "train loss:0.00408224054632\n",
      "train loss:0.0186254520157\n",
      "train loss:0.0409110830401\n",
      "train loss:0.013907606113\n",
      "train loss:0.00850863020556\n",
      "train loss:0.0150723055405\n",
      "train loss:0.00485754357111\n",
      "train loss:0.00343747974393\n",
      "train loss:0.0130095908757\n",
      "train loss:0.00233112320346\n",
      "train loss:0.0144651972872\n",
      "train loss:0.0158812847734\n",
      "train loss:0.00689518317304\n",
      "train loss:0.0167129144074\n",
      "train loss:0.0138432037642\n",
      "train loss:0.0302535201418\n",
      "train loss:0.00862177891561\n",
      "train loss:0.0109720780455\n",
      "train loss:0.00329441924157\n",
      "train loss:0.00745855886485\n",
      "train loss:0.0113454428941\n",
      "train loss:0.00736674122887\n",
      "train loss:0.0190258585433\n",
      "train loss:0.0187494355993\n",
      "train loss:0.0275013105163\n",
      "train loss:0.00195981188474\n",
      "train loss:0.0295366917167\n",
      "train loss:0.00848681396038\n",
      "train loss:0.00703671108563\n",
      "train loss:0.0273298685781\n",
      "train loss:0.0168811678041\n",
      "train loss:0.00196346646932\n",
      "train loss:0.00532775789174\n",
      "train loss:0.039322212129\n",
      "train loss:0.0151116815976\n",
      "train loss:0.0100983903035\n",
      "train loss:0.0127935067959\n",
      "train loss:0.00580353852365\n",
      "train loss:0.00452262831453\n",
      "train loss:0.00264564788934\n",
      "train loss:0.00444395225021\n",
      "train loss:0.0292522548929\n",
      "train loss:0.014480176226\n",
      "train loss:0.0132601240954\n",
      "train loss:0.0171866955313\n",
      "train loss:0.0213490187863\n",
      "train loss:0.00696690992014\n",
      "train loss:0.010557436337\n",
      "train loss:0.00635835928273\n",
      "train loss:0.00928151205803\n",
      "train loss:0.02849495344\n",
      "train loss:0.0260145493607\n",
      "train loss:0.00916777599097\n",
      "train loss:0.00687682835431\n",
      "train loss:0.0240237661994\n",
      "train loss:0.00779258609617\n",
      "train loss:0.0124319284366\n",
      "train loss:0.0163120452979\n",
      "train loss:0.0122196345899\n",
      "=== epoch:7, train acc:0.989, test acc:0.986 ===\n",
      "train loss:0.00425361946919\n",
      "train loss:0.0124126451271\n",
      "train loss:0.00347124006681\n",
      "train loss:0.0466861132782\n",
      "train loss:0.00658056877039\n",
      "train loss:0.00879765596455\n",
      "train loss:0.00934674604794\n",
      "train loss:0.00501485687973\n",
      "train loss:0.0578456843995\n",
      "train loss:0.00883461461895\n",
      "train loss:0.03738974004\n",
      "train loss:0.011816390248\n",
      "train loss:0.0310587208982\n",
      "train loss:0.0494789782563\n",
      "train loss:0.01372889904\n",
      "train loss:0.0150558007198\n",
      "train loss:0.0230397197382\n",
      "train loss:0.00360272338361\n",
      "train loss:0.0213815311157\n",
      "train loss:0.00296371795503\n",
      "train loss:0.0068428040644\n",
      "train loss:0.0083968726502\n",
      "train loss:0.0305251540272\n",
      "train loss:0.0186712416637\n",
      "train loss:0.019426063488\n",
      "train loss:0.00243213262509\n",
      "train loss:0.0295056558077\n",
      "train loss:0.00472687749249\n",
      "train loss:0.00459578548171\n",
      "train loss:0.0210121260846\n",
      "train loss:0.00349393324115\n",
      "train loss:0.0234142436523\n",
      "train loss:0.0267764091925\n",
      "train loss:0.00171597653526\n",
      "train loss:0.00329469718784\n",
      "train loss:0.00349988744564\n",
      "train loss:0.00409842769159\n",
      "train loss:0.00326347755947\n",
      "train loss:0.0310562995931\n",
      "train loss:0.00526623328788\n",
      "train loss:0.00198913520272\n",
      "train loss:0.010896586893\n",
      "train loss:0.0288367487917\n",
      "train loss:0.0155634788897\n",
      "train loss:0.0109052938502\n",
      "train loss:0.00282843276653\n",
      "train loss:0.00463321691511\n",
      "train loss:0.00318274577732\n",
      "train loss:0.0057231728753\n",
      "train loss:0.0514861239941\n",
      "train loss:0.00873714309095\n",
      "train loss:0.0141625313114\n",
      "train loss:0.0187030868376\n",
      "train loss:0.0177754447118\n",
      "train loss:0.0245608447953\n",
      "train loss:0.027157478\n",
      "train loss:0.018615108181\n",
      "train loss:0.00756707132121\n",
      "train loss:0.00211190978689\n",
      "train loss:0.0167117400145\n",
      "train loss:0.0599662649641\n",
      "train loss:0.0226298426979\n",
      "train loss:0.0577445639862\n",
      "train loss:0.0710087300155\n",
      "train loss:0.00800322079426\n",
      "train loss:0.0255066043444\n",
      "train loss:0.0101131435621\n",
      "train loss:0.00456180741092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00887763138657\n",
      "train loss:0.00234389142538\n",
      "train loss:0.0102926111971\n",
      "train loss:0.0149173318593\n",
      "train loss:0.0169680312244\n",
      "train loss:0.0513069061973\n",
      "train loss:0.0182389707435\n",
      "train loss:0.00715237770156\n",
      "train loss:0.0665859858671\n",
      "train loss:0.00827681115783\n",
      "train loss:0.00815863767978\n",
      "train loss:0.0189248127142\n",
      "train loss:0.0170753815895\n",
      "train loss:0.00393986966285\n",
      "train loss:0.00971584932817\n",
      "train loss:0.00876822743512\n",
      "train loss:0.00834662651596\n",
      "train loss:0.0201703154649\n",
      "train loss:0.00622683049782\n",
      "train loss:0.00469328448302\n",
      "train loss:0.0620845691847\n",
      "train loss:0.00604799120058\n",
      "train loss:0.00812940018261\n",
      "train loss:0.00645561147669\n",
      "train loss:0.00645309392223\n",
      "train loss:0.00722493040768\n",
      "train loss:0.00568146499754\n",
      "train loss:0.00606492140319\n",
      "train loss:0.00656651196334\n",
      "train loss:0.0328734607607\n",
      "train loss:0.0123260280717\n",
      "train loss:0.0135231321326\n",
      "train loss:0.0104137071758\n",
      "train loss:0.00376153787438\n",
      "train loss:0.00884005827068\n",
      "train loss:0.00515200139187\n",
      "train loss:0.0782219301266\n",
      "train loss:0.00619493283854\n",
      "train loss:0.0103496437965\n",
      "train loss:0.00571882197163\n",
      "train loss:0.0367763140478\n",
      "train loss:0.00475701653226\n",
      "train loss:0.0156956186054\n",
      "train loss:0.00973956956549\n",
      "train loss:0.00424513441292\n",
      "train loss:0.00898344787189\n",
      "train loss:0.00563381442906\n",
      "train loss:0.00335744158897\n",
      "train loss:0.00389514716755\n",
      "train loss:0.00134495366175\n",
      "train loss:0.00356018361255\n",
      "train loss:0.0102966810685\n",
      "train loss:0.0358788546474\n",
      "train loss:0.00487817922744\n",
      "train loss:0.0151116363179\n",
      "train loss:0.00463956495102\n",
      "train loss:0.0213961490009\n",
      "train loss:0.169739697773\n",
      "train loss:0.0571110570456\n",
      "train loss:0.0103083767429\n",
      "train loss:0.00342018272053\n",
      "train loss:0.0030657770085\n",
      "train loss:0.0444732433192\n",
      "train loss:0.0101740260538\n",
      "train loss:0.00645715514387\n",
      "train loss:0.0423339862441\n",
      "train loss:0.0267063263345\n",
      "train loss:0.0147598093094\n",
      "train loss:0.0199732130601\n",
      "train loss:0.0401479799902\n",
      "train loss:0.00758464196466\n",
      "train loss:0.0125121536964\n",
      "train loss:0.0195019446303\n",
      "train loss:0.0104281973338\n",
      "train loss:0.0136189649534\n",
      "train loss:0.0395711533532\n",
      "train loss:0.0402443230665\n",
      "train loss:0.0184647804152\n",
      "train loss:0.0224224427305\n",
      "train loss:0.0265213091474\n",
      "train loss:0.0115748094481\n",
      "train loss:0.00234099260688\n",
      "train loss:0.0197118449814\n",
      "train loss:0.00861128514563\n",
      "train loss:0.0117342826912\n",
      "train loss:0.012890952208\n",
      "train loss:0.00650305221794\n",
      "train loss:0.0033196244549\n",
      "train loss:0.0150091796009\n",
      "train loss:0.0115324004571\n",
      "train loss:0.00996823779594\n",
      "train loss:0.0238199644727\n",
      "train loss:0.077502076235\n",
      "train loss:0.00807578921579\n",
      "train loss:0.0284273995946\n",
      "train loss:0.038825388801\n",
      "train loss:0.00305403829842\n",
      "train loss:0.0289925016207\n",
      "train loss:0.011276261671\n",
      "train loss:0.00916360664266\n",
      "train loss:0.00272989937479\n",
      "train loss:0.0141299618272\n",
      "train loss:0.00118685407179\n",
      "train loss:0.00588490225575\n",
      "train loss:0.010180468754\n",
      "train loss:0.0505868129089\n",
      "train loss:0.00711569492668\n",
      "train loss:0.0125109851645\n",
      "train loss:0.0152066312551\n",
      "train loss:0.0190161788762\n",
      "train loss:0.0433037843337\n",
      "train loss:0.0230743075877\n",
      "train loss:0.000595685040382\n",
      "train loss:0.00440744548971\n",
      "train loss:0.00681398583103\n",
      "train loss:0.00928442762664\n",
      "train loss:0.0246051292975\n",
      "train loss:0.0298341966308\n",
      "train loss:0.00428851797299\n",
      "train loss:0.00711386394617\n",
      "train loss:0.0112463063433\n",
      "train loss:0.00721886455436\n",
      "train loss:0.00576019161608\n",
      "train loss:0.00536711716667\n",
      "train loss:0.0104750850812\n",
      "train loss:0.00301178210379\n",
      "train loss:0.00943078543367\n",
      "train loss:0.00807366394001\n",
      "train loss:0.00713008499394\n",
      "train loss:0.00780393398017\n",
      "train loss:0.00337856931303\n",
      "train loss:0.00856569595179\n",
      "train loss:0.00272779393883\n",
      "train loss:0.0687989577124\n",
      "train loss:0.00367872483913\n",
      "train loss:0.00645102266009\n",
      "train loss:0.0134115895791\n",
      "train loss:0.00860310101642\n",
      "train loss:0.0113158442648\n",
      "train loss:0.00732895733148\n",
      "train loss:0.0581304661765\n",
      "train loss:0.0482745982393\n",
      "train loss:0.0109233713781\n",
      "train loss:0.00370558729945\n",
      "train loss:0.0112090236399\n",
      "train loss:0.0105233795222\n",
      "train loss:0.0065754229928\n",
      "train loss:0.0252655709791\n",
      "train loss:0.00636321914979\n",
      "train loss:0.0102759795354\n",
      "train loss:0.0321282125317\n",
      "train loss:0.0176373959601\n",
      "train loss:0.0106920970968\n",
      "train loss:0.162382148482\n",
      "train loss:0.0102957808057\n",
      "train loss:0.027946571342\n",
      "train loss:0.00455425112751\n",
      "train loss:0.00856237371347\n",
      "train loss:0.00982781150483\n",
      "train loss:0.00706890558807\n",
      "train loss:0.00602927612177\n",
      "train loss:0.00383005943792\n",
      "train loss:0.018877605679\n",
      "train loss:0.0137121579335\n",
      "train loss:0.0133391679299\n",
      "train loss:0.00835403511614\n",
      "train loss:0.0556561849731\n",
      "train loss:0.0610726536298\n",
      "train loss:0.0104748246482\n",
      "train loss:0.00968439798107\n",
      "train loss:0.00742103200871\n",
      "train loss:0.0161981354561\n",
      "train loss:0.00770955453732\n",
      "train loss:0.0336431149774\n",
      "train loss:0.00579583412574\n",
      "train loss:0.0281766366541\n",
      "train loss:0.00983455820279\n",
      "train loss:0.00600272246036\n",
      "train loss:0.0381153726773\n",
      "train loss:0.00909356989323\n",
      "train loss:0.00402002654782\n",
      "train loss:0.0150323910851\n",
      "train loss:0.020020260098\n",
      "train loss:0.00500878793063\n",
      "train loss:0.0101050847966\n",
      "train loss:0.0184049752175\n",
      "train loss:0.00476954452411\n",
      "train loss:0.00733455937821\n",
      "train loss:0.0127250120438\n",
      "train loss:0.0138003441017\n",
      "train loss:0.013147095403\n",
      "train loss:0.0204035333093\n",
      "train loss:0.0066288632544\n",
      "train loss:0.00420087884889\n",
      "train loss:0.0146681326779\n",
      "train loss:0.00473075884894\n",
      "train loss:0.00739190634128\n",
      "train loss:0.00859013222847\n",
      "train loss:0.00151418536544\n",
      "train loss:0.0307374233826\n",
      "train loss:0.00349670719831\n",
      "train loss:0.0199235884747\n",
      "train loss:0.00831614937796\n",
      "train loss:0.0308806478599\n",
      "train loss:0.017729506092\n",
      "train loss:0.021286660794\n",
      "train loss:0.015705462854\n",
      "train loss:0.0256200553484\n",
      "train loss:0.0158309093754\n",
      "train loss:0.016964002561\n",
      "train loss:0.0160504631724\n",
      "train loss:0.021147553534\n",
      "train loss:0.00508673288009\n",
      "train loss:0.00659970044322\n",
      "train loss:0.00577384408049\n",
      "train loss:0.023449555781\n",
      "train loss:0.00562598233308\n",
      "train loss:0.0100541705813\n",
      "train loss:0.0126653379105\n",
      "train loss:0.00580178863544\n",
      "train loss:0.0109975329441\n",
      "train loss:0.00242720192428\n",
      "train loss:0.00700001584986\n",
      "train loss:0.00824296023335\n",
      "train loss:0.0120468980276\n",
      "train loss:0.00505200716347\n",
      "train loss:0.0165507752215\n",
      "train loss:0.00542729047413\n",
      "train loss:0.00243039668381\n",
      "train loss:0.0106975532465\n",
      "train loss:0.0230198500471\n",
      "train loss:0.00796138654907\n",
      "train loss:0.00779237150016\n",
      "train loss:0.0245996502783\n",
      "train loss:0.0233210132245\n",
      "train loss:0.0161556210622\n",
      "train loss:0.00439877546136\n",
      "train loss:0.00235572367061\n",
      "train loss:0.00940913620637\n",
      "train loss:0.0344899998835\n",
      "train loss:0.00490300814462\n",
      "train loss:0.0145390112821\n",
      "train loss:0.00825688128426\n",
      "train loss:0.00501924083249\n",
      "train loss:0.0250809383719\n",
      "train loss:0.0225406503483\n",
      "train loss:0.0184515651356\n",
      "train loss:0.00631794545764\n",
      "train loss:0.0444036732491\n",
      "train loss:0.00609729118474\n",
      "train loss:0.0121196886809\n",
      "train loss:0.0507800164594\n",
      "train loss:0.0195933254529\n",
      "train loss:0.0105301916782\n",
      "train loss:0.00681632493943\n",
      "train loss:0.013777035723\n",
      "train loss:0.00847660214727\n",
      "train loss:0.00454246690915\n",
      "train loss:0.0275549753108\n",
      "train loss:0.0186786415844\n",
      "train loss:0.00768335196047\n",
      "train loss:0.00334451161009\n",
      "train loss:0.0137710141838\n",
      "train loss:0.0103728331775\n",
      "train loss:0.0218465400413\n",
      "train loss:0.00277580944222\n",
      "train loss:0.0243603833642\n",
      "train loss:0.00818769775342\n",
      "train loss:0.00089717011939\n",
      "train loss:0.0306014299142\n",
      "train loss:0.0911420441179\n",
      "train loss:0.040127204537\n",
      "train loss:0.0326080919991\n",
      "train loss:0.00577327366819\n",
      "train loss:0.00570497134525\n",
      "train loss:0.0063613140427\n",
      "train loss:0.0689299853863\n",
      "train loss:0.183683652824\n",
      "train loss:0.0272947605669\n",
      "train loss:0.000909836899573\n",
      "train loss:0.00362059426138\n",
      "train loss:0.00798180326448\n",
      "train loss:0.0064900666636\n",
      "train loss:0.00284770716221\n",
      "train loss:0.00917186286901\n",
      "train loss:0.00226203668721\n",
      "train loss:0.0128384958205\n",
      "train loss:0.00626129129097\n",
      "train loss:0.0131620528702\n",
      "train loss:0.00396626614636\n",
      "train loss:0.00229031312297\n",
      "train loss:0.0093385439571\n",
      "train loss:0.00336680764604\n",
      "train loss:0.0262736524933\n",
      "train loss:0.0238271586989\n",
      "train loss:0.0206467465768\n",
      "train loss:0.00746590693924\n",
      "train loss:0.00561700769261\n",
      "train loss:0.0122655738461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0406783686952\n",
      "train loss:0.00403824007403\n",
      "train loss:0.00518240836635\n",
      "train loss:0.00325367460665\n",
      "train loss:0.142599115796\n",
      "train loss:0.00850513371015\n",
      "train loss:0.0921156971242\n",
      "train loss:0.00428279733198\n",
      "train loss:0.0416919774165\n",
      "train loss:0.0288407196951\n",
      "train loss:0.0040871601705\n",
      "train loss:0.0317574793162\n",
      "train loss:0.05186183322\n",
      "train loss:0.00680187919187\n",
      "train loss:0.0160963581468\n",
      "train loss:0.00667442056432\n",
      "train loss:0.00411192537269\n",
      "train loss:0.00984289371242\n",
      "train loss:0.0218187385866\n",
      "train loss:0.0107649182872\n",
      "train loss:0.0215543684618\n",
      "train loss:0.0307187304531\n",
      "train loss:0.0119537132949\n",
      "train loss:0.0456911421271\n",
      "train loss:0.028543022201\n",
      "train loss:0.0379714597963\n",
      "train loss:0.00863742587872\n",
      "train loss:0.00573772093436\n",
      "train loss:0.0248024692404\n",
      "train loss:0.0223079150145\n",
      "train loss:0.0143402324703\n",
      "train loss:0.00479990970887\n",
      "train loss:0.015303018592\n",
      "train loss:0.00186039012057\n",
      "train loss:0.102132845749\n",
      "train loss:0.0136978454561\n",
      "train loss:0.00915210385079\n",
      "train loss:0.00725559178344\n",
      "train loss:0.0804465299664\n",
      "train loss:0.00668727302791\n",
      "train loss:0.0105001326863\n",
      "train loss:0.0232215064382\n",
      "train loss:0.00561842247755\n",
      "train loss:0.00924527320391\n",
      "train loss:0.0229134995569\n",
      "train loss:0.00879111384428\n",
      "train loss:0.0111276110728\n",
      "train loss:0.0146557090077\n",
      "train loss:0.0332308435216\n",
      "train loss:0.00816451277228\n",
      "train loss:0.00537378148706\n",
      "train loss:0.0179369430625\n",
      "train loss:0.00487076011013\n",
      "train loss:0.0170159699491\n",
      "train loss:0.00182805057622\n",
      "train loss:0.0123251199023\n",
      "train loss:0.0191773223081\n",
      "train loss:0.00749742186225\n",
      "train loss:0.0300043443076\n",
      "train loss:0.00952159670296\n",
      "train loss:0.0131041899077\n",
      "train loss:0.0575306834933\n",
      "train loss:0.00833641389039\n",
      "train loss:0.00292079150537\n",
      "train loss:0.0183060904151\n",
      "train loss:0.0100435386045\n",
      "train loss:0.0063812053267\n",
      "train loss:0.012462375221\n",
      "train loss:0.0222273731128\n",
      "train loss:0.0285745540806\n",
      "train loss:0.00571046876229\n",
      "train loss:0.00615458854487\n",
      "train loss:0.00668345515565\n",
      "train loss:0.0209150600111\n",
      "train loss:0.0173791968018\n",
      "train loss:0.00554251249976\n",
      "train loss:0.0142882941079\n",
      "train loss:0.00548480946115\n",
      "train loss:0.086607732407\n",
      "train loss:0.0166900747038\n",
      "train loss:0.00602237138451\n",
      "train loss:0.0197914490154\n",
      "train loss:0.00252340485712\n",
      "train loss:0.000573387577773\n",
      "train loss:0.0673307468915\n",
      "train loss:0.0160277547087\n",
      "train loss:0.0176410142187\n",
      "train loss:0.0034085561509\n",
      "train loss:0.0181871484584\n",
      "train loss:0.0140389444099\n",
      "train loss:0.00659279866356\n",
      "train loss:0.0140953364288\n",
      "train loss:0.00397382292909\n",
      "train loss:0.0215631174901\n",
      "train loss:0.00431526039532\n",
      "train loss:0.0049466112071\n",
      "train loss:0.0202018479225\n",
      "train loss:0.00753416891034\n",
      "train loss:0.0166086298526\n",
      "train loss:0.000756718951188\n",
      "train loss:0.00952247139201\n",
      "train loss:0.00630209051289\n",
      "train loss:0.00531478274047\n",
      "train loss:0.00417492309609\n",
      "train loss:0.00294290678172\n",
      "train loss:0.00171562023004\n",
      "train loss:0.0129116926789\n",
      "train loss:0.0128076757424\n",
      "train loss:0.00395139039063\n",
      "train loss:0.0139425046158\n",
      "train loss:0.0155639324325\n",
      "train loss:0.0314341147867\n",
      "train loss:0.046311757888\n",
      "train loss:0.00592096204226\n",
      "train loss:0.0109488782399\n",
      "train loss:0.012739920101\n",
      "train loss:0.00734021540569\n",
      "train loss:0.0212518983898\n",
      "train loss:0.00109420423358\n",
      "train loss:0.0661050925024\n",
      "train loss:0.00656974993411\n",
      "train loss:0.00124561606804\n",
      "train loss:0.00564878763144\n",
      "train loss:0.015954345525\n",
      "train loss:0.0203662642665\n",
      "train loss:0.0162716454436\n",
      "train loss:0.00861657599864\n",
      "train loss:0.00673095406583\n",
      "train loss:0.014561287834\n",
      "train loss:0.00599037984853\n",
      "train loss:0.00942816092966\n",
      "train loss:0.0372632304245\n",
      "train loss:0.0195110016731\n",
      "train loss:0.00281248787149\n",
      "train loss:0.00550573410985\n",
      "train loss:0.0193895994062\n",
      "train loss:0.00527685771231\n",
      "train loss:0.0139210435879\n",
      "train loss:0.0146046793858\n",
      "train loss:0.0126322760446\n",
      "train loss:0.00558999826566\n",
      "train loss:0.0743921209065\n",
      "train loss:0.00339656921671\n",
      "train loss:0.129492279382\n",
      "train loss:0.00655223677701\n",
      "train loss:0.00870536219572\n",
      "train loss:0.0144592823163\n",
      "train loss:0.00970572942884\n",
      "train loss:0.00934210596723\n",
      "train loss:0.122184410626\n",
      "train loss:0.00135363794518\n",
      "train loss:0.00925270862141\n",
      "train loss:0.00371061234454\n",
      "train loss:0.0169170306513\n",
      "train loss:0.0231651772975\n",
      "train loss:0.010190941093\n",
      "train loss:0.0386304613587\n",
      "train loss:0.0411288544188\n",
      "train loss:0.00766818190509\n",
      "train loss:0.0307007934296\n",
      "train loss:0.00430578384956\n",
      "train loss:0.0488168902076\n",
      "train loss:0.00271219308813\n",
      "train loss:0.00142334338689\n",
      "train loss:0.0186887839638\n",
      "train loss:0.00243348628074\n",
      "train loss:0.0166913880171\n",
      "train loss:0.0032690225262\n",
      "train loss:0.0167803629629\n",
      "train loss:0.00151940275466\n",
      "train loss:0.0017142652912\n",
      "train loss:0.00683015191618\n",
      "train loss:0.0196934408231\n",
      "train loss:0.0110366987693\n",
      "train loss:0.016452806739\n",
      "train loss:0.0268585116689\n",
      "train loss:0.0147488831995\n",
      "train loss:0.0117250853353\n",
      "train loss:0.0235705819566\n",
      "train loss:0.00458921490509\n",
      "train loss:0.00479074098835\n",
      "train loss:0.00203945414699\n",
      "train loss:0.0108794048798\n",
      "train loss:0.00647661979331\n",
      "train loss:0.0460400861006\n",
      "train loss:0.0214590245364\n",
      "train loss:0.0046987846283\n",
      "train loss:0.00362046974263\n",
      "train loss:0.00637292051597\n",
      "train loss:0.0190307058128\n",
      "train loss:0.0197523188111\n",
      "train loss:0.0116408733392\n",
      "train loss:0.0156836578762\n",
      "train loss:0.00269525684882\n",
      "train loss:0.0117645015877\n",
      "train loss:0.0413798693084\n",
      "train loss:0.00539391797149\n",
      "train loss:0.0259575914495\n",
      "train loss:0.0220147934711\n",
      "train loss:0.0683094774979\n",
      "train loss:0.0729023665364\n",
      "train loss:0.0120121285914\n",
      "train loss:0.00441884725706\n",
      "train loss:0.0174704370327\n",
      "train loss:0.0305521930117\n",
      "train loss:0.0195920830213\n",
      "train loss:0.0175607610429\n",
      "train loss:0.0120134665449\n",
      "train loss:0.00972037222449\n",
      "train loss:0.0189475329906\n",
      "train loss:0.0198616749931\n",
      "train loss:0.00567946649351\n",
      "train loss:0.00853305874035\n",
      "train loss:0.0232813083524\n",
      "train loss:0.00715963494374\n",
      "train loss:0.0118976383933\n",
      "train loss:0.013203309916\n",
      "train loss:0.0125858227918\n",
      "train loss:0.0258741536956\n",
      "train loss:0.0298948614003\n",
      "train loss:0.00254242606352\n",
      "train loss:0.0102014757572\n",
      "train loss:0.017592597332\n",
      "train loss:0.0170267221718\n",
      "train loss:0.00455242779354\n",
      "train loss:0.0169276195821\n",
      "train loss:0.0335586027534\n",
      "train loss:0.0089932310816\n",
      "train loss:0.0177719971865\n",
      "train loss:0.0234021840354\n",
      "train loss:0.0164230441873\n",
      "train loss:0.0351861864819\n",
      "train loss:0.00334342001263\n",
      "=== epoch:8, train acc:0.989, test acc:0.987 ===\n",
      "train loss:0.0137224890674\n",
      "train loss:0.00278713789057\n",
      "train loss:0.00334869405822\n",
      "train loss:0.0323379734822\n",
      "train loss:0.00776241363789\n",
      "train loss:0.041183369008\n",
      "train loss:0.0290948023211\n",
      "train loss:0.00976480724257\n",
      "train loss:0.00662025604086\n",
      "train loss:0.0199027053608\n",
      "train loss:0.0135151090129\n",
      "train loss:0.00306577448538\n",
      "train loss:0.0868162905191\n",
      "train loss:0.00262188065416\n",
      "train loss:0.0108700093978\n",
      "train loss:0.0159025847108\n",
      "train loss:0.0310325544758\n",
      "train loss:0.01688221954\n",
      "train loss:0.0104382941367\n",
      "train loss:0.00791259077234\n",
      "train loss:0.00695521778218\n",
      "train loss:0.00308705168492\n",
      "train loss:0.0148071422186\n",
      "train loss:0.00705156738541\n",
      "train loss:0.00913849582132\n",
      "train loss:0.0218459803111\n",
      "train loss:0.0633004979359\n",
      "train loss:0.0465388004818\n",
      "train loss:0.00385275960292\n",
      "train loss:0.0125199609491\n",
      "train loss:0.0702444160106\n",
      "train loss:0.0434547760362\n",
      "train loss:0.0162678794353\n",
      "train loss:0.00784537457886\n",
      "train loss:0.00925097762749\n",
      "train loss:0.00735127555561\n",
      "train loss:0.0240546469032\n",
      "train loss:0.00855177025185\n",
      "train loss:0.0117366572917\n",
      "train loss:0.0432701956534\n",
      "train loss:0.00530277724356\n",
      "train loss:0.00784676606826\n",
      "train loss:0.0169516417143\n",
      "train loss:0.0102742347713\n",
      "train loss:0.00241895548003\n",
      "train loss:0.00933959647415\n",
      "train loss:0.01327402205\n",
      "train loss:0.0276148672218\n",
      "train loss:0.0162686106982\n",
      "train loss:0.0140755231307\n",
      "train loss:0.0291917278933\n",
      "train loss:0.00641819723051\n",
      "train loss:0.00465236044838\n",
      "train loss:0.00707357272255\n",
      "train loss:0.0214764987858\n",
      "train loss:0.0117390485431\n",
      "train loss:0.00583008288728\n",
      "train loss:0.0051779349875\n",
      "train loss:0.00828427765821\n",
      "train loss:0.0155904524828\n",
      "train loss:0.0306338766514\n",
      "train loss:0.0184855877796\n",
      "train loss:0.0380045336567\n",
      "train loss:0.00835937994642\n",
      "train loss:0.00395163307854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00744143541844\n",
      "train loss:0.0147889520912\n",
      "train loss:0.00777502754414\n",
      "train loss:0.00749142902795\n",
      "train loss:0.0175172614185\n",
      "train loss:0.0157338438676\n",
      "train loss:0.00422268699059\n",
      "train loss:0.00551394958288\n",
      "train loss:0.00361177870645\n",
      "train loss:0.0152498236885\n",
      "train loss:0.00803664292738\n",
      "train loss:0.0626410793659\n",
      "train loss:0.00882983159447\n",
      "train loss:0.0128280507454\n",
      "train loss:0.00746696044822\n",
      "train loss:0.0151132319384\n",
      "train loss:0.0171963464223\n",
      "train loss:0.00599402594303\n",
      "train loss:0.0185142795074\n",
      "train loss:0.0354173927996\n",
      "train loss:0.0107731153475\n",
      "train loss:0.00410420653451\n",
      "train loss:0.00891285355755\n",
      "train loss:0.00204954035769\n",
      "train loss:0.016646500879\n",
      "train loss:0.0146492718206\n",
      "train loss:0.0163282442327\n",
      "train loss:0.0044620920114\n",
      "train loss:0.0596338183361\n",
      "train loss:0.00345065228798\n",
      "train loss:0.0103694734695\n",
      "train loss:0.00405409376662\n",
      "train loss:0.00261795056228\n",
      "train loss:0.0019076049959\n",
      "train loss:0.00718596322708\n",
      "train loss:0.0043658862989\n",
      "train loss:0.024827779346\n",
      "train loss:0.00524558275566\n",
      "train loss:0.0259488054635\n",
      "train loss:0.012315759326\n",
      "train loss:0.0802173599072\n",
      "train loss:0.0261389325915\n",
      "train loss:0.0512463293325\n",
      "train loss:0.0339736028772\n",
      "train loss:0.00169411871601\n",
      "train loss:0.0217802540477\n",
      "train loss:0.0168696487171\n",
      "train loss:0.0114813232969\n",
      "train loss:0.00614430320183\n",
      "train loss:0.0289824139911\n",
      "train loss:0.023870112064\n",
      "train loss:0.00927823218025\n",
      "train loss:0.0316115433292\n",
      "train loss:0.0236820306709\n",
      "train loss:0.0314253147404\n",
      "train loss:0.0286972786283\n",
      "train loss:0.0131970895327\n",
      "train loss:0.00349832552966\n",
      "train loss:0.0021053880785\n",
      "train loss:0.0026273503024\n",
      "train loss:0.0395273818587\n",
      "train loss:0.0413283007788\n",
      "train loss:0.00595244879352\n",
      "train loss:0.0179172683414\n",
      "train loss:0.0199443704966\n",
      "train loss:0.00397371163824\n",
      "train loss:0.00826200893491\n",
      "train loss:0.0168175843263\n",
      "train loss:0.0962761723642\n",
      "train loss:0.012785534962\n",
      "train loss:0.0148526968521\n",
      "train loss:0.0118322940633\n",
      "train loss:0.00545241463415\n",
      "train loss:0.0104761644569\n",
      "train loss:0.0135603809444\n",
      "train loss:0.0266891165299\n",
      "train loss:0.0351841958402\n",
      "train loss:0.0103554825652\n",
      "train loss:0.00606456757845\n",
      "train loss:0.0169638090561\n",
      "train loss:0.0117872021226\n",
      "train loss:0.00444028291301\n",
      "train loss:0.00749700219151\n",
      "train loss:0.00134665275692\n",
      "train loss:0.0292500073263\n",
      "train loss:0.0208536274325\n",
      "train loss:0.00973478380581\n",
      "train loss:0.00196094261563\n",
      "train loss:0.00482124045536\n",
      "train loss:0.0243504832093\n",
      "train loss:0.0141140974841\n",
      "train loss:0.0140187907034\n",
      "train loss:0.021010400746\n",
      "train loss:0.0694430412736\n",
      "train loss:0.00481929753658\n",
      "train loss:0.00734106855246\n",
      "train loss:0.0105554152952\n",
      "train loss:0.00761841460782\n",
      "train loss:0.00757909683954\n",
      "train loss:0.0197210893423\n",
      "train loss:0.0143096334126\n",
      "train loss:0.0120858521562\n",
      "train loss:0.010039415047\n",
      "train loss:0.00959148016482\n",
      "train loss:0.00815532877502\n",
      "train loss:0.00841751836324\n",
      "train loss:0.0127758595088\n",
      "train loss:0.0986575133553\n",
      "train loss:0.0136156436188\n",
      "train loss:0.0141926811142\n",
      "train loss:0.0374515883206\n",
      "train loss:0.0235691639919\n",
      "train loss:0.0256537178563\n",
      "train loss:0.00581391700392\n",
      "train loss:0.00210237185997\n",
      "train loss:0.0227856127622\n",
      "train loss:0.0250189109394\n",
      "train loss:0.0150789180541\n",
      "train loss:0.00914738776756\n",
      "train loss:0.0115072541904\n",
      "train loss:0.00667204370697\n",
      "train loss:0.00246980794159\n",
      "train loss:0.022889582528\n",
      "train loss:0.00615357291735\n",
      "train loss:0.0283000973443\n",
      "train loss:0.0294378273801\n",
      "train loss:0.00430839433792\n",
      "train loss:0.0157867840145\n",
      "train loss:0.0107541284678\n",
      "train loss:0.00120792578039\n",
      "train loss:0.0243844509951\n",
      "train loss:0.0444657755603\n",
      "train loss:0.00507853909998\n",
      "train loss:0.0320037798171\n",
      "train loss:0.0197912848596\n",
      "train loss:0.0594092575947\n",
      "train loss:0.00725920096528\n",
      "train loss:0.00141423770344\n",
      "train loss:0.0123646620386\n",
      "train loss:0.00761529759377\n",
      "train loss:0.00833317248112\n",
      "train loss:0.00250060678143\n",
      "train loss:0.0123894806482\n",
      "train loss:0.00366556038892\n",
      "train loss:0.00427002375493\n",
      "train loss:0.0140242665151\n",
      "train loss:0.0069615710626\n",
      "train loss:0.00993826558731\n",
      "train loss:0.00803853480273\n",
      "train loss:0.00195062525727\n",
      "train loss:0.00553340255777\n",
      "train loss:0.00692225811211\n",
      "train loss:0.0177033922313\n",
      "train loss:0.0276643730328\n",
      "train loss:0.00163957342231\n",
      "train loss:0.0175284188102\n",
      "train loss:0.0251307152325\n",
      "train loss:0.0162794488136\n",
      "train loss:0.0326387819055\n",
      "train loss:0.00818062628087\n",
      "train loss:0.00428737899068\n",
      "train loss:0.0162754682837\n",
      "train loss:0.0394140380679\n",
      "train loss:0.0152783832646\n",
      "train loss:0.0112714950723\n",
      "train loss:0.00350925434328\n",
      "train loss:0.0127470300131\n",
      "train loss:0.00444076768553\n",
      "train loss:0.0101307068422\n",
      "train loss:0.0135390143206\n",
      "train loss:0.0153559532452\n",
      "train loss:0.00140192600128\n",
      "train loss:0.00401841636322\n",
      "train loss:0.00285603177952\n",
      "train loss:0.0233395763064\n",
      "train loss:0.0043442442912\n",
      "train loss:0.0249735560222\n",
      "train loss:0.00791261419563\n",
      "train loss:0.0063932827264\n",
      "train loss:0.0130981642494\n",
      "train loss:0.00301459247212\n",
      "train loss:0.00191952923488\n",
      "train loss:0.00540316960629\n",
      "train loss:0.00867785897958\n",
      "train loss:0.0278842353028\n",
      "train loss:0.0047800036676\n",
      "train loss:0.00468305184464\n",
      "train loss:0.00534563151103\n",
      "train loss:0.0119497553361\n",
      "train loss:0.00829892846663\n",
      "train loss:0.0636256660469\n",
      "train loss:0.0155698939877\n",
      "train loss:0.00645624450529\n",
      "train loss:0.0135537761515\n",
      "train loss:0.0176147091619\n",
      "train loss:0.00335489622755\n",
      "train loss:0.0171879130538\n",
      "train loss:0.00538393432326\n",
      "train loss:0.0368122112179\n",
      "train loss:0.00124851470557\n",
      "train loss:0.0120821787457\n",
      "train loss:0.00458021706276\n",
      "train loss:0.0141034893806\n",
      "train loss:0.0110980484306\n",
      "train loss:0.0159513265431\n",
      "train loss:0.011313415463\n",
      "train loss:0.0102509820554\n",
      "train loss:0.00799747544147\n",
      "train loss:0.00195540066998\n",
      "train loss:0.00425090139023\n",
      "train loss:0.00400506072178\n",
      "train loss:0.0012586064862\n",
      "train loss:0.00521944870237\n",
      "train loss:0.00710211198434\n",
      "train loss:0.000749288775658\n",
      "train loss:0.0210595096894\n",
      "train loss:0.00841827308623\n",
      "train loss:0.0254932332529\n",
      "train loss:0.00162206544163\n",
      "train loss:0.00656565307125\n",
      "train loss:0.0197491334678\n",
      "train loss:0.0133705998439\n",
      "train loss:0.0337397237105\n",
      "train loss:0.0130430944832\n",
      "train loss:0.00481702564806\n",
      "train loss:0.039059289697\n",
      "train loss:0.00790475204058\n",
      "train loss:0.0278758124516\n",
      "train loss:0.0152141019745\n",
      "train loss:0.00424032553914\n",
      "train loss:0.0165328250017\n",
      "train loss:0.00720370709042\n",
      "train loss:0.00595648441929\n",
      "train loss:0.0825394615592\n",
      "train loss:0.0171382397923\n",
      "train loss:0.00298394392659\n",
      "train loss:0.00362270184936\n",
      "train loss:0.0160016163485\n",
      "train loss:0.0110774145541\n",
      "train loss:0.0119388284846\n",
      "train loss:0.00327649774684\n",
      "train loss:0.0157299565089\n",
      "train loss:0.0176491700025\n",
      "train loss:0.00149966443401\n",
      "train loss:0.00968258521667\n",
      "train loss:0.0121346908299\n",
      "train loss:0.00219835936074\n",
      "train loss:0.0323318168123\n",
      "train loss:0.0517233028926\n",
      "train loss:0.00230462720265\n",
      "train loss:0.0344917067656\n",
      "train loss:0.013056453797\n",
      "train loss:0.0156322600471\n",
      "train loss:0.0208501679763\n",
      "train loss:0.0614927221062\n",
      "train loss:0.0440174927521\n",
      "train loss:0.0158975651046\n",
      "train loss:0.0496250806974\n",
      "train loss:0.0400961585421\n",
      "train loss:0.00369332167333\n",
      "train loss:0.0496036396668\n",
      "train loss:0.00460304587722\n",
      "train loss:0.0202038340876\n",
      "train loss:0.0058949436903\n",
      "train loss:0.0255896605651\n",
      "train loss:0.0879199812347\n",
      "train loss:0.0711721542413\n",
      "train loss:0.0315272173428\n",
      "train loss:0.0372509382274\n",
      "train loss:0.026657352164\n",
      "train loss:0.00891006843358\n",
      "train loss:0.00348461364099\n",
      "train loss:0.0091036614443\n",
      "train loss:0.0561382319346\n",
      "train loss:0.00634977624652\n",
      "train loss:0.0156631699391\n",
      "train loss:0.00266180974994\n",
      "train loss:0.0142700510075\n",
      "train loss:0.0120057645147\n",
      "train loss:0.0598852980041\n",
      "train loss:0.00274647389092\n",
      "train loss:0.0202673488691\n",
      "train loss:0.00390719901438\n",
      "train loss:0.0232084656679\n",
      "train loss:0.0152383870155\n",
      "train loss:0.0287890868594\n",
      "train loss:0.00436829455457\n",
      "train loss:0.0114771031316\n",
      "train loss:0.0179279468324\n",
      "train loss:0.00897816692032\n",
      "train loss:0.00235557277763\n",
      "train loss:0.0281096308596\n",
      "train loss:0.00691295264083\n",
      "train loss:0.00325968528347\n",
      "train loss:0.00569256753619\n",
      "train loss:0.00475221252284\n",
      "train loss:0.00149409299232\n",
      "train loss:0.00264379918218\n",
      "train loss:0.00175269959892\n",
      "train loss:0.00938617202671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00551634893044\n",
      "train loss:0.00223464017035\n",
      "train loss:0.0126285836786\n",
      "train loss:0.0285697888622\n",
      "train loss:0.0121481606389\n",
      "train loss:0.0198771605692\n",
      "train loss:0.0184427852408\n",
      "train loss:0.00621170293954\n",
      "train loss:0.0105521923913\n",
      "train loss:0.0808956380374\n",
      "train loss:0.019954112078\n",
      "train loss:0.0117419442759\n",
      "train loss:0.00654073466987\n",
      "train loss:0.00393631358237\n",
      "train loss:0.0105694396108\n",
      "train loss:0.00441408332973\n",
      "train loss:0.00903058087444\n",
      "train loss:0.0205869993318\n",
      "train loss:0.0257611830976\n",
      "train loss:0.00607411863291\n",
      "train loss:0.010407102425\n",
      "train loss:0.00202621700277\n",
      "train loss:0.0122680542805\n",
      "train loss:0.0150172257361\n",
      "train loss:0.014611341863\n",
      "train loss:0.00528335435525\n",
      "train loss:0.0215092058205\n",
      "train loss:0.0106924382824\n",
      "train loss:0.0039481113774\n",
      "train loss:0.0228357581926\n",
      "train loss:0.00937476902565\n",
      "train loss:0.00897105164758\n",
      "train loss:0.00359243521674\n",
      "train loss:0.00727897255603\n",
      "train loss:0.00778519901191\n",
      "train loss:0.0341932108975\n",
      "train loss:0.00920152161741\n",
      "train loss:0.00950602650804\n",
      "train loss:0.00654674101366\n",
      "train loss:0.00447052339061\n",
      "train loss:0.0305052473512\n",
      "train loss:0.0121082234768\n",
      "train loss:0.00992409048821\n",
      "train loss:0.0289695822598\n",
      "train loss:0.00269429192712\n",
      "train loss:0.0236091320496\n",
      "train loss:0.00454981200652\n",
      "train loss:0.0360007100897\n",
      "train loss:0.0028715548361\n",
      "train loss:0.0193277717719\n",
      "train loss:0.00522804748736\n",
      "train loss:0.0143159068062\n",
      "train loss:0.00274498156801\n",
      "train loss:0.00320777446109\n",
      "train loss:0.000937765781125\n",
      "train loss:0.00521356487711\n",
      "train loss:0.00638653854217\n",
      "train loss:0.00381081865871\n",
      "train loss:0.00839778362145\n",
      "train loss:0.035383450611\n",
      "train loss:0.00425021137122\n",
      "train loss:0.00356666580779\n",
      "train loss:0.00302423076745\n",
      "train loss:0.0045656879292\n",
      "train loss:0.00823302800483\n",
      "train loss:0.00300241205\n",
      "train loss:0.0172434131399\n",
      "train loss:0.00712807672943\n",
      "train loss:0.00166176260834\n",
      "train loss:0.00288360858309\n",
      "train loss:0.0108481910001\n",
      "train loss:0.014040170004\n",
      "train loss:0.00772452914109\n",
      "train loss:0.00193466579164\n",
      "train loss:0.01705215716\n",
      "train loss:0.00443196365042\n",
      "train loss:0.00825626060197\n",
      "train loss:0.00689254763032\n",
      "train loss:0.0172555603379\n",
      "train loss:0.007280159167\n",
      "train loss:0.00230863527106\n",
      "train loss:0.00418102945173\n",
      "train loss:0.00241567955288\n",
      "train loss:0.0130296438291\n",
      "train loss:0.0028346070765\n",
      "train loss:0.00514389070873\n",
      "train loss:0.00168943920531\n",
      "train loss:0.00366040943024\n",
      "train loss:0.0121381648612\n",
      "train loss:0.0174160559026\n",
      "train loss:0.0039785139265\n",
      "train loss:0.00203792043037\n",
      "train loss:0.0196832074523\n",
      "train loss:0.00389978080778\n",
      "train loss:0.00414792161044\n",
      "train loss:0.0043606478627\n",
      "train loss:0.0089302073102\n",
      "train loss:0.0247271471843\n",
      "train loss:0.030395405248\n",
      "train loss:0.00781601087949\n",
      "train loss:0.00546570708557\n",
      "train loss:0.030887406697\n",
      "train loss:0.0233824682896\n",
      "train loss:0.0178883802644\n",
      "train loss:0.00950087959166\n",
      "train loss:0.00351465190588\n",
      "train loss:0.0311601097012\n",
      "train loss:0.0209751879572\n",
      "train loss:0.008702127915\n",
      "train loss:0.0132338784477\n",
      "train loss:0.0205283490479\n",
      "train loss:0.00425725254328\n",
      "train loss:0.0127887577299\n",
      "train loss:0.0420977528319\n",
      "train loss:0.0500263944724\n",
      "train loss:0.00474826714198\n",
      "train loss:0.00442198795377\n",
      "train loss:0.0110898291791\n",
      "train loss:0.0146104831162\n",
      "train loss:0.0243430744314\n",
      "train loss:0.0126463705874\n",
      "train loss:0.00721558192152\n",
      "train loss:0.00651864752253\n",
      "train loss:0.0047002744477\n",
      "train loss:0.0185664734522\n",
      "train loss:0.0116411518247\n",
      "train loss:0.00948966819814\n",
      "train loss:0.00799947410006\n",
      "train loss:0.0122515276241\n",
      "train loss:0.0112435498822\n",
      "train loss:0.00874822791228\n",
      "train loss:0.00830028713376\n",
      "train loss:0.00325413586047\n",
      "train loss:0.018660273209\n",
      "train loss:0.00535437396161\n",
      "train loss:0.00742641743794\n",
      "train loss:0.00269295176797\n",
      "train loss:0.0290400126413\n",
      "train loss:0.00437337380278\n",
      "train loss:0.00306810665511\n",
      "train loss:0.00568595635069\n",
      "train loss:0.024687430095\n",
      "train loss:0.00380775603504\n",
      "train loss:0.00530176534934\n",
      "train loss:0.0107686173407\n",
      "train loss:0.0288010264842\n",
      "train loss:0.00473486546385\n",
      "train loss:0.00341138085307\n",
      "train loss:0.0289750664363\n",
      "train loss:0.00497470038666\n",
      "train loss:0.00936577422989\n",
      "train loss:0.00628248261881\n",
      "train loss:0.00460669880721\n",
      "train loss:0.036606365664\n",
      "train loss:0.00231675346079\n",
      "train loss:0.0229810718693\n",
      "train loss:0.000623513317035\n",
      "train loss:0.00337656520085\n",
      "train loss:0.0112408265193\n",
      "train loss:0.00967382642064\n",
      "train loss:0.0895024956787\n",
      "train loss:0.0353617197298\n",
      "train loss:0.0105579420655\n",
      "train loss:0.00249969537792\n",
      "train loss:0.00749316456912\n",
      "train loss:0.00880311516611\n",
      "train loss:0.00311076635535\n",
      "train loss:0.0158181050976\n",
      "train loss:0.00495571949173\n",
      "train loss:0.0096798055394\n",
      "train loss:0.013403596588\n",
      "train loss:0.0181762065066\n",
      "train loss:0.0165042565427\n",
      "train loss:0.00871127581628\n",
      "train loss:0.024470817483\n",
      "train loss:0.00387480541446\n",
      "train loss:0.0297937129075\n",
      "train loss:0.123356546122\n",
      "train loss:0.00358676020541\n",
      "train loss:0.00705138211195\n",
      "train loss:0.00123291672543\n",
      "train loss:0.00308636573681\n",
      "train loss:0.00673904215749\n",
      "train loss:0.00282720019502\n",
      "train loss:0.0260057325272\n",
      "train loss:0.0147683448329\n",
      "train loss:0.00883708536756\n",
      "train loss:0.00354118390703\n",
      "train loss:0.0165806084773\n",
      "train loss:0.00701214882615\n",
      "train loss:0.0377788929558\n",
      "train loss:0.0128925323376\n",
      "train loss:0.0236647080743\n",
      "train loss:0.0139241575443\n",
      "train loss:0.0309360296571\n",
      "train loss:0.00303421596944\n",
      "train loss:0.00253533758605\n",
      "train loss:0.00940997568891\n",
      "train loss:0.0164873691786\n",
      "train loss:0.0101038037559\n",
      "train loss:0.00477268629899\n",
      "train loss:0.00393299341439\n",
      "train loss:0.0712454914382\n",
      "train loss:0.0279368652149\n",
      "train loss:0.0362505342298\n",
      "train loss:0.00845069296723\n",
      "train loss:0.0109152847358\n",
      "train loss:0.0563279248718\n",
      "train loss:0.00386803795616\n",
      "train loss:0.0249435171899\n",
      "train loss:0.0221666263089\n",
      "train loss:0.01474754286\n",
      "train loss:0.00475640107732\n",
      "train loss:0.00671178502991\n",
      "train loss:0.017374144968\n",
      "train loss:0.0123162140702\n",
      "train loss:0.00797169634929\n",
      "train loss:0.0396907740187\n",
      "train loss:0.017241692731\n",
      "train loss:0.0190389531319\n",
      "train loss:0.00570591051202\n",
      "train loss:0.00972923820104\n",
      "train loss:0.00557071892772\n",
      "train loss:0.00346665247704\n",
      "train loss:0.00995798151405\n",
      "train loss:0.0113666672661\n",
      "train loss:0.014323821507\n",
      "train loss:0.00662462496158\n",
      "train loss:0.00575525238661\n",
      "train loss:0.00928671728113\n",
      "train loss:0.0178143124794\n",
      "train loss:0.00309613742462\n",
      "train loss:0.015308460151\n",
      "train loss:0.0023406747233\n",
      "train loss:0.00604869247168\n",
      "=== epoch:9, train acc:0.993, test acc:0.991 ===\n",
      "train loss:0.02177115918\n",
      "train loss:0.0199479236137\n",
      "train loss:0.0276131265157\n",
      "train loss:0.0263850583744\n",
      "train loss:0.00605777190924\n",
      "train loss:0.00855317147763\n",
      "train loss:0.00790372022245\n",
      "train loss:0.0188617065785\n",
      "train loss:0.0412247440977\n",
      "train loss:0.00758830999366\n",
      "train loss:0.020906850684\n",
      "train loss:0.00319886933036\n",
      "train loss:0.0033695417981\n",
      "train loss:0.0255172558733\n",
      "train loss:0.0117478899469\n",
      "train loss:0.00381253064707\n",
      "train loss:0.0313101001853\n",
      "train loss:0.00912209222956\n",
      "train loss:0.00298272422485\n",
      "train loss:0.0136089882794\n",
      "train loss:0.000982677394578\n",
      "train loss:0.0026193022925\n",
      "train loss:0.0127877711018\n",
      "train loss:0.0855317007293\n",
      "train loss:0.0115010885918\n",
      "train loss:0.00370897218784\n",
      "train loss:0.0153014653364\n",
      "train loss:0.0156267648269\n",
      "train loss:0.00239105937645\n",
      "train loss:0.00239976387094\n",
      "train loss:0.0123167774675\n",
      "train loss:0.0169975790546\n",
      "train loss:0.0159405699805\n",
      "train loss:0.0352475975003\n",
      "train loss:0.00829106138328\n",
      "train loss:0.00486460348048\n",
      "train loss:0.111370633543\n",
      "train loss:0.00154473193394\n",
      "train loss:0.0144446905435\n",
      "train loss:0.0186913936764\n",
      "train loss:0.00815872477679\n",
      "train loss:0.00911986789098\n",
      "train loss:0.00681453217621\n",
      "train loss:0.00572545126763\n",
      "train loss:0.00602094682877\n",
      "train loss:0.0238839224295\n",
      "train loss:0.00463146596725\n",
      "train loss:0.0116875987626\n",
      "train loss:0.00937461505843\n",
      "train loss:0.0159402145588\n",
      "train loss:0.00513534975203\n",
      "train loss:0.0051126789971\n",
      "train loss:0.00251751019759\n",
      "train loss:0.00775275284908\n",
      "train loss:0.0131164896194\n",
      "train loss:0.00475977265834\n",
      "train loss:0.010614838439\n",
      "train loss:0.00491673430407\n",
      "train loss:0.0014537696253\n",
      "train loss:0.00523917743005\n",
      "train loss:0.0237768375105\n",
      "train loss:0.0155102189366\n",
      "train loss:0.00825114440189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0106368113836\n",
      "train loss:0.00927777152951\n",
      "train loss:0.00702441825853\n",
      "train loss:0.00482306958266\n",
      "train loss:0.00275196212634\n",
      "train loss:0.00991570395698\n",
      "train loss:0.00926045649756\n",
      "train loss:0.0304433561146\n",
      "train loss:0.0141050719006\n",
      "train loss:0.00577322599606\n",
      "train loss:0.00319141825923\n",
      "train loss:0.00727466358851\n",
      "train loss:0.00304386445937\n",
      "train loss:0.0104642346436\n",
      "train loss:0.00751318380342\n",
      "train loss:0.00367110000071\n",
      "train loss:0.00326572143824\n",
      "train loss:0.0133593742174\n",
      "train loss:0.0138449515269\n",
      "train loss:0.00421785939357\n",
      "train loss:0.000723470577549\n",
      "train loss:0.0027389335923\n",
      "train loss:0.00669322198086\n",
      "train loss:0.00390800163274\n",
      "train loss:0.0176123023826\n",
      "train loss:0.00363961904543\n",
      "train loss:0.00284472850482\n",
      "train loss:0.00159442601756\n",
      "train loss:0.00565631635947\n",
      "train loss:0.0119080252052\n",
      "train loss:0.00627527779841\n",
      "train loss:0.004288830588\n",
      "train loss:0.00865693680443\n",
      "train loss:0.00738055603621\n",
      "train loss:0.051264483793\n",
      "train loss:0.0151903422449\n",
      "train loss:0.0261831595839\n",
      "train loss:0.0143977782002\n",
      "train loss:0.0019383794338\n",
      "train loss:0.0029209445871\n",
      "train loss:0.0437141692424\n",
      "train loss:0.00599946554394\n",
      "train loss:0.00317304652728\n",
      "train loss:0.0168112907499\n",
      "train loss:0.0772547448018\n",
      "train loss:0.00478915541959\n",
      "train loss:0.00147052645226\n",
      "train loss:0.0219106740333\n",
      "train loss:0.012809268108\n",
      "train loss:0.0125383084557\n",
      "train loss:0.00133969591438\n",
      "train loss:0.0166815498721\n",
      "train loss:0.000678813522725\n",
      "train loss:0.0062157711765\n",
      "train loss:0.0118414715381\n",
      "train loss:0.00611150787575\n",
      "train loss:0.0146905080125\n",
      "train loss:0.0138915343631\n",
      "train loss:0.0107331178021\n",
      "train loss:0.0125391566332\n",
      "train loss:0.0271151171914\n",
      "train loss:0.0138764818856\n",
      "train loss:0.00819869744713\n",
      "train loss:0.00828345859147\n",
      "train loss:0.0108835105016\n",
      "train loss:0.0018520077169\n",
      "train loss:0.00451558660264\n",
      "train loss:0.0371958868066\n",
      "train loss:0.031165260116\n",
      "train loss:0.00873973782863\n",
      "train loss:0.0107303794596\n",
      "train loss:0.0179220525781\n",
      "train loss:0.02007428973\n",
      "train loss:0.050190866081\n",
      "train loss:0.00827078970089\n",
      "train loss:0.00383642499834\n",
      "train loss:0.00247726721571\n",
      "train loss:0.00756392730794\n",
      "train loss:0.00290453901637\n",
      "train loss:0.00775296592907\n",
      "train loss:0.00337193773513\n",
      "train loss:0.00603298879508\n",
      "train loss:0.00902271474062\n",
      "train loss:0.001709451665\n",
      "train loss:0.0049220988248\n",
      "train loss:0.00235861905085\n",
      "train loss:0.00563523930494\n",
      "train loss:0.0045363933391\n",
      "train loss:0.0114391027166\n",
      "train loss:0.00257681295432\n",
      "train loss:0.00468331576715\n",
      "train loss:0.0118411003663\n",
      "train loss:0.0112124758185\n",
      "train loss:0.0186138680762\n",
      "train loss:0.00736526194202\n",
      "train loss:0.000540476412285\n",
      "train loss:0.0106438026183\n",
      "train loss:0.0194788582268\n",
      "train loss:0.0105029242207\n",
      "train loss:0.00210698370379\n",
      "train loss:0.0315573339814\n",
      "train loss:0.0125528627931\n",
      "train loss:0.0248032553805\n",
      "train loss:0.0102995429852\n",
      "train loss:0.00518141840831\n",
      "train loss:0.0386728987016\n",
      "train loss:0.00286131167389\n",
      "train loss:0.0035696767313\n",
      "train loss:0.0108088677827\n",
      "train loss:0.00633773829657\n",
      "train loss:0.0131643857892\n",
      "train loss:0.00888493876026\n",
      "train loss:0.00346195449986\n",
      "train loss:0.000832079441181\n",
      "train loss:0.0099625925515\n",
      "train loss:0.0160591111656\n",
      "train loss:0.00910311814493\n",
      "train loss:0.00675706520395\n",
      "train loss:0.00265951120643\n",
      "train loss:0.0219470533653\n",
      "train loss:0.00273909982107\n",
      "train loss:0.00449208256816\n",
      "train loss:0.00604835471163\n",
      "train loss:0.00240437536722\n",
      "train loss:0.00205692610346\n",
      "train loss:0.0219704551404\n",
      "train loss:0.0010609604193\n",
      "train loss:0.0334592761519\n",
      "train loss:0.0349069846976\n",
      "train loss:0.00534492527152\n",
      "train loss:0.0256470357624\n",
      "train loss:0.0295293054039\n",
      "train loss:0.00156125289665\n",
      "train loss:0.00134321112235\n",
      "train loss:0.00911168291515\n",
      "train loss:0.00436654330651\n",
      "train loss:0.00511292210626\n",
      "train loss:0.0063688588422\n",
      "train loss:0.00481920394913\n",
      "train loss:0.00523421452655\n",
      "train loss:0.0336747033856\n",
      "train loss:0.00610744820107\n",
      "train loss:0.00989608543996\n",
      "train loss:0.00151077646792\n",
      "train loss:0.00411207034977\n",
      "train loss:0.0064175388779\n",
      "train loss:0.00458318138133\n",
      "train loss:0.0054443105511\n",
      "train loss:0.00679829940124\n",
      "train loss:0.00606173977713\n",
      "train loss:0.000465099575063\n",
      "train loss:0.00501616921868\n",
      "train loss:0.00437786869751\n",
      "train loss:0.00750506641815\n",
      "train loss:0.00398008370401\n",
      "train loss:0.00705993012533\n",
      "train loss:0.00544897570891\n",
      "train loss:0.00766165716458\n",
      "train loss:0.0049940029347\n",
      "train loss:0.00190138568028\n",
      "train loss:0.00186449264275\n",
      "train loss:0.00696395088412\n",
      "train loss:0.000550320217316\n",
      "train loss:0.0016435035597\n",
      "train loss:0.00680244746031\n",
      "train loss:0.00387581001854\n",
      "train loss:0.00135114348591\n",
      "train loss:0.0335007825341\n",
      "train loss:0.00551978490123\n",
      "train loss:0.00261235610801\n",
      "train loss:0.00731785540908\n",
      "train loss:0.00343866836056\n",
      "train loss:0.00522963929136\n",
      "train loss:0.00376277674369\n",
      "train loss:0.00608318890198\n",
      "train loss:0.0046683939237\n",
      "train loss:0.00575429654873\n",
      "train loss:0.0181230488337\n",
      "train loss:0.00679343655419\n",
      "train loss:0.00848655284205\n",
      "train loss:0.00397492475439\n",
      "train loss:0.0138407337019\n",
      "train loss:0.000747697790332\n",
      "train loss:0.00327542585186\n",
      "train loss:0.000979813335424\n",
      "train loss:0.00209118748732\n",
      "train loss:0.00162460722769\n",
      "train loss:0.00757332846472\n",
      "train loss:0.00402806685384\n",
      "train loss:0.00435297107316\n",
      "train loss:0.000339403133861\n",
      "train loss:0.037467150601\n",
      "train loss:0.00608284748772\n",
      "train loss:0.00410198460337\n",
      "train loss:0.0132752459811\n",
      "train loss:0.00816061032716\n",
      "train loss:0.0239386094098\n",
      "train loss:0.00555136528985\n",
      "train loss:0.0105414399148\n",
      "train loss:0.0032183402748\n",
      "train loss:0.00914175141092\n",
      "train loss:0.00652350683551\n",
      "train loss:0.00382863870568\n",
      "train loss:0.000934250080436\n",
      "train loss:0.00387891175835\n",
      "train loss:0.0198086961288\n",
      "train loss:0.0151866913718\n",
      "train loss:0.00536986900878\n",
      "train loss:0.00475799172087\n",
      "train loss:0.00770554237348\n",
      "train loss:0.00183518456298\n",
      "train loss:0.0229180619506\n",
      "train loss:0.0016229716852\n",
      "train loss:0.00285426874636\n",
      "train loss:0.00120086632994\n",
      "train loss:0.0108035404285\n",
      "train loss:0.00196854774315\n",
      "train loss:0.0132313738446\n",
      "train loss:0.00403130885432\n",
      "train loss:0.00585997298491\n",
      "train loss:0.00116667688281\n",
      "train loss:0.0162916466441\n",
      "train loss:0.00207415146208\n",
      "train loss:0.00642890613147\n",
      "train loss:0.000771516188407\n",
      "train loss:0.00682855547609\n",
      "train loss:0.00199982720549\n",
      "train loss:0.004562286055\n",
      "train loss:0.00843109728939\n",
      "train loss:0.0161769742313\n",
      "train loss:0.00773419092411\n",
      "train loss:0.0223616501887\n",
      "train loss:0.00606759253762\n",
      "train loss:0.0165008602908\n",
      "train loss:0.0243088644954\n",
      "train loss:0.00139089747618\n",
      "train loss:0.006295747437\n",
      "train loss:0.00119679068863\n",
      "train loss:0.00297215423233\n",
      "train loss:0.00348143918124\n",
      "train loss:0.0124378534984\n",
      "train loss:0.00363708213592\n",
      "train loss:0.0103183941039\n",
      "train loss:0.0131766782659\n",
      "train loss:0.00218161337925\n",
      "train loss:0.0246883843722\n",
      "train loss:0.000192640393758\n",
      "train loss:0.0138965792629\n",
      "train loss:0.00202214087622\n",
      "train loss:0.0119216172435\n",
      "train loss:0.0310504068494\n",
      "train loss:0.00871676896306\n",
      "train loss:0.00468397933082\n",
      "train loss:0.028051345766\n",
      "train loss:0.036863296673\n",
      "train loss:0.0118297503656\n",
      "train loss:0.00570937600704\n",
      "train loss:0.0264974157138\n",
      "train loss:0.0119237962741\n",
      "train loss:0.00304829082352\n",
      "train loss:0.0204954663676\n",
      "train loss:0.00969725171551\n",
      "train loss:0.0156074681119\n",
      "train loss:0.0288809527812\n",
      "train loss:0.00316757669709\n",
      "train loss:0.0169792276508\n",
      "train loss:0.00404777617296\n",
      "train loss:0.0154855157785\n",
      "train loss:0.0150420972835\n",
      "train loss:0.00179666071898\n",
      "train loss:0.0180886612477\n",
      "train loss:0.0148811836997\n",
      "train loss:0.00642946895706\n",
      "train loss:0.00391357830037\n",
      "train loss:0.00575903496573\n",
      "train loss:0.0109043999254\n",
      "train loss:0.00179791164358\n",
      "train loss:0.00469824048487\n",
      "train loss:0.000725985262965\n",
      "train loss:0.00924750506778\n",
      "train loss:0.0038738674895\n",
      "train loss:0.0164080564278\n",
      "train loss:0.00747282156906\n",
      "train loss:0.0284793679421\n",
      "train loss:0.00374251833844\n",
      "train loss:0.000683917022466\n",
      "train loss:0.00237213835218\n",
      "train loss:0.00139963286501\n",
      "train loss:0.0304899896204\n",
      "train loss:0.0235497985766\n",
      "train loss:0.00711466478051\n",
      "train loss:0.00366471027226\n",
      "train loss:0.0283120898307\n",
      "train loss:0.0246523322148\n",
      "train loss:0.00449288848456\n",
      "train loss:0.0025606263496\n",
      "train loss:0.00738462667327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00155722822544\n",
      "train loss:0.0112887057264\n",
      "train loss:0.00212891398781\n",
      "train loss:0.0142073369191\n",
      "train loss:0.00391736110538\n",
      "train loss:0.0194207771914\n",
      "train loss:0.0140581638135\n",
      "train loss:0.0302529063361\n",
      "train loss:0.00114097840562\n",
      "train loss:0.00503532583744\n",
      "train loss:0.00588640762981\n",
      "train loss:0.0342059291141\n",
      "train loss:0.00153140204139\n",
      "train loss:0.00264629735282\n",
      "train loss:0.0329663335654\n",
      "train loss:0.00654489566285\n",
      "train loss:0.00624743600415\n",
      "train loss:0.00351016500105\n",
      "train loss:0.00273437274404\n",
      "train loss:0.00448526448938\n",
      "train loss:0.00322805468737\n",
      "train loss:0.00511542587679\n",
      "train loss:0.0145189728485\n",
      "train loss:0.0035953293505\n",
      "train loss:0.0086807816135\n",
      "train loss:0.000949801809512\n",
      "train loss:0.00329605200433\n",
      "train loss:0.0237141069659\n",
      "train loss:0.00293000947204\n",
      "train loss:0.0215634369554\n",
      "train loss:0.0172040605197\n",
      "train loss:0.0218843868023\n",
      "train loss:0.00352161070009\n",
      "train loss:0.00586692772082\n",
      "train loss:0.00401523404872\n",
      "train loss:0.00132905995509\n",
      "train loss:0.0302115222394\n",
      "train loss:0.0208352532782\n",
      "train loss:0.00457352523319\n",
      "train loss:0.00292836211905\n",
      "train loss:0.0139164454503\n",
      "train loss:0.00234478344811\n",
      "train loss:0.0054359599741\n",
      "train loss:0.00513118145898\n",
      "train loss:0.013096748486\n",
      "train loss:0.00272613891553\n",
      "train loss:0.0040334274735\n",
      "train loss:0.022134802669\n",
      "train loss:0.00752063035418\n",
      "train loss:0.000184611800856\n",
      "train loss:0.0126286684499\n",
      "train loss:0.0127282261833\n",
      "train loss:0.00199407715913\n",
      "train loss:0.0101416164761\n",
      "train loss:0.0269699246597\n",
      "train loss:0.00506215741903\n",
      "train loss:0.0028022436798\n",
      "train loss:0.00431580551142\n",
      "train loss:0.00271375290585\n",
      "train loss:0.00134712749966\n",
      "train loss:0.0340978409198\n",
      "train loss:0.00972602314248\n",
      "train loss:0.00873142610673\n",
      "train loss:0.0111378102242\n",
      "train loss:0.00167142010252\n",
      "train loss:0.0168887824733\n",
      "train loss:0.0444591234242\n",
      "train loss:0.0138405533391\n",
      "train loss:0.0222432354434\n",
      "train loss:0.009586566867\n",
      "train loss:0.0227750021563\n",
      "train loss:0.00432881344138\n",
      "train loss:0.00509168917998\n",
      "train loss:0.0198998710276\n",
      "train loss:0.00690276607229\n",
      "train loss:0.00453293182841\n",
      "train loss:0.00902008021749\n",
      "train loss:0.012697338642\n",
      "train loss:0.0061690334184\n",
      "train loss:0.0123233717267\n",
      "train loss:0.0126810655004\n",
      "train loss:0.00535103876067\n",
      "train loss:0.0248456889298\n",
      "train loss:0.00490692119441\n",
      "train loss:0.0075030009755\n",
      "train loss:0.00493358351767\n",
      "train loss:0.0137524101956\n",
      "train loss:0.00105191336302\n",
      "train loss:0.00223280076294\n",
      "train loss:0.00123671533521\n",
      "train loss:0.0202401598843\n",
      "train loss:0.00785411131245\n",
      "train loss:0.0291443010768\n",
      "train loss:0.0187514629264\n",
      "train loss:0.00171725449333\n",
      "train loss:0.00366658944878\n",
      "train loss:0.000741954319441\n",
      "train loss:0.025144722097\n",
      "train loss:0.00152767728502\n",
      "train loss:0.000250298293322\n",
      "train loss:0.0199709784242\n",
      "train loss:0.00671966197377\n",
      "train loss:0.00317070182925\n",
      "train loss:0.00214930654153\n",
      "train loss:0.00468751172472\n",
      "train loss:0.00777999193597\n",
      "train loss:0.00396393823308\n",
      "train loss:0.0125166815913\n",
      "train loss:0.00258649127627\n",
      "train loss:0.0354095065911\n",
      "train loss:0.0048209737389\n",
      "train loss:0.00114551559664\n",
      "train loss:0.137808866973\n",
      "train loss:0.0147350524718\n",
      "train loss:0.00289777354505\n",
      "train loss:0.00890869588644\n",
      "train loss:0.00985927261517\n",
      "train loss:0.0103993120693\n",
      "train loss:0.0170036866537\n",
      "train loss:0.0231125681182\n",
      "train loss:0.00881359059593\n",
      "train loss:0.0165148517105\n",
      "train loss:0.00250969398239\n",
      "train loss:0.0055753054955\n",
      "train loss:0.0273325080113\n",
      "train loss:0.00879790085484\n",
      "train loss:0.0130059136224\n",
      "train loss:0.00267763481323\n",
      "train loss:0.00916465106186\n",
      "train loss:0.0052081983285\n",
      "train loss:0.0256131019152\n",
      "train loss:0.0145221645617\n",
      "train loss:0.00415260776224\n",
      "train loss:0.0232258592084\n",
      "train loss:0.00569075953823\n",
      "train loss:0.00206567626472\n",
      "train loss:0.00188118292891\n",
      "train loss:0.0436672009741\n",
      "train loss:0.0243242978589\n",
      "train loss:0.00835070972937\n",
      "train loss:0.00418853380314\n",
      "train loss:0.00915385543431\n",
      "train loss:0.00875890145858\n",
      "train loss:0.000847469660238\n",
      "train loss:0.00165922622173\n",
      "train loss:0.00696280836435\n",
      "train loss:0.0113027929689\n",
      "train loss:0.00785686493609\n",
      "train loss:0.00909520513715\n",
      "train loss:0.00261867532482\n",
      "train loss:0.0455185151315\n",
      "train loss:0.0795558973609\n",
      "train loss:0.0236148195912\n",
      "train loss:0.00817835603817\n",
      "train loss:0.00920174263403\n",
      "train loss:0.00311238808625\n",
      "train loss:0.0112234177512\n",
      "train loss:0.000766994830224\n",
      "train loss:0.00798653444515\n",
      "train loss:0.00529275485716\n",
      "train loss:0.00235206502495\n",
      "train loss:0.00857577380085\n",
      "train loss:0.00525522985701\n",
      "train loss:0.0199693439312\n",
      "train loss:0.00392994966661\n",
      "train loss:0.0038986783176\n",
      "train loss:0.00853571425598\n",
      "train loss:0.0420240435517\n",
      "train loss:0.00327702380198\n",
      "train loss:0.00838370659669\n",
      "train loss:0.000935858977566\n",
      "train loss:0.00129946408917\n",
      "train loss:0.00186150427267\n",
      "train loss:0.0109512589964\n",
      "train loss:0.0156422291928\n",
      "train loss:0.00597720982038\n",
      "train loss:0.00154403795895\n",
      "train loss:0.0017266203758\n",
      "train loss:0.00483616852461\n",
      "train loss:0.00620103101494\n",
      "train loss:0.00206298367491\n",
      "train loss:0.00220382486268\n",
      "train loss:0.0021161181073\n",
      "train loss:0.00262311475051\n",
      "train loss:0.00527976002649\n",
      "train loss:0.00765945333727\n",
      "train loss:0.00579871687799\n",
      "train loss:0.00313317283667\n",
      "train loss:0.00754572875052\n",
      "train loss:0.00362065602755\n",
      "train loss:0.000591261253102\n",
      "train loss:0.00484798029879\n",
      "train loss:0.00505979613279\n",
      "train loss:0.00423643954161\n",
      "train loss:0.0033331973159\n",
      "train loss:0.00179628025466\n",
      "train loss:0.000809256648388\n",
      "train loss:0.00352435307831\n",
      "train loss:0.000922991308408\n",
      "train loss:0.000800898665507\n",
      "train loss:0.00375736103094\n",
      "train loss:0.00572105956932\n",
      "train loss:0.00224073404579\n",
      "train loss:0.00672426431191\n",
      "train loss:0.00292607341801\n",
      "train loss:0.00476925337972\n",
      "train loss:0.0027390212623\n",
      "train loss:0.00671244886534\n",
      "train loss:0.0065827695758\n",
      "train loss:0.00777170569996\n",
      "train loss:0.00657516685965\n",
      "train loss:0.00737903178369\n",
      "train loss:0.0138466299282\n",
      "train loss:0.0283324076276\n",
      "train loss:0.0089327401086\n",
      "train loss:0.000707349752475\n",
      "train loss:0.00513794929205\n",
      "train loss:0.0117759363582\n",
      "train loss:0.00582835795294\n",
      "train loss:0.0103549779009\n",
      "train loss:0.00288607693255\n",
      "train loss:0.00165422015438\n",
      "train loss:0.00171670595675\n",
      "train loss:0.00163896780802\n",
      "train loss:0.00600870741051\n",
      "train loss:0.0122382921676\n",
      "train loss:0.077805117935\n",
      "train loss:0.000353863535045\n",
      "train loss:0.0853827512941\n",
      "train loss:0.00383092187615\n",
      "train loss:0.0142399403778\n",
      "train loss:0.00673673445623\n",
      "train loss:0.0139580395173\n",
      "train loss:0.00139365438702\n",
      "train loss:0.00447515068599\n",
      "train loss:0.00262406623446\n",
      "train loss:0.00190209258402\n",
      "train loss:0.00152844164252\n",
      "train loss:0.000899230744829\n",
      "train loss:0.00261887195753\n",
      "=== epoch:10, train acc:0.99, test acc:0.988 ===\n",
      "train loss:0.00268360585476\n",
      "train loss:0.0048376839869\n",
      "train loss:0.00168534371305\n",
      "train loss:0.00386640278472\n",
      "train loss:0.0034120114643\n",
      "train loss:0.000649473963021\n",
      "train loss:0.0122933548151\n",
      "train loss:0.0401544265945\n",
      "train loss:0.00262938317882\n",
      "train loss:0.000764156807586\n",
      "train loss:0.00212469860439\n",
      "train loss:0.0217869883891\n",
      "train loss:0.00576623857294\n",
      "train loss:0.00943955770276\n",
      "train loss:0.00841448752493\n",
      "train loss:0.0410252813113\n",
      "train loss:0.0113837167047\n",
      "train loss:0.00165015056982\n",
      "train loss:0.00426078033844\n",
      "train loss:0.000524127703106\n",
      "train loss:0.00262190186042\n",
      "train loss:0.0137365384132\n",
      "train loss:0.00549180724189\n",
      "train loss:0.0200105758973\n",
      "train loss:0.000537658115916\n",
      "train loss:0.00549181291168\n",
      "train loss:0.00368752478712\n",
      "train loss:0.00154015129804\n",
      "train loss:0.00630523718963\n",
      "train loss:0.00636673810466\n",
      "train loss:0.016759859023\n",
      "train loss:0.0058114252893\n",
      "train loss:0.0011461577368\n",
      "train loss:0.00691727724417\n",
      "train loss:0.0187917711632\n",
      "train loss:0.0242601860247\n",
      "train loss:0.00886785049495\n",
      "train loss:0.000745621267065\n",
      "train loss:0.00200865491168\n",
      "train loss:0.00120920639071\n",
      "train loss:0.00100879243588\n",
      "train loss:0.00160594695178\n",
      "train loss:0.0157058066939\n",
      "train loss:0.0179948742546\n",
      "train loss:0.0051138876958\n",
      "train loss:0.0117931222191\n",
      "train loss:0.00363668714601\n",
      "train loss:0.00486495217165\n",
      "train loss:0.0077827954727\n",
      "train loss:0.00696074059501\n",
      "train loss:0.00107360211586\n",
      "train loss:0.00714814235979\n",
      "train loss:0.00592637269832\n",
      "train loss:0.00534594777443\n",
      "train loss:0.00372122914579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00952484597255\n",
      "train loss:0.000392033107935\n",
      "train loss:0.0125258916248\n",
      "train loss:0.00423284290508\n",
      "train loss:0.00299773518631\n",
      "train loss:0.00573015695741\n",
      "train loss:0.00163474800242\n",
      "train loss:0.00159529604994\n",
      "train loss:0.00032019469066\n",
      "train loss:0.00201076726771\n",
      "train loss:0.011610649371\n",
      "train loss:0.00558642206905\n",
      "train loss:0.00709060996744\n",
      "train loss:0.00152503806224\n",
      "train loss:0.000955831058164\n",
      "train loss:0.000939743646357\n",
      "train loss:0.016431825803\n",
      "train loss:0.00811912430706\n",
      "train loss:0.00675719189993\n",
      "train loss:0.00381938765445\n",
      "train loss:0.00460389562788\n",
      "train loss:0.00555958567525\n",
      "train loss:0.00183509671679\n",
      "train loss:0.0164224823617\n",
      "train loss:0.0072554200173\n",
      "train loss:0.00309611360819\n",
      "train loss:0.0113641667837\n",
      "train loss:0.000626641526644\n",
      "train loss:0.00439158873882\n",
      "train loss:0.00211484133969\n",
      "train loss:0.0162011659097\n",
      "train loss:0.0038170654672\n",
      "train loss:0.00917801488578\n",
      "train loss:0.0141593495117\n",
      "train loss:0.00524132748669\n",
      "train loss:0.000650536347425\n",
      "train loss:0.00529864675295\n",
      "train loss:0.0492825552334\n",
      "train loss:0.00588147114807\n",
      "train loss:0.00210487633842\n",
      "train loss:0.061141472925\n",
      "train loss:0.00136183100826\n",
      "train loss:0.00178889003009\n",
      "train loss:0.00872859084846\n",
      "train loss:0.00260715403886\n",
      "train loss:0.00320693813036\n",
      "train loss:0.0123613747116\n",
      "train loss:0.0116467231972\n",
      "train loss:0.0162613915382\n",
      "train loss:0.00646585972612\n",
      "train loss:0.00369927027631\n",
      "train loss:0.00259317136727\n",
      "train loss:0.00615110018651\n",
      "train loss:0.00489996242731\n",
      "train loss:0.00759987077485\n",
      "train loss:0.00922871337296\n",
      "train loss:0.0925997679244\n",
      "train loss:0.0124600634251\n",
      "train loss:0.0111217308116\n",
      "train loss:0.00459441348297\n",
      "train loss:0.0101279324138\n",
      "train loss:0.00468469946438\n",
      "train loss:0.00330719203287\n",
      "train loss:0.00479244854681\n",
      "train loss:0.00599149628071\n",
      "train loss:0.0278141408245\n",
      "train loss:0.00723914149362\n",
      "train loss:0.00111737415543\n",
      "train loss:0.0300395556044\n",
      "train loss:0.00708867826187\n",
      "train loss:0.0226349549839\n",
      "train loss:0.00127447138778\n",
      "train loss:0.00415162676221\n",
      "train loss:0.00428009686967\n",
      "train loss:0.0280242361296\n",
      "train loss:0.00585078198374\n",
      "train loss:0.00237662115554\n",
      "train loss:0.00315122216824\n",
      "train loss:0.00418206794577\n",
      "train loss:0.00432177050137\n",
      "train loss:0.00353860033358\n",
      "train loss:0.00336500691449\n",
      "train loss:0.00179543688343\n",
      "train loss:0.0408225902223\n",
      "train loss:0.00201002505203\n",
      "train loss:0.00273938791114\n",
      "train loss:0.00190038483903\n",
      "train loss:0.00436571577333\n",
      "train loss:0.0070007764434\n",
      "train loss:0.0733525300265\n",
      "train loss:0.0331461394768\n",
      "train loss:0.0273693106669\n",
      "train loss:0.000949967953646\n",
      "train loss:0.0017695092751\n",
      "train loss:0.00553361130835\n",
      "train loss:0.0328782706838\n",
      "train loss:0.019895114999\n",
      "train loss:0.0133836550222\n",
      "train loss:0.000660825869092\n",
      "train loss:0.0138634397585\n",
      "train loss:0.00534510640353\n",
      "train loss:0.00497064447692\n",
      "train loss:0.0139063573576\n",
      "train loss:0.00731207063515\n",
      "train loss:0.00721814573173\n",
      "train loss:0.00209391372535\n",
      "train loss:0.00340829648996\n",
      "train loss:0.005204771957\n",
      "train loss:0.00195120464484\n",
      "train loss:0.00083095772046\n",
      "train loss:0.00344951434132\n",
      "train loss:0.0100362618812\n",
      "train loss:0.00151539468835\n",
      "train loss:0.00524557709782\n",
      "train loss:0.00230820155749\n",
      "train loss:0.0146627244913\n",
      "train loss:0.00508863863209\n",
      "train loss:0.0252361547545\n",
      "train loss:0.00135308626807\n",
      "train loss:0.0159785577796\n",
      "train loss:0.00706246834389\n",
      "train loss:0.00024947561305\n",
      "train loss:0.00496089742678\n",
      "train loss:0.000636155852603\n",
      "train loss:0.00901340855687\n",
      "train loss:0.00791190588239\n",
      "train loss:0.00924973949385\n",
      "train loss:0.0282782541019\n",
      "train loss:0.00456768959106\n",
      "train loss:0.011430326587\n",
      "train loss:0.00143119057118\n",
      "train loss:0.00498633917582\n",
      "train loss:0.00590501618873\n",
      "train loss:0.000606172718813\n",
      "train loss:0.00949138008547\n",
      "train loss:0.0330115471087\n",
      "train loss:0.00153580219474\n",
      "train loss:0.0073174857153\n",
      "train loss:0.00182007948101\n",
      "train loss:0.00476248505862\n",
      "train loss:0.00616859392372\n",
      "train loss:0.00370662990466\n",
      "train loss:0.00575203113801\n",
      "train loss:0.00152618496436\n",
      "train loss:0.00318159829741\n",
      "train loss:0.0348014592784\n",
      "train loss:0.057198809056\n",
      "train loss:0.0261432079996\n",
      "train loss:0.00307724973294\n",
      "train loss:0.00277724284395\n",
      "train loss:0.00160052239298\n",
      "train loss:0.00343613687432\n",
      "train loss:0.0358255107426\n",
      "train loss:0.00217862749262\n",
      "train loss:0.0114717993904\n",
      "train loss:0.0296324330753\n",
      "train loss:0.00161487288756\n",
      "train loss:0.0227183360019\n",
      "train loss:0.0201335979455\n",
      "train loss:0.0147906460339\n",
      "train loss:0.000444156194713\n",
      "train loss:0.0217346386454\n",
      "train loss:0.0381949575055\n",
      "train loss:0.00201919521778\n",
      "train loss:0.0143293111279\n",
      "train loss:0.0147997220226\n",
      "train loss:0.0109026769347\n",
      "train loss:0.00309614421376\n",
      "train loss:0.0043892415139\n",
      "train loss:0.0118482823795\n",
      "train loss:0.00518019422946\n",
      "train loss:0.0598712935746\n",
      "train loss:0.00235525281079\n",
      "train loss:0.00533717022685\n",
      "train loss:0.00196686518189\n",
      "train loss:0.00930123208214\n",
      "train loss:0.00618160048802\n",
      "train loss:0.00181714310732\n",
      "train loss:0.000911859693882\n",
      "train loss:0.0100262467029\n",
      "train loss:0.0186161119828\n",
      "train loss:0.00955649514645\n",
      "train loss:0.0291697374635\n",
      "train loss:0.0105761192431\n",
      "train loss:0.0114219715303\n",
      "train loss:0.00131598151561\n",
      "train loss:0.0323491715014\n",
      "train loss:0.0128944630545\n",
      "train loss:0.00420994618197\n",
      "train loss:0.00808205287561\n",
      "train loss:0.00751764803857\n",
      "train loss:0.00235307276272\n",
      "train loss:0.00706322214976\n",
      "train loss:0.00675379789333\n",
      "train loss:0.0030035909871\n",
      "train loss:0.00129261078067\n",
      "train loss:0.00721353225271\n",
      "train loss:0.0261729509324\n",
      "train loss:0.00542305997377\n",
      "train loss:0.0336164295737\n",
      "train loss:0.00563401574118\n",
      "train loss:0.00563734395679\n",
      "train loss:0.00274773666104\n",
      "train loss:0.00362492120604\n",
      "train loss:0.00224699652169\n",
      "train loss:0.00300050375334\n",
      "train loss:0.00190312274085\n",
      "train loss:0.00418772901722\n",
      "train loss:0.00924081203913\n",
      "train loss:0.00330463888091\n",
      "train loss:0.00478676121882\n",
      "train loss:0.00282952918316\n",
      "train loss:0.00804418557381\n",
      "train loss:0.00659255202671\n",
      "train loss:0.0245340709623\n",
      "train loss:0.000969165394817\n",
      "train loss:0.00901827262693\n",
      "train loss:0.001552107483\n",
      "train loss:0.0266114717003\n",
      "train loss:0.00432400770689\n",
      "train loss:0.00468347865912\n",
      "train loss:0.0130058554347\n",
      "train loss:0.00306420029725\n",
      "train loss:0.0110520527213\n",
      "train loss:0.0330402319857\n",
      "train loss:0.0147825172458\n",
      "train loss:0.0334165149009\n",
      "train loss:0.0024707559595\n",
      "train loss:0.00442244206077\n",
      "train loss:0.00191506522784\n",
      "train loss:0.00154084049962\n",
      "train loss:0.108493950276\n",
      "train loss:0.000664011925503\n",
      "train loss:0.00325967887942\n",
      "train loss:0.0023789759028\n",
      "train loss:0.00439677948935\n",
      "train loss:0.00637939975587\n",
      "train loss:0.00664042340966\n",
      "train loss:0.00543522075953\n",
      "train loss:0.00522101909773\n",
      "train loss:0.0165076326452\n",
      "train loss:0.00326760536136\n",
      "train loss:0.00146627412174\n",
      "train loss:0.004203808831\n",
      "train loss:0.00723274105087\n",
      "train loss:0.0048373634672\n",
      "train loss:0.0051479729083\n",
      "train loss:0.0148910270153\n",
      "train loss:0.00333201467284\n",
      "train loss:0.012187166612\n",
      "train loss:0.00296483912347\n",
      "train loss:0.00314489685588\n",
      "train loss:0.00343252527865\n",
      "train loss:0.00134160974549\n",
      "train loss:0.00597892515225\n",
      "train loss:0.000623259374206\n",
      "train loss:0.0382071953566\n",
      "train loss:0.00464362785344\n",
      "train loss:0.00672010143656\n",
      "train loss:0.00453891709413\n",
      "train loss:0.0205909017465\n",
      "train loss:0.00634606774692\n",
      "train loss:0.00580632683565\n",
      "train loss:0.00951779927728\n",
      "train loss:0.00291723199622\n",
      "train loss:0.00387308045529\n",
      "train loss:0.00347354055008\n",
      "train loss:0.0173781581301\n",
      "train loss:0.00656736882416\n",
      "train loss:0.00496810552379\n",
      "train loss:0.0242356756206\n",
      "train loss:0.00669829684551\n",
      "train loss:0.0116130741253\n",
      "train loss:0.0287676157559\n",
      "train loss:0.0115693202524\n",
      "train loss:0.00828947607704\n",
      "train loss:0.00119665724081\n",
      "train loss:0.0148973060479\n",
      "train loss:0.00120194093286\n",
      "train loss:0.0109674250139\n",
      "train loss:0.001909515455\n",
      "train loss:0.00354863333184\n",
      "train loss:0.00253059697826\n",
      "train loss:0.00149010906831\n",
      "train loss:0.00255789403098\n",
      "train loss:0.00202970554378\n",
      "train loss:0.0015338827308\n",
      "train loss:0.00431315288705\n",
      "train loss:0.00386751793258\n",
      "train loss:0.0114955961199\n",
      "train loss:0.00389744497124\n",
      "train loss:0.0109913742522\n",
      "train loss:0.00624293176047\n",
      "train loss:0.00152335495954\n",
      "train loss:0.00445572715427\n",
      "train loss:0.00328652511895\n",
      "train loss:0.0116106604629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0246683366518\n",
      "train loss:0.00248045193073\n",
      "train loss:0.000499553140837\n",
      "train loss:0.122155970735\n",
      "train loss:0.0088453040979\n",
      "train loss:0.0101921119935\n",
      "train loss:0.00871293625447\n",
      "train loss:0.00728766841584\n",
      "train loss:0.00223017662047\n",
      "train loss:0.00634476791159\n",
      "train loss:0.0043000730027\n",
      "train loss:0.00281259614001\n",
      "train loss:0.0023379710692\n",
      "train loss:0.106832399758\n",
      "train loss:0.00506705678284\n",
      "train loss:0.00906986998492\n",
      "train loss:0.00628998829302\n",
      "train loss:0.00454946732042\n",
      "train loss:0.00416329847924\n",
      "train loss:0.00501932390995\n",
      "train loss:0.00317942760737\n",
      "train loss:0.0107050359665\n",
      "train loss:0.0090100294322\n",
      "train loss:0.00446030706891\n",
      "train loss:0.00304342736079\n",
      "train loss:0.00214509816416\n",
      "train loss:0.00421016714396\n",
      "train loss:0.00344302236367\n",
      "train loss:0.00739998627818\n",
      "train loss:0.00556279158139\n",
      "train loss:0.0185403710719\n",
      "train loss:0.00408458181604\n",
      "train loss:0.00166884097121\n",
      "train loss:0.0024138623588\n",
      "train loss:0.00179077285413\n",
      "train loss:0.0078724498567\n",
      "train loss:0.000846134850843\n",
      "train loss:0.00478481639536\n",
      "train loss:0.00387535867\n",
      "train loss:0.00519848321111\n",
      "train loss:0.00432939395917\n",
      "train loss:0.00608426597061\n",
      "train loss:0.00205256731727\n",
      "train loss:0.00749971611241\n",
      "train loss:0.0107216096053\n",
      "train loss:0.00347158286639\n",
      "train loss:0.00115581501387\n",
      "train loss:0.00603789067548\n",
      "train loss:0.00772898045076\n",
      "train loss:0.00757902011664\n",
      "train loss:0.00323718002705\n",
      "train loss:0.00126961145737\n",
      "train loss:0.00697824329329\n",
      "train loss:0.00210963467371\n",
      "train loss:0.0139131806222\n",
      "train loss:0.00768905172002\n",
      "train loss:0.0182982116657\n",
      "train loss:0.00763971265695\n",
      "train loss:0.0342605634033\n",
      "train loss:0.00585080303116\n",
      "train loss:0.00319953718531\n",
      "train loss:0.0435742361338\n",
      "train loss:0.00255422766104\n",
      "train loss:0.0149512078741\n",
      "train loss:0.00567987110452\n",
      "train loss:0.0142626718003\n",
      "train loss:0.01148801645\n",
      "train loss:0.024728333023\n",
      "train loss:0.00575895207544\n",
      "train loss:0.023849557033\n",
      "train loss:0.00831569363099\n",
      "train loss:0.00321452185601\n",
      "train loss:0.00164038414226\n",
      "train loss:0.00583653744113\n",
      "train loss:0.0119281316826\n",
      "train loss:0.0010592321426\n",
      "train loss:0.0346240931279\n",
      "train loss:0.00918671273929\n",
      "train loss:0.00195536723088\n",
      "train loss:0.00868060918854\n",
      "train loss:0.00287964522883\n",
      "train loss:0.00111008545141\n",
      "train loss:0.00209299888629\n",
      "train loss:0.00223639359051\n",
      "train loss:0.00678078230708\n",
      "train loss:0.00752664610683\n",
      "train loss:0.0531875053271\n",
      "train loss:0.00301406574912\n",
      "train loss:0.00255253705467\n",
      "train loss:0.00124116835514\n",
      "train loss:0.00466072162357\n",
      "train loss:0.0107507822818\n",
      "train loss:0.00129947766897\n",
      "train loss:0.00411082369818\n",
      "train loss:0.0570820235086\n",
      "train loss:0.00227075154943\n",
      "train loss:0.00879270785414\n",
      "train loss:0.00542272222098\n",
      "train loss:0.0181851325228\n",
      "train loss:0.00932849528297\n",
      "train loss:0.00297614880696\n",
      "train loss:0.0242909502101\n",
      "train loss:0.0131198856161\n",
      "train loss:0.00944733629282\n",
      "train loss:0.0010497364813\n",
      "train loss:0.0192671328567\n",
      "train loss:0.00921864908064\n",
      "train loss:0.0111755139989\n",
      "train loss:0.00885908211818\n",
      "train loss:0.00598865326217\n",
      "train loss:0.0220668668017\n",
      "train loss:0.00562519839307\n",
      "train loss:0.00186567422946\n",
      "train loss:0.000915167014437\n",
      "train loss:0.0082956242486\n",
      "train loss:0.00218860589475\n",
      "train loss:0.00122939644125\n",
      "train loss:0.00185097187336\n",
      "train loss:0.00223981822966\n",
      "train loss:0.00107834350558\n",
      "train loss:0.0290045626057\n",
      "train loss:0.00568433712287\n",
      "train loss:0.00994094322654\n",
      "train loss:0.00445335502031\n",
      "train loss:0.00170241441781\n",
      "train loss:0.061318940562\n",
      "train loss:0.000891519344523\n",
      "train loss:0.00684996791422\n",
      "train loss:0.0241335286607\n",
      "train loss:0.0047215183748\n",
      "train loss:0.00191223417891\n",
      "train loss:0.0204023118405\n",
      "train loss:0.00830619819763\n",
      "train loss:0.00373687546131\n",
      "train loss:0.00457761456728\n",
      "train loss:0.00559746206513\n",
      "train loss:0.00154317049638\n",
      "train loss:0.0254750227728\n",
      "train loss:0.00629387075059\n",
      "train loss:0.00567868217256\n",
      "train loss:0.00995225353596\n",
      "train loss:0.00245912063564\n",
      "train loss:0.00710395543071\n",
      "train loss:0.00203030708775\n",
      "train loss:0.011036810714\n",
      "train loss:0.0043676956629\n",
      "train loss:0.0131117481005\n",
      "train loss:0.0210532096022\n",
      "train loss:0.0148626777076\n",
      "train loss:0.0838108312006\n",
      "train loss:0.00687839496515\n",
      "train loss:0.0182647936728\n",
      "train loss:0.0132898075277\n",
      "train loss:0.0204769066797\n",
      "train loss:0.00657436900503\n",
      "train loss:0.00431630266951\n",
      "train loss:0.00266142335552\n",
      "train loss:0.0132108150219\n",
      "train loss:0.00466629624988\n",
      "train loss:0.00509012125974\n",
      "train loss:0.0111403556025\n",
      "train loss:0.0463687564402\n",
      "train loss:0.0086593041358\n",
      "train loss:0.00165687616522\n",
      "train loss:0.0156974919605\n",
      "train loss:0.00233119635538\n",
      "train loss:0.0037917228758\n",
      "train loss:0.00684536001771\n",
      "train loss:0.0106985283118\n",
      "train loss:0.0066835747437\n",
      "train loss:0.00680381746213\n",
      "train loss:0.0194655237856\n",
      "train loss:0.00483865500945\n",
      "train loss:0.00131877809847\n",
      "train loss:0.00443816883173\n",
      "train loss:0.0179194560831\n",
      "train loss:0.0157769702787\n",
      "train loss:0.00740102072558\n",
      "train loss:0.012291929199\n",
      "train loss:0.0042998188217\n",
      "train loss:0.0164823412144\n",
      "train loss:0.0104098469816\n",
      "train loss:0.00758169759504\n",
      "train loss:0.00840658020519\n",
      "train loss:0.00146899607932\n",
      "train loss:0.0244441499434\n",
      "train loss:0.025490723563\n",
      "train loss:0.0274497220078\n",
      "train loss:0.00822234726925\n",
      "train loss:0.011544464437\n",
      "train loss:0.0164796140055\n",
      "train loss:0.00400197011078\n",
      "train loss:0.00691759434301\n",
      "train loss:0.00116060610539\n",
      "train loss:0.00114511740142\n",
      "train loss:0.00206031013983\n",
      "train loss:0.0024900221484\n",
      "train loss:0.00328263864634\n",
      "train loss:0.0170264383191\n",
      "train loss:0.00307797258905\n",
      "train loss:0.00437581558464\n",
      "train loss:0.0196440426958\n",
      "train loss:0.00235249041624\n",
      "train loss:0.00335210323033\n",
      "train loss:0.0070983383508\n",
      "train loss:0.00462221635791\n",
      "train loss:0.00249056738344\n",
      "train loss:0.0013287522428\n",
      "train loss:0.0199139885658\n",
      "train loss:0.0370120439553\n",
      "train loss:0.00514468329374\n",
      "train loss:0.000590182917243\n",
      "train loss:0.00312777406758\n",
      "train loss:0.0224234040725\n",
      "train loss:0.0245167631855\n",
      "train loss:0.015838391515\n",
      "train loss:0.0089254421481\n",
      "train loss:0.0121337174314\n",
      "train loss:0.00688049867996\n",
      "train loss:0.00247224040718\n",
      "train loss:0.00216576428536\n",
      "train loss:0.00307276151846\n",
      "train loss:0.00453973832948\n",
      "train loss:0.00858353644177\n",
      "train loss:0.00596126814776\n",
      "train loss:0.0102236576117\n",
      "train loss:0.00697878585605\n",
      "train loss:0.00489460472721\n",
      "train loss:0.0066758964352\n",
      "train loss:0.00459279482026\n",
      "train loss:0.0215830180925\n",
      "train loss:0.00414504760343\n",
      "train loss:0.00339391683837\n",
      "train loss:0.000287809325517\n",
      "train loss:0.00260840490806\n",
      "train loss:0.00787046417352\n",
      "train loss:0.00230335257899\n",
      "train loss:0.00387057857784\n",
      "train loss:0.0137146878548\n",
      "train loss:0.00950332498403\n",
      "train loss:0.0237881338292\n",
      "train loss:0.00736243363202\n",
      "train loss:0.00496404579123\n",
      "train loss:0.00267664058461\n",
      "train loss:0.0235735336512\n",
      "train loss:0.019351790269\n",
      "train loss:0.00451218910317\n",
      "train loss:0.00899880931422\n",
      "=== epoch:11, train acc:0.994, test acc:0.983 ===\n",
      "train loss:0.0013988378273\n",
      "train loss:0.0101771773741\n",
      "train loss:0.00138174366099\n",
      "train loss:0.0211053587553\n",
      "train loss:0.00786938772296\n",
      "train loss:0.0208792304903\n",
      "train loss:0.000993810600538\n",
      "train loss:0.00698568689528\n",
      "train loss:0.00895216172623\n",
      "train loss:0.0110553012067\n",
      "train loss:0.00935171745542\n",
      "train loss:0.00320771820446\n",
      "train loss:0.0293978707149\n",
      "train loss:0.000397845769187\n",
      "train loss:0.00436324305538\n",
      "train loss:0.000661710258735\n",
      "train loss:0.00496508108899\n",
      "train loss:0.00669912841393\n",
      "train loss:0.00460702090891\n",
      "train loss:0.00425333721971\n",
      "train loss:0.000583787043006\n",
      "train loss:0.0203637355433\n",
      "train loss:0.0164572721278\n",
      "train loss:0.0127048291285\n",
      "train loss:0.0042303831114\n",
      "train loss:0.000244629216994\n",
      "train loss:0.00222665036938\n",
      "train loss:0.0052682461059\n",
      "train loss:0.00419273918103\n",
      "train loss:0.0295905681058\n",
      "train loss:0.000316231364403\n",
      "train loss:0.00309127965223\n",
      "train loss:0.00318178751323\n",
      "train loss:0.0209348416409\n",
      "train loss:0.00112662368198\n",
      "train loss:0.00532694369387\n",
      "train loss:0.00275751090385\n",
      "train loss:0.00824233762769\n",
      "train loss:0.00541325156938\n",
      "train loss:0.0083482688478\n",
      "train loss:0.0111902138683\n",
      "train loss:0.003552497615\n",
      "train loss:0.00339835326138\n",
      "train loss:0.00119520566108\n",
      "train loss:0.00308720769504\n",
      "train loss:0.00152421576151\n",
      "train loss:0.00137286393345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0146641562567\n",
      "train loss:0.00572652575541\n",
      "train loss:0.00405736983365\n",
      "train loss:0.070848782171\n",
      "train loss:0.000471824064204\n",
      "train loss:0.0105752619594\n",
      "train loss:0.00311599126368\n",
      "train loss:0.00715699172544\n",
      "train loss:0.0164913630055\n",
      "train loss:0.000457873329742\n",
      "train loss:0.00245021084151\n",
      "train loss:0.0036322014791\n",
      "train loss:0.0212929072573\n",
      "train loss:0.00495423339796\n",
      "train loss:0.00178454535705\n",
      "train loss:0.00415261544681\n",
      "train loss:0.00686941484694\n",
      "train loss:0.0116602883123\n",
      "train loss:0.00226668245578\n",
      "train loss:0.0335633229588\n",
      "train loss:0.0327584854084\n",
      "train loss:0.00860381911958\n",
      "train loss:0.0118712606217\n",
      "train loss:0.00237983950753\n",
      "train loss:0.00503100990719\n",
      "train loss:0.00078990250666\n",
      "train loss:0.00682450199376\n",
      "train loss:0.00453910672686\n",
      "train loss:0.00582805741808\n",
      "train loss:0.0107350329264\n",
      "train loss:0.00302786911301\n",
      "train loss:0.0206426778035\n",
      "train loss:0.00189477267865\n",
      "train loss:0.0044931847046\n",
      "train loss:0.0128826470034\n",
      "train loss:0.00406753040835\n",
      "train loss:0.00186486416695\n",
      "train loss:0.00175704226737\n",
      "train loss:0.0171349833166\n",
      "train loss:0.000496367936296\n",
      "train loss:0.00614807028747\n",
      "train loss:0.0034921870073\n",
      "train loss:0.0018365820421\n",
      "train loss:0.0175859497215\n",
      "train loss:0.022344686363\n",
      "train loss:0.0334766950502\n",
      "train loss:0.00332263324875\n",
      "train loss:0.00181993652889\n",
      "train loss:0.000839541966183\n",
      "train loss:0.00270099551378\n",
      "train loss:0.00226506432111\n",
      "train loss:0.0154427576873\n",
      "train loss:0.0154322793955\n",
      "train loss:0.000555901044232\n",
      "train loss:0.00170578672369\n",
      "train loss:0.0221291869732\n",
      "train loss:0.00458861398999\n",
      "train loss:0.0022983884495\n",
      "train loss:0.00439610517792\n",
      "train loss:0.00611354796076\n",
      "train loss:0.00257768283262\n",
      "train loss:0.00333203453436\n",
      "train loss:0.0187161373514\n",
      "train loss:0.0160415066881\n",
      "train loss:0.00269011576613\n",
      "train loss:0.011360410423\n",
      "train loss:0.00441715070494\n",
      "train loss:0.00328413494092\n",
      "train loss:0.0031261004219\n",
      "train loss:0.0016916651145\n",
      "train loss:0.00102830017353\n",
      "train loss:0.00400733021753\n",
      "train loss:0.00526153776122\n",
      "train loss:0.0117172814697\n",
      "train loss:0.0122526412852\n",
      "train loss:0.000261582280577\n",
      "train loss:0.00419442764114\n",
      "train loss:0.000458641022978\n",
      "train loss:0.00139324061092\n",
      "train loss:0.00722943976611\n",
      "train loss:0.0016720306383\n",
      "train loss:0.00196608758352\n",
      "train loss:0.000604967488792\n",
      "train loss:0.0029215032036\n",
      "train loss:0.00574728939847\n",
      "train loss:0.0180761140435\n",
      "train loss:0.00302355020615\n",
      "train loss:0.00239019564512\n",
      "train loss:0.00245818636075\n",
      "train loss:0.00144073675794\n",
      "train loss:0.00412393494002\n",
      "train loss:0.00257093442144\n",
      "train loss:0.0137203995257\n",
      "train loss:0.00890092134696\n",
      "train loss:0.00252268453816\n",
      "train loss:0.00712303714303\n",
      "train loss:0.00837406050223\n",
      "train loss:0.00392607384545\n",
      "train loss:0.0210207070775\n",
      "train loss:0.00217812348625\n",
      "train loss:0.0110677730761\n",
      "train loss:0.00360756034777\n",
      "train loss:0.124143735261\n",
      "train loss:0.00285896488805\n",
      "train loss:0.00176375244399\n",
      "train loss:0.00337532943696\n",
      "train loss:0.01712226377\n",
      "train loss:0.00657828597422\n",
      "train loss:0.00454878682794\n",
      "train loss:0.00461875016291\n",
      "train loss:0.00316321016687\n",
      "train loss:0.00635319255476\n",
      "train loss:0.00608336213874\n",
      "train loss:0.118891938324\n",
      "train loss:0.0145100217508\n",
      "train loss:0.0312328208124\n",
      "train loss:0.0886496518814\n",
      "train loss:0.00336884893416\n",
      "train loss:0.00206794058083\n",
      "train loss:0.00296188821386\n",
      "train loss:0.00841701570306\n",
      "train loss:0.0172905165277\n",
      "train loss:0.0133684797942\n",
      "train loss:0.00115580517129\n",
      "train loss:0.00627787525422\n",
      "train loss:0.00252172310222\n",
      "train loss:0.00400734788063\n",
      "train loss:0.00457401881497\n",
      "train loss:0.0108180194078\n",
      "train loss:0.00868698172746\n",
      "train loss:0.00437014422214\n",
      "train loss:0.0042113034719\n",
      "train loss:0.00482942586724\n",
      "train loss:0.0150454145451\n",
      "train loss:0.0464237109169\n",
      "train loss:0.00263285217088\n",
      "train loss:0.0257272305197\n",
      "train loss:0.0250723983805\n",
      "train loss:0.051244132763\n",
      "train loss:0.00198044822967\n",
      "train loss:0.00095631962281\n",
      "train loss:0.039667320862\n",
      "train loss:0.000971509328464\n",
      "train loss:0.000576964913423\n",
      "train loss:0.0034403870558\n",
      "train loss:0.0031118034681\n",
      "train loss:0.0796531050915\n",
      "train loss:0.0460507977562\n",
      "train loss:0.0320570174521\n",
      "train loss:0.00649275113155\n",
      "train loss:0.00437960199805\n",
      "train loss:0.00237912108863\n",
      "train loss:0.0168709404248\n",
      "train loss:0.0175243458511\n",
      "train loss:0.00274451757307\n",
      "train loss:0.00464975673789\n",
      "train loss:0.0106264685836\n",
      "train loss:0.00785592222074\n",
      "train loss:0.0146302265686\n",
      "train loss:0.0106667198664\n",
      "train loss:0.00546252565915\n",
      "train loss:0.00846360660858\n",
      "train loss:0.000549570423585\n",
      "train loss:0.0109838073186\n",
      "train loss:0.00345935474384\n",
      "train loss:0.0131510510127\n",
      "train loss:0.00292091182774\n",
      "train loss:0.00454378603258\n",
      "train loss:0.00937975022089\n",
      "train loss:0.017648856064\n",
      "train loss:0.00774172385902\n",
      "train loss:0.0214484696606\n",
      "train loss:0.00710350851229\n",
      "train loss:0.00147263964471\n",
      "train loss:0.00207826246474\n",
      "train loss:0.00413520640266\n",
      "train loss:0.0132983315168\n",
      "train loss:0.00753487869636\n",
      "train loss:0.00836133289943\n",
      "train loss:0.00265871568686\n",
      "train loss:0.00633858706959\n",
      "train loss:0.00414264256413\n",
      "train loss:0.00711094274696\n",
      "train loss:0.00965480075002\n",
      "train loss:0.00106498970435\n",
      "train loss:0.0241663997259\n",
      "train loss:0.00393714848391\n",
      "train loss:0.00347259180446\n",
      "train loss:0.00747571191006\n",
      "train loss:0.00584467789144\n",
      "train loss:0.00691718343776\n",
      "train loss:0.00824299263301\n",
      "train loss:0.000752149047841\n",
      "train loss:0.0250477331396\n",
      "train loss:0.00635810190182\n",
      "train loss:0.0121875727617\n",
      "train loss:0.0126206830201\n",
      "train loss:0.00397670088159\n",
      "train loss:0.00102404132189\n",
      "train loss:0.0610193671221\n",
      "train loss:0.00192748689616\n",
      "train loss:0.00363320573723\n",
      "train loss:0.0150169649384\n",
      "train loss:0.00215589726785\n",
      "train loss:0.0263182959959\n",
      "train loss:0.00218863366468\n",
      "train loss:0.0094429102462\n",
      "train loss:0.00883562944988\n",
      "train loss:0.0109529230263\n",
      "train loss:0.0107347153615\n",
      "train loss:0.000895271616876\n",
      "train loss:0.00154172819208\n",
      "train loss:0.0128870115875\n",
      "train loss:0.00159936513722\n",
      "train loss:0.0418916474779\n",
      "train loss:0.00708536056226\n",
      "train loss:0.00400281100313\n",
      "train loss:0.00541190909051\n",
      "train loss:0.000619379373241\n",
      "train loss:0.00189654232479\n",
      "train loss:0.0215772929648\n",
      "train loss:0.0222974892042\n",
      "train loss:0.00277925068082\n",
      "train loss:0.00834122327123\n",
      "train loss:0.00720361573968\n",
      "train loss:0.00582484980281\n",
      "train loss:0.00455707506463\n",
      "train loss:0.00148689678876\n",
      "train loss:0.00191554832553\n",
      "train loss:0.00536908237043\n",
      "train loss:0.00536658313725\n",
      "train loss:0.00218407044785\n",
      "train loss:0.00969508179595\n",
      "train loss:0.00676568355481\n",
      "train loss:0.00101713839314\n",
      "train loss:0.00136569133146\n",
      "train loss:0.0104666025601\n",
      "train loss:0.00240617531203\n",
      "train loss:0.0088944197608\n",
      "train loss:0.00487499812476\n",
      "train loss:0.00482496792293\n",
      "train loss:0.00303738587389\n",
      "train loss:0.00300845496082\n",
      "train loss:0.00195840626945\n",
      "train loss:0.00258330528707\n",
      "train loss:0.00119421330371\n",
      "train loss:0.00205881018037\n",
      "train loss:0.00087165322769\n",
      "train loss:0.0083578766448\n",
      "train loss:0.00959403133741\n",
      "train loss:0.00271215533528\n",
      "train loss:0.00671365932266\n",
      "train loss:0.00306348595176\n",
      "train loss:0.00103659403084\n",
      "train loss:0.00437149323564\n",
      "train loss:0.00212124674339\n",
      "train loss:0.00194938840155\n",
      "train loss:0.00155677934817\n",
      "train loss:0.00448707013904\n",
      "train loss:0.00505947708219\n",
      "train loss:0.00220744287941\n",
      "train loss:0.00299167618518\n",
      "train loss:0.00160489199809\n",
      "train loss:0.00187692543199\n",
      "train loss:0.000937747034122\n",
      "train loss:0.0119445548192\n",
      "train loss:0.00551528213382\n",
      "train loss:0.00404843632022\n",
      "train loss:0.00277651436786\n",
      "train loss:0.00386131847357\n",
      "train loss:0.0130907669003\n",
      "train loss:0.00113426775606\n",
      "train loss:0.0180089297798\n",
      "train loss:0.00181990015098\n",
      "train loss:0.0126348206764\n",
      "train loss:0.00186106757494\n",
      "train loss:0.00199778738301\n",
      "train loss:0.0032417016036\n",
      "train loss:0.00364717195011\n",
      "train loss:0.00278636521183\n",
      "train loss:0.00312391582178\n",
      "train loss:0.0011039055055\n",
      "train loss:0.00512445038573\n",
      "train loss:0.000731291581145\n",
      "train loss:0.00253708671043\n",
      "train loss:0.00339570278768\n",
      "train loss:0.00680468215009\n",
      "train loss:0.00465657171218\n",
      "train loss:0.00107350568413\n",
      "train loss:0.00153356229796\n",
      "train loss:0.00735361964882\n",
      "train loss:0.00258766496148\n",
      "train loss:0.00434188697909\n",
      "train loss:0.000929094193487\n",
      "train loss:0.00445292471112\n",
      "train loss:0.000365949379256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00469075723284\n",
      "train loss:0.00129427834939\n",
      "train loss:0.00672195954182\n",
      "train loss:0.00118218455831\n",
      "train loss:0.00499164798424\n",
      "train loss:0.0104005507128\n",
      "train loss:0.00231755501376\n",
      "train loss:0.00724648421245\n",
      "train loss:0.00510954230741\n",
      "train loss:0.00084706426066\n",
      "train loss:0.000876590986468\n",
      "train loss:0.0045155533207\n",
      "train loss:0.0309843612035\n",
      "train loss:0.00366201345382\n",
      "train loss:0.00283646998467\n",
      "train loss:0.00923543500943\n",
      "train loss:0.00185776337297\n",
      "train loss:0.0172645355783\n",
      "train loss:0.000323862285525\n",
      "train loss:0.00657153577903\n",
      "train loss:0.0125879045878\n",
      "train loss:0.00328335487188\n",
      "train loss:0.00585241376399\n",
      "train loss:0.00196051411748\n",
      "train loss:0.00191331947276\n",
      "train loss:0.00173507920443\n",
      "train loss:0.0060114913158\n",
      "train loss:0.00670634628956\n",
      "train loss:0.00428381667308\n",
      "train loss:0.00248640686162\n",
      "train loss:0.00687242644789\n",
      "train loss:0.00732837023909\n",
      "train loss:0.000773489875705\n",
      "train loss:0.00158823888105\n",
      "train loss:0.0030714460576\n",
      "train loss:0.0127746401758\n",
      "train loss:0.00214486696944\n",
      "train loss:0.000802117119289\n",
      "train loss:0.00218134196397\n",
      "train loss:0.00136321341507\n",
      "train loss:0.000960885012839\n",
      "train loss:0.00762200403889\n",
      "train loss:0.0166182566041\n",
      "train loss:0.000709955080407\n",
      "train loss:0.00484233941533\n",
      "train loss:0.00170864158021\n",
      "train loss:0.00025487710532\n",
      "train loss:0.00301106151926\n",
      "train loss:0.00459936418723\n",
      "train loss:0.000913330047112\n",
      "train loss:0.00506267645844\n",
      "train loss:0.00270691666389\n",
      "train loss:0.00321345900489\n",
      "train loss:0.00401342932117\n",
      "train loss:0.00130491210432\n",
      "train loss:0.0109066403433\n",
      "train loss:0.00697839676528\n",
      "train loss:0.00325536187185\n",
      "train loss:0.00596644206173\n",
      "train loss:0.0236288219776\n",
      "train loss:0.00967656846317\n",
      "train loss:0.0158062879539\n",
      "train loss:0.00377933749416\n",
      "train loss:0.00382804906559\n",
      "train loss:0.00264847005294\n",
      "train loss:0.00270401874238\n",
      "train loss:0.00229074994888\n",
      "train loss:0.00318489836355\n",
      "train loss:0.00134120004398\n",
      "train loss:0.00148540328556\n",
      "train loss:0.00198617051451\n",
      "train loss:0.00683860475529\n",
      "train loss:0.00116550606809\n",
      "train loss:0.000737585442266\n",
      "train loss:0.00282281430402\n",
      "train loss:0.00275972605172\n",
      "train loss:0.00251747217473\n",
      "train loss:0.00814821219354\n",
      "train loss:0.0167960397657\n",
      "train loss:0.00114671659638\n",
      "train loss:0.013066661551\n",
      "train loss:0.00568962283894\n",
      "train loss:0.00138320892398\n",
      "train loss:0.00213880472877\n",
      "train loss:0.0118879859324\n",
      "train loss:0.0030259835493\n",
      "train loss:0.00485001212833\n",
      "train loss:0.0122518374966\n",
      "train loss:0.00504234766594\n",
      "train loss:0.00495178272788\n",
      "train loss:0.00367568585398\n",
      "train loss:0.011099927788\n",
      "train loss:0.007575089124\n",
      "train loss:0.0016249689449\n",
      "train loss:0.00486655936285\n",
      "train loss:0.00309495462703\n",
      "train loss:0.00698176961388\n",
      "train loss:0.0185651412653\n",
      "train loss:0.0136298054657\n",
      "train loss:0.00272995682043\n",
      "train loss:0.0033003977538\n",
      "train loss:0.0341106687503\n",
      "train loss:0.00865118683845\n",
      "train loss:0.0135006169113\n",
      "train loss:0.0247289583831\n",
      "train loss:0.00100081239479\n",
      "train loss:0.0023761281231\n",
      "train loss:0.00442517690671\n",
      "train loss:0.00861595066918\n",
      "train loss:0.016049186405\n",
      "train loss:0.00627463096644\n",
      "train loss:0.000502687647477\n",
      "train loss:0.014183909521\n",
      "train loss:0.00302207118525\n",
      "train loss:0.00538956758377\n",
      "train loss:0.00132625999835\n",
      "train loss:0.000478404752527\n",
      "train loss:0.00707464703191\n",
      "train loss:0.00361133907571\n",
      "train loss:0.0123525754017\n",
      "train loss:0.0105187273222\n",
      "train loss:0.00360730984572\n",
      "train loss:0.00828989327073\n",
      "train loss:0.00301347717589\n",
      "train loss:0.00114716393184\n",
      "train loss:0.00291391866263\n",
      "train loss:0.00156356733437\n",
      "train loss:0.000877849205105\n",
      "train loss:0.00224481581587\n",
      "train loss:0.00148573699541\n",
      "train loss:0.00283565879789\n",
      "train loss:0.00544515066414\n",
      "train loss:0.00194275172648\n",
      "train loss:0.0101185121742\n",
      "train loss:0.0044674169388\n",
      "train loss:0.00478945219612\n",
      "train loss:0.00422807684445\n",
      "train loss:0.00566246066359\n",
      "train loss:0.00507533073057\n",
      "train loss:0.00177637602648\n",
      "train loss:0.0420624217549\n",
      "train loss:0.00309830153136\n",
      "train loss:0.00648145348399\n",
      "train loss:0.00202686996757\n",
      "train loss:0.00425725300823\n",
      "train loss:0.0033334027033\n",
      "train loss:0.00392536958761\n",
      "train loss:0.00370885248859\n",
      "train loss:0.00788686343931\n",
      "train loss:0.00749079762065\n",
      "train loss:0.0118811640376\n",
      "train loss:0.00477983697389\n",
      "train loss:0.00428196370672\n",
      "train loss:0.0208269598721\n",
      "train loss:0.00814066311435\n",
      "train loss:0.00481300051664\n",
      "train loss:0.00745793170005\n",
      "train loss:0.0671882461713\n",
      "train loss:0.00489621011189\n",
      "train loss:0.00224061371205\n",
      "train loss:0.00776508315818\n",
      "train loss:0.00279844353541\n",
      "train loss:0.00480977128177\n",
      "train loss:0.00168706588662\n",
      "train loss:0.00192040329826\n",
      "train loss:0.00426028252236\n",
      "train loss:0.0116407153393\n",
      "train loss:0.000687666976833\n",
      "train loss:0.00466394757899\n",
      "train loss:0.00132950346019\n",
      "train loss:0.000964982898247\n",
      "train loss:0.00502057243811\n",
      "train loss:0.0137842231292\n",
      "train loss:0.00160766046967\n",
      "train loss:0.00187062771984\n",
      "train loss:0.00424667412525\n",
      "train loss:0.00934185094124\n",
      "train loss:0.00200480998728\n",
      "train loss:0.0134307271596\n",
      "train loss:0.00241575366581\n",
      "train loss:0.00539125363452\n",
      "train loss:0.00507991267222\n",
      "train loss:0.00481578573415\n",
      "train loss:0.00505686240437\n",
      "train loss:0.00186074507476\n",
      "train loss:0.0185991576319\n",
      "train loss:0.0141943060088\n",
      "train loss:0.00704838521784\n",
      "train loss:0.012048180929\n",
      "train loss:0.0112069812627\n",
      "train loss:0.00235267740443\n",
      "train loss:0.00242462248313\n",
      "train loss:0.0031164844534\n",
      "train loss:0.000881568391234\n",
      "train loss:0.00497227015661\n",
      "train loss:0.00554449708329\n",
      "train loss:0.00417986287922\n",
      "train loss:0.000434746700932\n",
      "train loss:0.00544885642082\n",
      "train loss:0.00518866781597\n",
      "train loss:0.00197334104882\n",
      "train loss:0.00465478134476\n",
      "train loss:0.00646292449752\n",
      "train loss:0.0021850047521\n",
      "train loss:0.0111682723423\n",
      "train loss:0.00125361048938\n",
      "train loss:0.00971589382311\n",
      "train loss:0.00210607408148\n",
      "train loss:0.00994890947073\n",
      "train loss:0.000771210102308\n",
      "train loss:0.0233867974646\n",
      "train loss:0.00864017106151\n",
      "train loss:0.00176192109924\n",
      "train loss:0.000214987486313\n",
      "train loss:0.00441363795892\n",
      "train loss:0.0441880025512\n",
      "train loss:0.00229755867796\n",
      "train loss:0.00175186228086\n",
      "train loss:0.00272009811583\n",
      "train loss:0.002126149891\n",
      "train loss:0.00718204214876\n",
      "train loss:0.00380951223141\n",
      "train loss:0.00378945484203\n",
      "train loss:0.00442911135467\n",
      "train loss:0.00105907645864\n",
      "train loss:0.0368287936857\n",
      "train loss:0.00343775670788\n",
      "train loss:0.00561341523817\n",
      "train loss:0.0907372577195\n",
      "train loss:0.00124836804634\n",
      "train loss:0.00296961259895\n",
      "train loss:0.00311826623655\n",
      "train loss:0.00348237594782\n",
      "train loss:0.00456868821725\n",
      "train loss:0.00412266988568\n",
      "train loss:0.00309935407882\n",
      "train loss:0.0104718541012\n",
      "train loss:0.00113938986544\n",
      "train loss:0.00465874405976\n",
      "train loss:0.016494494365\n",
      "train loss:0.089036224966\n",
      "train loss:0.0054835442047\n",
      "train loss:0.00955396775799\n",
      "train loss:0.00703433071896\n",
      "train loss:0.00716304129017\n",
      "train loss:0.00435145939267\n",
      "train loss:0.0191179495241\n",
      "train loss:0.00103114986064\n",
      "train loss:0.00960277644946\n",
      "train loss:0.000931072378775\n",
      "train loss:0.00173265729956\n",
      "train loss:0.00172567663537\n",
      "train loss:0.00270605919318\n",
      "train loss:0.0019822133586\n",
      "train loss:0.0103504609005\n",
      "train loss:0.00305892498188\n",
      "train loss:0.0100635256884\n",
      "=== epoch:12, train acc:0.995, test acc:0.989 ===\n",
      "train loss:0.00841172199582\n",
      "train loss:0.0134835266538\n",
      "train loss:0.00758616375194\n",
      "train loss:0.0213694454842\n",
      "train loss:0.000921852166472\n",
      "train loss:0.0294215351574\n",
      "train loss:0.00284183193932\n",
      "train loss:0.00104252664108\n",
      "train loss:0.00337718148\n",
      "train loss:0.00640697396264\n",
      "train loss:0.00737995485436\n",
      "train loss:0.00690531471109\n",
      "train loss:0.00384926267861\n",
      "train loss:0.00224549457625\n",
      "train loss:0.0124263165782\n",
      "train loss:0.00315044951707\n",
      "train loss:0.00199916519624\n",
      "train loss:0.00252420295659\n",
      "train loss:0.0258048533733\n",
      "train loss:0.00526860431581\n",
      "train loss:0.00598048297955\n",
      "train loss:0.0292771776839\n",
      "train loss:0.00611329714224\n",
      "train loss:0.00723114139932\n",
      "train loss:0.0109363840316\n",
      "train loss:0.00369314295579\n",
      "train loss:0.00469109958608\n",
      "train loss:0.0073648802127\n",
      "train loss:0.00441690197306\n",
      "train loss:0.00112988597935\n",
      "train loss:0.00497531564376\n",
      "train loss:0.000953258588781\n",
      "train loss:0.00243032106328\n",
      "train loss:0.000188233056661\n",
      "train loss:0.00713461644153\n",
      "train loss:0.00395906212165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00402227554772\n",
      "train loss:0.00327781636911\n",
      "train loss:0.00779807642773\n",
      "train loss:0.00516786669988\n",
      "train loss:0.00207427472424\n",
      "train loss:0.00336263316424\n",
      "train loss:0.0075098608174\n",
      "train loss:0.0149620295159\n",
      "train loss:0.00174397385861\n",
      "train loss:0.000571909199279\n",
      "train loss:0.00108399428912\n",
      "train loss:0.00452662282613\n",
      "train loss:0.00360212731508\n",
      "train loss:0.000884754368043\n",
      "train loss:0.0020668958751\n",
      "train loss:0.0158309167661\n",
      "train loss:0.00600869472361\n",
      "train loss:0.0283903005998\n",
      "train loss:0.000527015188784\n",
      "train loss:0.015111374998\n",
      "train loss:0.00104273839199\n",
      "train loss:0.00440849589798\n",
      "train loss:0.00406804491\n",
      "train loss:0.0111075856846\n",
      "train loss:0.00701000406251\n",
      "train loss:0.0106848534022\n",
      "train loss:0.00101851302668\n",
      "train loss:0.0111361039059\n",
      "train loss:0.00479912698736\n",
      "train loss:0.00292557001223\n",
      "train loss:0.0053686500388\n",
      "train loss:0.00554261842571\n",
      "train loss:0.00122772098294\n",
      "train loss:0.0163300202355\n",
      "train loss:0.0115771098168\n",
      "train loss:0.00331797884639\n",
      "train loss:0.0100235378267\n",
      "train loss:0.00259131328428\n",
      "train loss:0.009728959969\n",
      "train loss:0.000225080567487\n",
      "train loss:0.00259793851396\n",
      "train loss:0.00330313123352\n",
      "train loss:0.0172442908845\n",
      "train loss:0.00870461555976\n",
      "train loss:0.00106982997148\n",
      "train loss:0.00412050548089\n",
      "train loss:0.00635549901896\n",
      "train loss:0.00204846256192\n",
      "train loss:0.002617717522\n",
      "train loss:0.00127518618296\n",
      "train loss:0.00525568098281\n",
      "train loss:0.00460310968908\n",
      "train loss:0.00191150861853\n",
      "train loss:0.000879573428084\n",
      "train loss:0.00346876420859\n",
      "train loss:0.00555001125301\n",
      "train loss:0.00171437520998\n",
      "train loss:0.00275800679066\n",
      "train loss:0.00928858480321\n",
      "train loss:0.00867813181746\n",
      "train loss:0.000557113421301\n",
      "train loss:0.00155508211262\n",
      "train loss:0.0309466021733\n",
      "train loss:0.00271658594109\n",
      "train loss:0.00318912977055\n",
      "train loss:0.0095968541141\n",
      "train loss:0.000584114643717\n",
      "train loss:0.000742922403384\n",
      "train loss:0.0177961982079\n",
      "train loss:0.00152614124183\n",
      "train loss:0.000394926602589\n",
      "train loss:0.00383098752794\n",
      "train loss:0.00186509563038\n",
      "train loss:0.00190905407806\n",
      "train loss:0.00247612030815\n",
      "train loss:0.0142278721633\n",
      "train loss:0.00581140643666\n",
      "train loss:0.00156214569874\n",
      "train loss:0.00192951321209\n",
      "train loss:0.00468540628717\n",
      "train loss:0.00581960600637\n",
      "train loss:0.00158581480475\n",
      "train loss:0.013065219307\n",
      "train loss:0.00236706926294\n",
      "train loss:0.0015332718869\n",
      "train loss:0.00744029318893\n",
      "train loss:0.00447101240177\n",
      "train loss:0.00315101988872\n",
      "train loss:0.00207730167144\n",
      "train loss:0.00194488838412\n",
      "train loss:0.011117489003\n",
      "train loss:0.00136037978988\n",
      "train loss:0.0335437702149\n",
      "train loss:0.00247713178789\n",
      "train loss:0.00663426231558\n",
      "train loss:0.000387289437836\n",
      "train loss:0.0373647745187\n",
      "train loss:0.00263333816632\n",
      "train loss:0.000912417417777\n",
      "train loss:0.0016323714807\n",
      "train loss:0.00171793587295\n",
      "train loss:0.0113244185546\n",
      "train loss:0.00208547769413\n",
      "train loss:0.000560557131925\n",
      "train loss:0.00808967016138\n",
      "train loss:0.00249582495434\n",
      "train loss:0.00597228809004\n",
      "train loss:0.00202791823307\n",
      "train loss:0.00888694895486\n",
      "train loss:0.00218861367597\n",
      "train loss:0.0140234023603\n",
      "train loss:0.00157693738536\n",
      "train loss:0.000159138647474\n",
      "train loss:0.00381593068154\n",
      "train loss:0.000786940824398\n",
      "train loss:0.00856665626531\n",
      "train loss:0.00645219161181\n",
      "train loss:0.0355383593995\n",
      "train loss:0.00233470896835\n",
      "train loss:0.0258113887323\n",
      "train loss:0.00113184797864\n",
      "train loss:0.0198087240313\n",
      "train loss:0.00173181000318\n",
      "train loss:0.00334336567437\n",
      "train loss:0.000397260158946\n",
      "train loss:0.00121667637652\n",
      "train loss:0.00433584985515\n",
      "train loss:0.0033513753986\n",
      "train loss:0.0019943209857\n",
      "train loss:0.000427476124723\n",
      "train loss:0.00376136611033\n",
      "train loss:0.00152110051304\n",
      "train loss:0.00164124819611\n",
      "train loss:0.00319330731465\n",
      "train loss:0.0384095798188\n",
      "train loss:0.000109555118473\n",
      "train loss:0.00339328900307\n",
      "train loss:0.000364614871206\n",
      "train loss:0.00277558515344\n",
      "train loss:0.00333438055083\n",
      "train loss:0.000940455638105\n",
      "train loss:0.000977661491151\n",
      "train loss:0.0061445011312\n",
      "train loss:0.00140673869335\n",
      "train loss:0.0199507785332\n",
      "train loss:0.00562646020241\n",
      "train loss:0.00709046318078\n",
      "train loss:0.0100759090258\n",
      "train loss:0.00112207012187\n",
      "train loss:0.00224263015216\n",
      "train loss:0.00125862689219\n",
      "train loss:0.00273346434428\n",
      "train loss:0.00993235077809\n",
      "train loss:0.00610606404331\n",
      "train loss:0.00222063044359\n",
      "train loss:0.000267765908022\n",
      "train loss:0.00116781950513\n",
      "train loss:0.000767167156589\n",
      "train loss:0.00172764613168\n",
      "train loss:0.00190671203334\n",
      "train loss:0.00371202750224\n",
      "train loss:0.0099996060783\n",
      "train loss:0.0117112531822\n",
      "train loss:0.00129321866799\n",
      "train loss:0.00264686135065\n",
      "train loss:0.000580359999639\n",
      "train loss:0.00277958106958\n",
      "train loss:0.00661289761217\n",
      "train loss:0.0020341914771\n",
      "train loss:0.0125189566625\n",
      "train loss:0.0100388662961\n",
      "train loss:0.00157350119178\n",
      "train loss:0.000802591338407\n",
      "train loss:0.0038071626424\n",
      "train loss:0.00356603860155\n",
      "train loss:0.00471765262999\n",
      "train loss:0.003952019382\n",
      "train loss:0.00464800163488\n",
      "train loss:0.00605359707131\n",
      "train loss:0.00181155162562\n",
      "train loss:0.0206383554808\n",
      "train loss:0.0300246903599\n",
      "train loss:0.0103119714087\n",
      "train loss:0.00467644687377\n",
      "train loss:0.00343857200769\n",
      "train loss:0.00111951248985\n",
      "train loss:0.00527070409951\n",
      "train loss:0.0109831668805\n",
      "train loss:0.0301352010088\n",
      "train loss:0.00945922961038\n",
      "train loss:0.0138673338785\n",
      "train loss:0.010171523043\n",
      "train loss:0.022573093569\n",
      "train loss:0.00130389759737\n",
      "train loss:0.00320337720244\n",
      "train loss:0.023506253391\n",
      "train loss:0.000636923570431\n",
      "train loss:0.017431123931\n",
      "train loss:0.0121792045895\n",
      "train loss:0.00522042354771\n",
      "train loss:0.00435165530208\n",
      "train loss:0.00274541070796\n",
      "train loss:0.00215613948281\n",
      "train loss:0.00878377689397\n",
      "train loss:0.00699636563325\n",
      "train loss:0.0148613169416\n",
      "train loss:0.00727193508737\n",
      "train loss:0.0031273004048\n",
      "train loss:0.00208881752586\n",
      "train loss:0.0128858879975\n",
      "train loss:0.00157934418351\n",
      "train loss:0.00974790844065\n",
      "train loss:0.00188421971295\n",
      "train loss:0.00546862586951\n",
      "train loss:0.00204424315681\n",
      "train loss:0.00213357376795\n",
      "train loss:0.0122742429454\n",
      "train loss:0.00558214939198\n",
      "train loss:0.00095802521121\n",
      "train loss:0.00197635066783\n",
      "train loss:0.00638243316012\n",
      "train loss:0.0022170303587\n",
      "train loss:0.00441731784409\n",
      "train loss:0.0142960436477\n",
      "train loss:0.0206399141959\n",
      "train loss:0.00328452504861\n",
      "train loss:0.0119053363397\n",
      "train loss:0.00768397378591\n",
      "train loss:0.00267074038764\n",
      "train loss:0.00273007234635\n",
      "train loss:0.00238545371982\n",
      "train loss:0.00802504633601\n",
      "train loss:0.000340259591246\n",
      "train loss:0.000437572992655\n",
      "train loss:0.00683093797682\n",
      "train loss:0.00107353128063\n",
      "train loss:0.0161228688036\n",
      "train loss:0.000777888391925\n",
      "train loss:0.0205847338798\n",
      "train loss:0.00489798672918\n",
      "train loss:0.00167994750971\n",
      "train loss:0.00361704385781\n",
      "train loss:0.00101533984947\n",
      "train loss:0.00459369870975\n",
      "train loss:0.00413705585193\n",
      "train loss:0.00324367090008\n",
      "train loss:0.00134079390196\n",
      "train loss:0.0106878692113\n",
      "train loss:0.00539786636666\n",
      "train loss:0.00271140011847\n",
      "train loss:0.00877257870301\n",
      "train loss:0.00485960236307\n",
      "train loss:0.0104142910915\n",
      "train loss:0.0391599479003\n",
      "train loss:0.000473322127723\n",
      "train loss:0.00322448245887\n",
      "train loss:0.0219918895761\n",
      "train loss:0.00757662696183\n",
      "train loss:0.00500755527035\n",
      "train loss:0.00130897916305\n",
      "train loss:0.000840934125116\n",
      "train loss:0.00118381057041\n",
      "train loss:0.00983670417167\n",
      "train loss:0.00884163302163\n",
      "train loss:0.00542451545621\n",
      "train loss:0.00473145126346\n",
      "train loss:0.00904812485941\n",
      "train loss:0.00764188455226\n",
      "train loss:0.00291128840951\n",
      "train loss:0.0021868081142\n",
      "train loss:0.00187860303244\n",
      "train loss:0.0197139903043\n",
      "train loss:0.00411520424044\n",
      "train loss:0.00248922044869\n",
      "train loss:0.00236200251252\n",
      "train loss:0.00362576867747\n",
      "train loss:0.00237209098655\n",
      "train loss:0.00455618465778\n",
      "train loss:0.00699702307958\n",
      "train loss:0.000457557560574\n",
      "train loss:0.00315325116795\n",
      "train loss:0.0114749674142\n",
      "train loss:0.0122181452893\n",
      "train loss:0.00442430453113\n",
      "train loss:0.00150065189901\n",
      "train loss:0.0130880649302\n",
      "train loss:0.00802310541682\n",
      "train loss:0.00312317366673\n",
      "train loss:0.000984974311863\n",
      "train loss:0.00118320957727\n",
      "train loss:0.000836748055388\n",
      "train loss:0.000450585426853\n",
      "train loss:0.00295214999488\n",
      "train loss:0.00743681964896\n",
      "train loss:0.00750824882077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0124916534818\n",
      "train loss:0.00377479024503\n",
      "train loss:0.0020523388506\n",
      "train loss:0.00867784205914\n",
      "train loss:0.00870632663463\n",
      "train loss:0.00444329209551\n",
      "train loss:0.013743758194\n",
      "train loss:0.00060517804614\n",
      "train loss:0.0043457577025\n",
      "train loss:0.00675822857003\n",
      "train loss:0.000738404723993\n",
      "train loss:0.00912509561222\n",
      "train loss:0.00280555790059\n",
      "train loss:0.00439460387769\n",
      "train loss:0.0229511242402\n",
      "train loss:0.0108800628986\n",
      "train loss:0.000585646767292\n",
      "train loss:0.00948023473172\n",
      "train loss:0.00571155253563\n",
      "train loss:0.000988824834344\n",
      "train loss:0.00170742106509\n",
      "train loss:0.00449619333688\n",
      "train loss:0.0056849990198\n",
      "train loss:0.00437469003059\n",
      "train loss:0.000688275407392\n",
      "train loss:0.0051994865034\n",
      "train loss:0.00896122014482\n",
      "train loss:0.00281049104366\n",
      "train loss:0.0117202456578\n",
      "train loss:0.00201616885452\n",
      "train loss:0.000935314874819\n",
      "train loss:0.00419758830745\n",
      "train loss:0.000664181038507\n",
      "train loss:0.0029513871306\n",
      "train loss:0.00255546267585\n",
      "train loss:0.000799268781559\n",
      "train loss:0.00374786336547\n",
      "train loss:0.00378893578531\n",
      "train loss:0.000451287083026\n",
      "train loss:0.00182374136627\n",
      "train loss:0.00249256404985\n",
      "train loss:0.000372197114036\n",
      "train loss:0.00408006126022\n",
      "train loss:0.00626935934196\n",
      "train loss:0.00403943321196\n",
      "train loss:0.00150720505567\n",
      "train loss:0.00697536992192\n",
      "train loss:0.00428294933082\n",
      "train loss:0.024881728951\n",
      "train loss:0.00136023651275\n",
      "train loss:0.000167903787389\n",
      "train loss:0.0100509228908\n",
      "train loss:0.00361447408186\n",
      "train loss:0.00197200091913\n",
      "train loss:0.00198733525069\n",
      "train loss:0.00699244415856\n",
      "train loss:0.00300016941612\n",
      "train loss:0.00866690943745\n",
      "train loss:0.000881556839557\n",
      "train loss:0.00352830213552\n",
      "train loss:0.00196475616144\n",
      "train loss:0.00233334301151\n",
      "train loss:0.00195506175659\n",
      "train loss:0.000846099602421\n",
      "train loss:0.00171200638842\n",
      "train loss:0.00188794496913\n",
      "train loss:0.0255434087451\n",
      "train loss:0.00378746270781\n",
      "train loss:0.000430468133318\n",
      "train loss:0.00160175504722\n",
      "train loss:0.0102773470753\n",
      "train loss:0.00211937461939\n",
      "train loss:0.0116357438618\n",
      "train loss:0.00024978180248\n",
      "train loss:0.00300173849367\n",
      "train loss:0.0117404923848\n",
      "train loss:0.00665138556887\n",
      "train loss:0.0229675697741\n",
      "train loss:0.00109448391728\n",
      "train loss:0.00925384094\n",
      "train loss:0.000869465454163\n",
      "train loss:0.000121809549436\n",
      "train loss:0.00762066136069\n",
      "train loss:0.00118873280387\n",
      "train loss:0.000835397640207\n",
      "train loss:7.7064114414e-05\n",
      "train loss:0.0191434486576\n",
      "train loss:0.00311124705151\n",
      "train loss:0.0146283743564\n",
      "train loss:0.00571031783495\n",
      "train loss:0.00353689199295\n",
      "train loss:0.00398927418375\n",
      "train loss:0.0101079640641\n",
      "train loss:0.0136525453179\n",
      "train loss:0.00346847534381\n",
      "train loss:0.00308410543214\n",
      "train loss:0.0174247103909\n",
      "train loss:0.00303915420769\n",
      "train loss:0.00179119639569\n",
      "train loss:0.00211083159079\n",
      "train loss:0.00522542608576\n",
      "train loss:0.00167815361146\n",
      "train loss:0.000656793332512\n",
      "train loss:0.00219248145351\n",
      "train loss:0.00402556022118\n",
      "train loss:0.0046921993409\n",
      "train loss:0.00112970425411\n",
      "train loss:0.00698021914365\n",
      "train loss:0.0213167611899\n",
      "train loss:0.00442457523851\n",
      "train loss:0.000824347182332\n",
      "train loss:0.0175447616031\n",
      "train loss:0.0025936930214\n",
      "train loss:0.00745625527727\n",
      "train loss:0.000610558062103\n",
      "train loss:0.00495782904322\n",
      "train loss:0.00118510568033\n",
      "train loss:0.00145753897958\n",
      "train loss:0.010478963224\n",
      "train loss:0.00459432343993\n",
      "train loss:0.0026978713512\n",
      "train loss:0.00300207784978\n",
      "train loss:0.00109498591276\n",
      "train loss:0.00175592531958\n",
      "train loss:0.00254388016398\n",
      "train loss:0.00154211250241\n",
      "train loss:0.00148092656097\n",
      "train loss:0.00202624915139\n",
      "train loss:0.0017730589141\n",
      "train loss:0.00239794612174\n",
      "train loss:0.00187005866012\n",
      "train loss:0.00121295140458\n",
      "train loss:0.00212087803546\n",
      "train loss:0.00578299455445\n",
      "train loss:0.00410925800651\n",
      "train loss:0.0194703703466\n",
      "train loss:0.00268966256616\n",
      "train loss:0.00254980542126\n",
      "train loss:0.000794741314448\n",
      "train loss:0.00161121875372\n",
      "train loss:0.00581585669892\n",
      "train loss:0.0025905019192\n",
      "train loss:0.00389198722233\n",
      "train loss:0.00142893659357\n",
      "train loss:0.00268283416284\n",
      "train loss:0.000235509991555\n",
      "train loss:0.000419403867149\n",
      "train loss:0.0010759871468\n",
      "train loss:0.00987688341974\n",
      "train loss:0.00450499727372\n",
      "train loss:0.00603020130656\n",
      "train loss:0.0036746278591\n",
      "train loss:0.00521832841885\n",
      "train loss:0.0662167437132\n",
      "train loss:0.000785239719884\n",
      "train loss:0.00288133283662\n",
      "train loss:0.003196333681\n",
      "train loss:0.00769387475227\n",
      "train loss:0.000433502384017\n",
      "train loss:0.0227788367067\n",
      "train loss:0.00455629093199\n",
      "train loss:0.00171919078418\n",
      "train loss:0.00267832177148\n",
      "train loss:0.00289774755877\n",
      "train loss:0.0245504022389\n",
      "train loss:0.00352408320327\n",
      "train loss:0.00254486461707\n",
      "train loss:0.000347072823827\n",
      "train loss:0.000368962135723\n",
      "train loss:0.00283010909983\n",
      "train loss:0.00236554256303\n",
      "train loss:0.0049816877855\n",
      "train loss:0.00276177646566\n",
      "train loss:0.00121174410469\n",
      "train loss:0.00595127299262\n",
      "train loss:0.00238990980525\n",
      "train loss:0.00160672736674\n",
      "train loss:0.00058171718373\n",
      "train loss:0.000101659735734\n",
      "train loss:0.00932903763984\n",
      "train loss:0.00510902738621\n",
      "train loss:0.0406710829593\n",
      "train loss:0.00976597573446\n",
      "train loss:0.00184572764259\n",
      "train loss:0.0117181403362\n",
      "train loss:0.0246476833253\n",
      "train loss:0.00468873882062\n",
      "train loss:0.0200454107975\n",
      "train loss:0.00545860028883\n",
      "train loss:0.000383433407091\n",
      "train loss:0.00207017533879\n",
      "train loss:0.00131426691224\n",
      "train loss:0.00492080648301\n",
      "train loss:0.00415468563059\n",
      "train loss:0.000560794277444\n",
      "train loss:0.00547403688934\n",
      "train loss:0.0175128051086\n",
      "train loss:0.0069406186414\n",
      "train loss:0.00456240221437\n",
      "train loss:0.00244249252137\n",
      "train loss:0.000936544566725\n",
      "train loss:0.00256025705136\n",
      "train loss:0.000374835153335\n",
      "train loss:0.00191181878166\n",
      "train loss:0.00101653003418\n",
      "train loss:0.002820607056\n",
      "train loss:0.0045423372575\n",
      "train loss:0.013977478316\n",
      "train loss:0.00815929689377\n",
      "train loss:0.000161544369882\n",
      "train loss:0.00561556902637\n",
      "train loss:0.00248319872023\n",
      "train loss:0.00402348669268\n",
      "train loss:0.00301761100917\n",
      "train loss:0.00400751039962\n",
      "train loss:0.0751108583279\n",
      "train loss:0.00129882330079\n",
      "train loss:0.00298809432222\n",
      "train loss:0.00123256013058\n",
      "train loss:0.00898221607604\n",
      "train loss:0.00147895403988\n",
      "train loss:0.00390203699955\n",
      "train loss:0.00809002349491\n",
      "train loss:0.00844346954596\n",
      "train loss:0.001237303594\n",
      "train loss:0.0141460260326\n",
      "train loss:0.00173881754484\n",
      "train loss:0.000510822284856\n",
      "train loss:0.00764650693437\n",
      "train loss:0.00334525063044\n",
      "train loss:0.0189272298144\n",
      "train loss:0.000965103623396\n",
      "train loss:0.000668703278935\n",
      "train loss:0.00212395789633\n",
      "train loss:0.00278943009759\n",
      "train loss:0.00289230621617\n",
      "train loss:0.00150971886617\n",
      "train loss:0.000414248047759\n",
      "train loss:0.00043208013287\n",
      "train loss:0.00750255457421\n",
      "train loss:0.0203750158273\n",
      "train loss:0.00852694643344\n",
      "train loss:0.00643481500488\n",
      "train loss:0.000140108672872\n",
      "train loss:0.0031547438047\n",
      "train loss:0.0013081875152\n",
      "train loss:0.00292059554547\n",
      "train loss:0.0240487894053\n",
      "train loss:0.0036148365757\n",
      "train loss:0.00587197741315\n",
      "train loss:0.00031999415784\n",
      "train loss:0.00570293501775\n",
      "train loss:0.000826012151277\n",
      "train loss:0.00282265116964\n",
      "train loss:0.000650031561534\n",
      "train loss:0.0020813294892\n",
      "train loss:0.00270849539086\n",
      "train loss:0.00127491573528\n",
      "train loss:0.00201387525664\n",
      "train loss:0.00256727448661\n",
      "train loss:0.000383814336462\n",
      "train loss:0.00193165736053\n",
      "train loss:0.00103843490347\n",
      "train loss:0.00028627906609\n",
      "train loss:0.007316766863\n",
      "train loss:0.0114924040353\n",
      "train loss:0.00402184778858\n",
      "train loss:0.000375067770553\n",
      "train loss:0.00326471138357\n",
      "=== epoch:13, train acc:0.997, test acc:0.989 ===\n",
      "train loss:0.00502598986072\n",
      "train loss:0.00211060291961\n",
      "train loss:0.00070895081142\n",
      "train loss:0.00721030198847\n",
      "train loss:0.00125372068451\n",
      "train loss:0.00391858079845\n",
      "train loss:0.00155051654718\n",
      "train loss:7.21630674261e-05\n",
      "train loss:0.000872612695583\n",
      "train loss:0.000670376226993\n",
      "train loss:0.00100234882822\n",
      "train loss:0.00149461084653\n",
      "train loss:0.00201413463067\n",
      "train loss:0.00130039599296\n",
      "train loss:0.00517040494215\n",
      "train loss:0.000841411641937\n",
      "train loss:0.00280490223018\n",
      "train loss:0.00214777829207\n",
      "train loss:0.00183377340867\n",
      "train loss:0.00437184202764\n",
      "train loss:0.00315737709713\n",
      "train loss:0.00126412920641\n",
      "train loss:0.00248368929819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00395026328584\n",
      "train loss:0.000455014294022\n",
      "train loss:0.000757257211332\n",
      "train loss:0.0037581121579\n",
      "train loss:0.00167077309799\n",
      "train loss:0.00325693680138\n",
      "train loss:0.00473831626779\n",
      "train loss:0.00203137850299\n",
      "train loss:0.00401708688998\n",
      "train loss:0.00465662449828\n",
      "train loss:0.00799043337289\n",
      "train loss:0.00114810868364\n",
      "train loss:0.004460247799\n",
      "train loss:0.00124284769561\n",
      "train loss:0.00072677544704\n",
      "train loss:0.000957433884471\n",
      "train loss:0.000108374777605\n",
      "train loss:0.00327595714342\n",
      "train loss:0.0023364194778\n",
      "train loss:0.00308876533773\n",
      "train loss:0.000190615637314\n",
      "train loss:0.00459260844974\n",
      "train loss:0.0129033767745\n",
      "train loss:0.000855572911914\n",
      "train loss:0.0108272911421\n",
      "train loss:0.00622615918716\n",
      "train loss:0.000202936480673\n",
      "train loss:0.000706669607641\n",
      "train loss:0.0013683681533\n",
      "train loss:0.00201075970916\n",
      "train loss:0.00734482872549\n",
      "train loss:0.00656365016398\n",
      "train loss:0.000200344451323\n",
      "train loss:0.000522329985007\n",
      "train loss:0.000876905539167\n",
      "train loss:0.00187718998445\n",
      "train loss:0.00362576770569\n",
      "train loss:0.00366371314805\n",
      "train loss:0.00175467220724\n",
      "train loss:0.00652599481793\n",
      "train loss:0.000653744574664\n",
      "train loss:0.00328473947651\n",
      "train loss:0.00734026242509\n",
      "train loss:0.00563928405455\n",
      "train loss:0.00224525951865\n",
      "train loss:0.010216304434\n",
      "train loss:0.00154899428234\n",
      "train loss:0.000818432948545\n",
      "train loss:0.0016357561297\n",
      "train loss:0.00461367714118\n",
      "train loss:0.00930164869558\n",
      "train loss:0.00141186723402\n",
      "train loss:0.00193749072311\n",
      "train loss:0.00995786032214\n",
      "train loss:0.0016233302743\n",
      "train loss:0.000480390250912\n",
      "train loss:0.00242454035365\n",
      "train loss:0.00436622953099\n",
      "train loss:0.00762270023514\n",
      "train loss:0.00038933146739\n",
      "train loss:0.00379401226471\n",
      "train loss:0.000752958859921\n",
      "train loss:0.0166750664766\n",
      "train loss:0.00434682712301\n",
      "train loss:0.00606020176051\n",
      "train loss:0.0297276141067\n",
      "train loss:0.000645769506734\n",
      "train loss:0.00278754976659\n",
      "train loss:0.00959160642886\n",
      "train loss:0.00419489872864\n",
      "train loss:0.00398859937492\n",
      "train loss:0.00242370894525\n",
      "train loss:0.0072008367142\n",
      "train loss:0.0053377610592\n",
      "train loss:0.00288163457365\n",
      "train loss:0.000533569380211\n",
      "train loss:0.00260947770726\n",
      "train loss:0.0016915072286\n",
      "train loss:0.0036686565336\n",
      "train loss:0.00155313436202\n",
      "train loss:0.00340314844774\n",
      "train loss:0.00436831316865\n",
      "train loss:0.00269024130585\n",
      "train loss:0.0039274408619\n",
      "train loss:0.0207410170222\n",
      "train loss:0.00107119063033\n",
      "train loss:0.000278777131613\n",
      "train loss:0.0112805847283\n",
      "train loss:0.00412739067029\n",
      "train loss:0.00356747084089\n",
      "train loss:0.00156689977697\n",
      "train loss:0.00455371138944\n",
      "train loss:0.0024090710697\n",
      "train loss:0.00100882125017\n",
      "train loss:0.00198870589407\n",
      "train loss:0.00268919964671\n",
      "train loss:0.00315914907963\n",
      "train loss:0.00359080025176\n",
      "train loss:0.0020760482893\n",
      "train loss:0.00725695881665\n",
      "train loss:0.00188521439865\n",
      "train loss:0.00280251390035\n",
      "train loss:0.00116441282051\n",
      "train loss:0.040873235784\n",
      "train loss:0.0182276176052\n",
      "train loss:0.000484012921471\n",
      "train loss:0.00455710670005\n",
      "train loss:0.00527075011328\n",
      "train loss:0.00188043029627\n",
      "train loss:0.0108808949517\n",
      "train loss:0.0026878945839\n",
      "train loss:0.00269899117011\n",
      "train loss:0.0108487699838\n",
      "train loss:0.00536801004938\n",
      "train loss:0.00232554946596\n",
      "train loss:0.0162541044824\n",
      "train loss:0.00200077090947\n",
      "train loss:0.00552241967599\n",
      "train loss:0.0312377564433\n",
      "train loss:0.000437195464585\n",
      "train loss:0.00125775926695\n",
      "train loss:0.00192104167585\n",
      "train loss:0.00430229423833\n",
      "train loss:0.000439821518946\n",
      "train loss:0.000777021799059\n",
      "train loss:0.000487763517527\n",
      "train loss:0.00281635533378\n",
      "train loss:0.0137169507363\n",
      "train loss:0.0015953440292\n",
      "train loss:0.00689650046754\n",
      "train loss:0.00145826584299\n",
      "train loss:0.012168149341\n",
      "train loss:0.000797105390196\n",
      "train loss:0.00908801242514\n",
      "train loss:0.00185821781436\n",
      "train loss:0.00138769508508\n",
      "train loss:0.000287787817003\n",
      "train loss:0.00134430569535\n",
      "train loss:0.0078206738714\n",
      "train loss:0.00115475834542\n",
      "train loss:0.0103469803212\n",
      "train loss:0.00537945698213\n",
      "train loss:0.000737469277579\n",
      "train loss:0.00168203077713\n",
      "train loss:0.000788404810909\n",
      "train loss:0.00214138573649\n",
      "train loss:0.000466292835678\n",
      "train loss:0.00426650670996\n",
      "train loss:0.00071680064683\n",
      "train loss:0.00300511012983\n",
      "train loss:0.00876810933512\n",
      "train loss:0.000502315311807\n",
      "train loss:0.00252514398279\n",
      "train loss:0.00878395345435\n",
      "train loss:0.000194693279852\n",
      "train loss:0.000479440438903\n",
      "train loss:0.000554033440252\n",
      "train loss:0.00692869484584\n",
      "train loss:0.0230136541434\n",
      "train loss:0.000736803519392\n",
      "train loss:0.00591494492856\n",
      "train loss:0.00777650409785\n",
      "train loss:0.00468737978477\n",
      "train loss:0.000479350646382\n",
      "train loss:0.00703232558041\n",
      "train loss:0.001931126896\n",
      "train loss:0.0070583582728\n",
      "train loss:0.0108864798989\n",
      "train loss:0.00252293896198\n",
      "train loss:0.00291707872459\n",
      "train loss:0.00208122200478\n",
      "train loss:0.00258425101398\n",
      "train loss:0.0134630577122\n",
      "train loss:0.00100738340514\n",
      "train loss:0.00475248973195\n",
      "train loss:0.00310023447428\n",
      "train loss:0.00172407439482\n",
      "train loss:0.00658015576049\n",
      "train loss:0.00377438116654\n",
      "train loss:0.000310894929287\n",
      "train loss:0.00577191563284\n",
      "train loss:0.0501958924615\n",
      "train loss:0.00104630050501\n",
      "train loss:0.000137541413655\n",
      "train loss:0.0146140387604\n",
      "train loss:0.00742289509083\n",
      "train loss:0.0054875120002\n",
      "train loss:0.0044490881099\n",
      "train loss:0.00338531210936\n",
      "train loss:0.00246368550983\n",
      "train loss:0.00133584649127\n",
      "train loss:0.00152016522469\n",
      "train loss:0.00385481091652\n",
      "train loss:0.00105279452342\n",
      "train loss:0.00154830551155\n",
      "train loss:0.00643516715317\n",
      "train loss:0.000864838896688\n",
      "train loss:0.0147875872143\n",
      "train loss:0.105545031273\n",
      "train loss:0.00102378240564\n",
      "train loss:0.00567017836281\n",
      "train loss:0.00115529155728\n",
      "train loss:0.0624362044696\n",
      "train loss:0.00383384167782\n",
      "train loss:0.017586954708\n",
      "train loss:0.00850398569864\n",
      "train loss:0.00119714015082\n",
      "train loss:0.00384539419293\n",
      "train loss:0.000660910845256\n",
      "train loss:0.0184463190862\n",
      "train loss:0.0040892568471\n",
      "train loss:0.00342224539699\n",
      "train loss:0.00327118178563\n",
      "train loss:0.00155811834404\n",
      "train loss:0.00667757976819\n",
      "train loss:0.0135224172786\n",
      "train loss:0.00286568765064\n",
      "train loss:0.000947898233598\n",
      "train loss:0.00312996793213\n",
      "train loss:0.00185203659846\n",
      "train loss:0.000963380428875\n",
      "train loss:0.0561555271736\n",
      "train loss:0.0414507115567\n",
      "train loss:0.00584343294607\n",
      "train loss:0.000610450467269\n",
      "train loss:0.000323384887735\n",
      "train loss:0.00417034616113\n",
      "train loss:0.000992048080489\n",
      "train loss:0.00081438801244\n",
      "train loss:0.0187907646074\n",
      "train loss:0.0051503953259\n",
      "train loss:0.00411956342691\n",
      "train loss:0.0114049939977\n",
      "train loss:0.0100411017141\n",
      "train loss:0.00208759674026\n",
      "train loss:0.00269741453707\n",
      "train loss:0.00120043916593\n",
      "train loss:0.00335444953682\n",
      "train loss:0.00579946847305\n",
      "train loss:0.00330414036958\n",
      "train loss:0.0153614822564\n",
      "train loss:0.0180956853015\n",
      "train loss:0.0025435625846\n",
      "train loss:0.00341179881285\n",
      "train loss:0.00659074775789\n",
      "train loss:0.00585695103077\n",
      "train loss:0.000890387053472\n",
      "train loss:0.000845921533476\n",
      "train loss:0.0059521437364\n",
      "train loss:0.000917047096625\n",
      "train loss:0.00122321349751\n",
      "train loss:0.0169890120682\n",
      "train loss:0.00226156991432\n",
      "train loss:0.0029897471981\n",
      "train loss:0.00457074931876\n",
      "train loss:0.00717299858772\n",
      "train loss:0.0054724005106\n",
      "train loss:0.00227167473186\n",
      "train loss:0.0104256673333\n",
      "train loss:0.00650414597726\n",
      "train loss:0.00104541841304\n",
      "train loss:0.00494821735985\n",
      "train loss:0.00798464023428\n",
      "train loss:0.00823636938008\n",
      "train loss:0.00225307895809\n",
      "train loss:0.00263267036427\n",
      "train loss:0.000646776060433\n",
      "train loss:0.00389896029746\n",
      "train loss:0.00221450966321\n",
      "train loss:0.00025732520127\n",
      "train loss:0.00791867367344\n",
      "train loss:0.0107744219093\n",
      "train loss:0.00170236126024\n",
      "train loss:0.00184108659788\n",
      "train loss:0.00229139126561\n",
      "train loss:0.00134265079599\n",
      "train loss:0.0142378786983\n",
      "train loss:0.00203248717904\n",
      "train loss:0.00650715373911\n",
      "train loss:0.000285305242026\n",
      "train loss:0.000736515949494\n",
      "train loss:0.000838892486611\n",
      "train loss:0.00542115401228\n",
      "train loss:0.00775527264166\n",
      "train loss:0.00191832896346\n",
      "train loss:0.00374167288093\n",
      "train loss:0.00195519656382\n",
      "train loss:0.000184687135776\n",
      "train loss:0.0250534613127\n",
      "train loss:0.00227388730456\n",
      "train loss:0.000429664826971\n",
      "train loss:0.000702913854513\n",
      "train loss:0.00306083748264\n",
      "train loss:0.00234347803935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00857114888206\n",
      "train loss:0.00638878950721\n",
      "train loss:0.0115133419531\n",
      "train loss:0.00252299853481\n",
      "train loss:0.000694439692228\n",
      "train loss:0.00451901412972\n",
      "train loss:0.00390873721181\n",
      "train loss:0.0003065955419\n",
      "train loss:0.00150148565897\n",
      "train loss:0.00182200784829\n",
      "train loss:0.00438575621881\n",
      "train loss:0.000542213560201\n",
      "train loss:0.00146329442253\n",
      "train loss:0.0203177341473\n",
      "train loss:0.00552311985462\n",
      "train loss:0.00210032224051\n",
      "train loss:0.00139677667857\n",
      "train loss:0.00164693873245\n",
      "train loss:0.00243599699662\n",
      "train loss:0.000381076874878\n",
      "train loss:0.00539449837933\n",
      "train loss:0.00279740449015\n",
      "train loss:0.00077210870775\n",
      "train loss:0.00232447493776\n",
      "train loss:0.00546784167842\n",
      "train loss:0.000573461184924\n",
      "train loss:0.0135644987438\n",
      "train loss:0.00337911643629\n",
      "train loss:0.00123428123012\n",
      "train loss:0.00581875482521\n",
      "train loss:0.0089888710962\n",
      "train loss:0.014657270577\n",
      "train loss:0.000278412420533\n",
      "train loss:0.00111581019108\n",
      "train loss:0.00918614094659\n",
      "train loss:0.00173471084589\n",
      "train loss:0.00345791038555\n",
      "train loss:0.0103934862809\n",
      "train loss:0.00918956998142\n",
      "train loss:0.000905659254614\n",
      "train loss:0.00153693825465\n",
      "train loss:0.00577143454156\n",
      "train loss:0.00662012123911\n",
      "train loss:0.00126779383211\n",
      "train loss:0.00595715436979\n",
      "train loss:0.00378625092999\n",
      "train loss:0.00972969356426\n",
      "train loss:0.00411962353711\n",
      "train loss:0.00275212871004\n",
      "train loss:0.0536539212533\n",
      "train loss:0.00517136980767\n",
      "train loss:0.00272889648031\n",
      "train loss:0.00456149126466\n",
      "train loss:0.000277272588902\n",
      "train loss:0.00341855061056\n",
      "train loss:0.000366284674509\n",
      "train loss:0.000587115064789\n",
      "train loss:0.00246150743151\n",
      "train loss:0.00704396915823\n",
      "train loss:0.00394667024246\n",
      "train loss:0.00164453994927\n",
      "train loss:0.00064387742572\n",
      "train loss:0.000272367001633\n",
      "train loss:0.00706701201804\n",
      "train loss:0.000979158931588\n",
      "train loss:0.00146291352492\n",
      "train loss:0.00187902587497\n",
      "train loss:0.00933856610949\n",
      "train loss:0.00175419121981\n",
      "train loss:0.00460329773896\n",
      "train loss:0.00361413427978\n",
      "train loss:0.0392299161388\n",
      "train loss:0.00158462193778\n",
      "train loss:0.00184522618149\n",
      "train loss:0.00254295424761\n",
      "train loss:0.0450114105378\n",
      "train loss:0.000429288830155\n",
      "train loss:0.00286908463168\n",
      "train loss:0.00331251332067\n",
      "train loss:0.00247798550706\n",
      "train loss:0.000124579369843\n",
      "train loss:0.000808526216618\n",
      "train loss:0.00167204407821\n",
      "train loss:0.00254958098502\n",
      "train loss:0.00263989101203\n",
      "train loss:0.0498532074454\n",
      "train loss:0.00829764138709\n",
      "train loss:0.000780759475067\n",
      "train loss:0.0107068458166\n",
      "train loss:0.00269025599664\n",
      "train loss:0.0559162963333\n",
      "train loss:0.0020631183006\n",
      "train loss:0.00202095604385\n",
      "train loss:0.00246095585871\n",
      "train loss:0.00245466271608\n",
      "train loss:0.00126288802686\n",
      "train loss:0.0114220726517\n",
      "train loss:0.00297035404839\n",
      "train loss:0.00102949805693\n",
      "train loss:0.0773690535118\n",
      "train loss:0.0585760489119\n",
      "train loss:0.000507791206893\n",
      "train loss:0.00269745793822\n",
      "train loss:0.00479741202482\n",
      "train loss:0.00303658674713\n",
      "train loss:0.0049520452994\n",
      "train loss:0.00148370361561\n",
      "train loss:0.00492693265587\n",
      "train loss:0.000262681052038\n",
      "train loss:0.000911057218524\n",
      "train loss:0.00105738668082\n",
      "train loss:0.0100768124288\n",
      "train loss:0.000311498636792\n",
      "train loss:0.00497708543394\n",
      "train loss:0.00159421172778\n",
      "train loss:0.00524517391107\n",
      "train loss:0.00126977283471\n",
      "train loss:0.0145943005557\n",
      "train loss:0.000705620772536\n",
      "train loss:0.000180356752274\n",
      "train loss:0.00208189729593\n",
      "train loss:0.00275638349953\n",
      "train loss:0.024524049142\n",
      "train loss:0.00170571599318\n",
      "train loss:0.0023065068744\n",
      "train loss:0.00432612381984\n",
      "train loss:0.00460847491477\n",
      "train loss:0.00224666641859\n",
      "train loss:0.0028400773611\n",
      "train loss:0.00212773316279\n",
      "train loss:0.00616804180181\n",
      "train loss:0.0183406690464\n",
      "train loss:0.000237047135221\n",
      "train loss:0.00166864816854\n",
      "train loss:0.00631746333151\n",
      "train loss:0.000467945437778\n",
      "train loss:0.00698074588685\n",
      "train loss:0.00338998596941\n",
      "train loss:0.00191237163351\n",
      "train loss:0.00216441421873\n",
      "train loss:0.0131640852873\n",
      "train loss:0.00120534152325\n",
      "train loss:0.00300402470062\n",
      "train loss:0.000893708776326\n",
      "train loss:0.00771205818485\n",
      "train loss:0.0232973549525\n",
      "train loss:0.00324099267681\n",
      "train loss:0.000347163694872\n",
      "train loss:0.00327463222438\n",
      "train loss:0.0018138403852\n",
      "train loss:0.000571489719627\n",
      "train loss:0.00424170714326\n",
      "train loss:0.00587452437641\n",
      "train loss:0.000539205954563\n",
      "train loss:0.000749466847686\n",
      "train loss:0.000473258941486\n",
      "train loss:0.0156027340533\n",
      "train loss:0.00339272277681\n",
      "train loss:0.000494959523341\n",
      "train loss:0.00158335765178\n",
      "train loss:0.00236965302773\n",
      "train loss:0.0180620098357\n",
      "train loss:0.00129407868027\n",
      "train loss:0.011817627998\n",
      "train loss:0.00434308451892\n",
      "train loss:0.00267427585734\n",
      "train loss:0.000953262531251\n",
      "train loss:0.00772415818029\n",
      "train loss:0.00281216531856\n",
      "train loss:0.000963848032572\n",
      "train loss:0.00921964498399\n",
      "train loss:0.000233743441004\n",
      "train loss:0.00195260263126\n",
      "train loss:0.00237707557275\n",
      "train loss:0.00157060453979\n",
      "train loss:0.00262144170882\n",
      "train loss:0.00120907547065\n",
      "train loss:0.000319010827936\n",
      "train loss:0.000376012562924\n",
      "train loss:0.00326294759581\n",
      "train loss:0.00376651347279\n",
      "train loss:0.0077015941351\n",
      "train loss:0.00538073430604\n",
      "train loss:0.00103575713574\n",
      "train loss:0.00341690597953\n",
      "train loss:0.00223992426124\n",
      "train loss:0.00991988967583\n",
      "train loss:0.000138077607289\n",
      "train loss:0.00553758074092\n",
      "train loss:0.00225248057737\n",
      "train loss:0.00490107059953\n",
      "train loss:0.00483757420525\n",
      "train loss:0.000645701528058\n",
      "train loss:0.0091055464077\n",
      "train loss:0.00675400503931\n",
      "train loss:0.00155077062125\n",
      "train loss:0.00282210067908\n",
      "train loss:0.00201243565637\n",
      "train loss:0.000499452182476\n",
      "train loss:0.00193264296421\n",
      "train loss:0.00251720500049\n",
      "train loss:0.004230681886\n",
      "train loss:0.00383298850722\n",
      "train loss:0.00361873295665\n",
      "train loss:0.00523958829804\n",
      "train loss:0.0211051070534\n",
      "train loss:0.000630107149293\n",
      "train loss:0.00997902272286\n",
      "train loss:0.00683981134781\n",
      "train loss:0.00111836368145\n",
      "train loss:0.00131798099412\n",
      "train loss:0.00105770279726\n",
      "train loss:0.00128224082157\n",
      "train loss:0.000657255284602\n",
      "train loss:0.0170598566969\n",
      "train loss:0.00163008799559\n",
      "train loss:0.00232608016097\n",
      "train loss:0.00320055381941\n",
      "train loss:0.00321806403026\n",
      "train loss:0.00387855654059\n",
      "train loss:0.00935889108744\n",
      "train loss:0.00510983044437\n",
      "train loss:0.00542086939233\n",
      "train loss:0.00376638922868\n",
      "train loss:0.00388382932792\n",
      "train loss:0.000944782084428\n",
      "train loss:0.00383124950031\n",
      "train loss:0.000151071673126\n",
      "train loss:0.00672427097842\n",
      "train loss:0.0242520910453\n",
      "train loss:0.000539028574982\n",
      "train loss:0.00419438971643\n",
      "train loss:0.00532245149084\n",
      "train loss:0.00358902434183\n",
      "train loss:0.00145884654287\n",
      "train loss:0.000211620596607\n",
      "train loss:0.00152298278879\n",
      "train loss:0.00124825140456\n",
      "train loss:9.96867958104e-05\n",
      "train loss:0.00081460671675\n",
      "train loss:0.000953721608843\n",
      "train loss:0.000557683217313\n",
      "train loss:0.0094355638939\n",
      "train loss:0.00584235795941\n",
      "train loss:0.0011662184391\n",
      "train loss:0.00199663258967\n",
      "train loss:0.00918781245935\n",
      "train loss:0.00686166787248\n",
      "train loss:0.000784519635281\n",
      "train loss:0.000305934343277\n",
      "train loss:0.00352378987062\n",
      "train loss:0.00409574835213\n",
      "train loss:0.00157065935128\n",
      "train loss:0.000561794480295\n",
      "train loss:0.000463763770459\n",
      "train loss:0.0113015651221\n",
      "train loss:0.00140410704131\n",
      "train loss:0.000751636652062\n",
      "train loss:0.00836299309434\n",
      "train loss:0.000711476581052\n",
      "train loss:0.00224203868552\n",
      "train loss:0.000401808358794\n",
      "train loss:0.0104662687174\n",
      "train loss:0.000421393739236\n",
      "train loss:0.00312128684287\n",
      "train loss:0.00172445049898\n",
      "train loss:0.00105301501586\n",
      "train loss:0.000485348675991\n",
      "train loss:0.00194460255691\n",
      "train loss:0.00296289830013\n",
      "train loss:0.0146686501068\n",
      "train loss:0.0137380704842\n",
      "train loss:0.00262297382484\n",
      "train loss:0.00117362048233\n",
      "train loss:0.000243003370916\n",
      "train loss:0.00172572566406\n",
      "train loss:0.000616676479228\n",
      "train loss:0.00700394867469\n",
      "train loss:0.00280893366929\n",
      "train loss:0.0055051559987\n",
      "train loss:0.006236798557\n",
      "train loss:0.000617257934443\n",
      "train loss:0.00126938858933\n",
      "=== epoch:14, train acc:0.998, test acc:0.991 ===\n",
      "train loss:0.000199820670487\n",
      "train loss:0.00532182145454\n",
      "train loss:0.000901196413414\n",
      "train loss:0.00715974295332\n",
      "train loss:0.00848286081121\n",
      "train loss:0.000588540803616\n",
      "train loss:0.00212093442552\n",
      "train loss:0.00153464955129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00654150463631\n",
      "train loss:0.000650435687486\n",
      "train loss:0.00164836490489\n",
      "train loss:0.000619738802888\n",
      "train loss:0.000450813067063\n",
      "train loss:0.0121167638844\n",
      "train loss:0.00633643825203\n",
      "train loss:0.00131696241436\n",
      "train loss:0.00238832947037\n",
      "train loss:0.00463507396744\n",
      "train loss:0.00190011795494\n",
      "train loss:0.00114096016777\n",
      "train loss:0.00274958491773\n",
      "train loss:0.0113303141864\n",
      "train loss:0.00076724301328\n",
      "train loss:0.00121313543624\n",
      "train loss:0.00853364781598\n",
      "train loss:0.00402203870917\n",
      "train loss:0.00980012397788\n",
      "train loss:0.00158391772182\n",
      "train loss:0.00899927027557\n",
      "train loss:0.00464390385765\n",
      "train loss:0.0145425681268\n",
      "train loss:0.00672182991606\n",
      "train loss:0.00196641536392\n",
      "train loss:0.00574886330761\n",
      "train loss:5.4661297698e-05\n",
      "train loss:0.00366863378432\n",
      "train loss:0.0171129122803\n",
      "train loss:0.0021113350753\n",
      "train loss:0.00700670080623\n",
      "train loss:0.00421424300612\n",
      "train loss:0.0213264932926\n",
      "train loss:0.00120289150521\n",
      "train loss:0.0056832003077\n",
      "train loss:0.00301603775157\n",
      "train loss:0.000573716890454\n",
      "train loss:0.0046320712634\n",
      "train loss:0.00984800807435\n",
      "train loss:0.0032451825368\n",
      "train loss:0.00267277026436\n",
      "train loss:0.000647511951245\n",
      "train loss:0.000826835925391\n",
      "train loss:0.0133492882591\n",
      "train loss:0.000522151149078\n",
      "train loss:0.00600507779026\n",
      "train loss:0.00245274052234\n",
      "train loss:0.000765726398361\n",
      "train loss:0.00420602800002\n",
      "train loss:0.00322742301749\n",
      "train loss:0.000736823640126\n",
      "train loss:0.00171730083714\n",
      "train loss:0.000725618988751\n",
      "train loss:0.00401393945602\n",
      "train loss:0.000274463747283\n",
      "train loss:0.000646664609245\n",
      "train loss:0.013316501434\n",
      "train loss:0.00324877498817\n",
      "train loss:0.00401288190117\n",
      "train loss:0.00185261333606\n",
      "train loss:0.00157627060644\n",
      "train loss:0.00604210438101\n",
      "train loss:0.00159042440906\n",
      "train loss:0.0022838813466\n",
      "train loss:0.00905443009958\n",
      "train loss:0.0267777343969\n",
      "train loss:0.00181737697398\n",
      "train loss:0.00147972014315\n",
      "train loss:0.00471051657689\n",
      "train loss:0.00277593321293\n",
      "train loss:0.00790136959443\n",
      "train loss:0.000661141859603\n",
      "train loss:0.00122069247933\n",
      "train loss:0.00501742598607\n",
      "train loss:0.00294950691003\n",
      "train loss:0.000412027477384\n",
      "train loss:0.00084588504811\n",
      "train loss:0.00138432483017\n",
      "train loss:0.00799813354987\n",
      "train loss:0.00430169437551\n",
      "train loss:0.00930521415201\n",
      "train loss:0.000997025302145\n",
      "train loss:0.000142011832716\n",
      "train loss:0.0275155525722\n",
      "train loss:0.00421336636651\n",
      "train loss:0.00264691713456\n",
      "train loss:0.00652177536644\n",
      "train loss:0.0221620295158\n",
      "train loss:0.00364088530463\n",
      "train loss:0.00220345450581\n",
      "train loss:0.000444794910068\n",
      "train loss:0.00058772518894\n",
      "train loss:0.00350254177935\n",
      "train loss:0.0233399463427\n",
      "train loss:0.00684743052344\n",
      "train loss:0.00780955178909\n",
      "train loss:0.0145563105675\n",
      "train loss:0.00148385173852\n",
      "train loss:0.00523494121164\n",
      "train loss:0.00236351454154\n",
      "train loss:0.00329798539623\n",
      "train loss:0.00140599581048\n",
      "train loss:0.000815466755694\n",
      "train loss:0.00259184922329\n",
      "train loss:0.0126717760173\n",
      "train loss:0.00067388231703\n",
      "train loss:0.00355938562203\n",
      "train loss:0.00541891761471\n",
      "train loss:0.0037542188862\n",
      "train loss:0.00207654451642\n",
      "train loss:0.0474515553401\n",
      "train loss:0.00225886649485\n",
      "train loss:0.00429839069696\n",
      "train loss:0.00208689384812\n",
      "train loss:0.00105251323434\n",
      "train loss:0.00131561578195\n",
      "train loss:0.0017816786357\n",
      "train loss:0.000408985408746\n",
      "train loss:0.000820256839466\n",
      "train loss:0.00757920733832\n",
      "train loss:0.00425169744726\n",
      "train loss:0.000723545925101\n",
      "train loss:0.000408165140731\n",
      "train loss:0.00299565727508\n",
      "train loss:0.0023013685286\n",
      "train loss:0.00275969003379\n",
      "train loss:0.0026634505673\n",
      "train loss:0.00158084925684\n",
      "train loss:0.00945510704869\n",
      "train loss:0.000938521804083\n",
      "train loss:0.000125532205734\n",
      "train loss:0.00231570376606\n",
      "train loss:0.00140707697945\n",
      "train loss:0.00414963931486\n",
      "train loss:0.00602053593651\n",
      "train loss:0.000976737624163\n",
      "train loss:0.000675503218135\n",
      "train loss:0.0158822997035\n",
      "train loss:0.00412716889962\n",
      "train loss:0.00141775992204\n",
      "train loss:0.00138525331284\n",
      "train loss:0.00260990688005\n",
      "train loss:0.00626661845292\n",
      "train loss:0.00293077464016\n",
      "train loss:0.0031617266215\n",
      "train loss:0.00187827076925\n",
      "train loss:0.0118023578\n",
      "train loss:0.00774134188373\n",
      "train loss:0.00149507273129\n",
      "train loss:0.00143404911112\n",
      "train loss:0.0165385159268\n",
      "train loss:0.00239427776196\n",
      "train loss:0.0029046594618\n",
      "train loss:0.00535516979733\n",
      "train loss:0.00334564234022\n",
      "train loss:0.00172747221833\n",
      "train loss:0.00606574726272\n",
      "train loss:0.000769689624701\n",
      "train loss:0.00260470829294\n",
      "train loss:0.00445904743068\n",
      "train loss:0.00191460606308\n",
      "train loss:0.00191156388931\n",
      "train loss:0.000763364703985\n",
      "train loss:0.00106192382826\n",
      "train loss:0.0063387328275\n",
      "train loss:0.00415295390063\n",
      "train loss:0.00301137699602\n",
      "train loss:0.0103450844566\n",
      "train loss:0.000313958966513\n",
      "train loss:0.000492938302153\n",
      "train loss:0.000721213559412\n",
      "train loss:0.00303341628088\n",
      "train loss:0.0022088158366\n",
      "train loss:0.00330631743203\n",
      "train loss:0.00581997570993\n",
      "train loss:0.00383895971153\n",
      "train loss:0.000483192214749\n",
      "train loss:0.00231770265907\n",
      "train loss:0.00068924779331\n",
      "train loss:0.00261184269322\n",
      "train loss:0.000372894525966\n",
      "train loss:0.00131811505878\n",
      "train loss:0.000256293989265\n",
      "train loss:0.001755411858\n",
      "train loss:0.00321550130791\n",
      "train loss:0.00122024735882\n",
      "train loss:0.000824735027187\n",
      "train loss:0.000637480946779\n",
      "train loss:0.00478632151637\n",
      "train loss:0.00509063775244\n",
      "train loss:0.00240605583857\n",
      "train loss:0.022014105134\n",
      "train loss:0.00381187412575\n",
      "train loss:0.00157005075252\n",
      "train loss:0.00040308913325\n",
      "train loss:0.00150240365372\n",
      "train loss:0.00244290342965\n",
      "train loss:0.0123812834638\n",
      "train loss:0.00892393886253\n",
      "train loss:0.00291427414937\n",
      "train loss:0.000861071975936\n",
      "train loss:0.0024894022561\n",
      "train loss:0.000849518176598\n",
      "train loss:0.0121602195282\n",
      "train loss:0.0106532602237\n",
      "train loss:0.00110448449543\n",
      "train loss:0.000132909587025\n",
      "train loss:0.00186683477868\n",
      "train loss:0.00517423087725\n",
      "train loss:0.00146123938646\n",
      "train loss:0.00390054724635\n",
      "train loss:0.00112751206619\n",
      "train loss:0.00516677337371\n",
      "train loss:9.37562623269e-05\n",
      "train loss:0.00473779071806\n",
      "train loss:0.00034240533304\n",
      "train loss:0.00463390014082\n",
      "train loss:0.00287247134809\n",
      "train loss:0.000213496355244\n",
      "train loss:0.000189058813552\n",
      "train loss:0.000845491934224\n",
      "train loss:0.000527399437996\n",
      "train loss:0.0014819244208\n",
      "train loss:0.0002550021836\n",
      "train loss:0.00807369851537\n",
      "train loss:0.00112509449746\n",
      "train loss:0.00173408358857\n",
      "train loss:0.00721844341655\n",
      "train loss:0.000265169086082\n",
      "train loss:0.0261289383781\n",
      "train loss:0.000249181787789\n",
      "train loss:0.00965549360774\n",
      "train loss:0.00680625524202\n",
      "train loss:0.00343430488475\n",
      "train loss:0.00240600917315\n",
      "train loss:0.00462303102585\n",
      "train loss:0.0357635533626\n",
      "train loss:0.000789487991405\n",
      "train loss:0.000939834726287\n",
      "train loss:2.43573537386e-05\n",
      "train loss:0.0144205764827\n",
      "train loss:0.0101694445055\n",
      "train loss:0.00738471040717\n",
      "train loss:0.00141215204665\n",
      "train loss:0.00081696844928\n",
      "train loss:0.000963221639282\n",
      "train loss:0.00301787168105\n",
      "train loss:0.00821432349202\n",
      "train loss:0.00410417597479\n",
      "train loss:0.00239516967398\n",
      "train loss:0.00305102055773\n",
      "train loss:0.00344708800388\n",
      "train loss:0.000737153628792\n",
      "train loss:0.00278382658485\n",
      "train loss:0.00675627949879\n",
      "train loss:0.00288251968602\n",
      "train loss:0.00195895501816\n",
      "train loss:0.00107281288835\n",
      "train loss:0.000573065259054\n",
      "train loss:0.00116841267565\n",
      "train loss:0.00052960465787\n",
      "train loss:0.00154531659287\n",
      "train loss:0.0177877748528\n",
      "train loss:0.00195450461644\n",
      "train loss:0.00543596692864\n",
      "train loss:0.00233915589121\n",
      "train loss:0.00266337572354\n",
      "train loss:0.00123457539802\n",
      "train loss:0.00669400185243\n",
      "train loss:0.00548246679128\n",
      "train loss:0.000427149397524\n",
      "train loss:0.00387671807124\n",
      "train loss:0.000614624386294\n",
      "train loss:0.00265001406835\n",
      "train loss:0.000995761475683\n",
      "train loss:0.00167452974324\n",
      "train loss:0.00436616022495\n",
      "train loss:0.00046498451158\n",
      "train loss:0.00566763690983\n",
      "train loss:0.00441191894964\n",
      "train loss:0.00553118574826\n",
      "train loss:0.00327302253819\n",
      "train loss:0.00228939507407\n",
      "train loss:6.63497927772e-05\n",
      "train loss:0.00026356534542\n",
      "train loss:0.00486431426588\n",
      "train loss:0.0024698267937\n",
      "train loss:0.00154268528905\n",
      "train loss:0.00894046177038\n",
      "train loss:0.00581120685476\n",
      "train loss:0.00697078751647\n",
      "train loss:0.001297536876\n",
      "train loss:0.00847015418407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000687796697499\n",
      "train loss:0.00321295687834\n",
      "train loss:0.00896350614781\n",
      "train loss:0.0184869759725\n",
      "train loss:0.0200996817381\n",
      "train loss:0.00185743550478\n",
      "train loss:0.00102630264652\n",
      "train loss:0.00137802873466\n",
      "train loss:0.000220999368238\n",
      "train loss:0.00100293145888\n",
      "train loss:0.0051997418952\n",
      "train loss:0.00170844040439\n",
      "train loss:0.00467280149134\n",
      "train loss:0.00451826108635\n",
      "train loss:0.000293375987362\n",
      "train loss:0.00044819296536\n",
      "train loss:0.000818491122659\n",
      "train loss:0.000985250439671\n",
      "train loss:0.00172985074374\n",
      "train loss:0.00208507887712\n",
      "train loss:0.00207318903502\n",
      "train loss:0.000903138176747\n",
      "train loss:0.00275543627343\n",
      "train loss:0.00373769751873\n",
      "train loss:0.000814211011189\n",
      "train loss:0.000883937806522\n",
      "train loss:0.00724460256411\n",
      "train loss:0.00576854262129\n",
      "train loss:0.00935533332815\n",
      "train loss:0.000802529016726\n",
      "train loss:0.00923173372111\n",
      "train loss:0.000605054723231\n",
      "train loss:0.0225473031422\n",
      "train loss:6.87449319365e-05\n",
      "train loss:0.00181446168655\n",
      "train loss:0.000448405605993\n",
      "train loss:0.000995929073421\n",
      "train loss:0.00159516028553\n",
      "train loss:0.0052486008841\n",
      "train loss:0.00258256778699\n",
      "train loss:0.00232086606666\n",
      "train loss:0.0154965570475\n",
      "train loss:0.00119086711055\n",
      "train loss:0.000344161822553\n",
      "train loss:0.000653703468823\n",
      "train loss:0.00052032858351\n",
      "train loss:0.000692152007139\n",
      "train loss:0.00189189187881\n",
      "train loss:0.00140189475397\n",
      "train loss:0.00125724850614\n",
      "train loss:0.00464982645912\n",
      "train loss:0.0221718557021\n",
      "train loss:0.000517111499265\n",
      "train loss:0.00172221633967\n",
      "train loss:0.00194428908855\n",
      "train loss:0.000619229438566\n",
      "train loss:0.00184491035306\n",
      "train loss:0.00325013562221\n",
      "train loss:0.00140579279132\n",
      "train loss:0.0720668917707\n",
      "train loss:0.000842722040376\n",
      "train loss:0.00370766759351\n",
      "train loss:0.000241509832425\n",
      "train loss:0.000760269597901\n",
      "train loss:0.00217532865775\n",
      "train loss:0.00033237021516\n",
      "train loss:0.00159511195359\n",
      "train loss:0.00940375119262\n",
      "train loss:0.00682009690317\n",
      "train loss:0.00293297866927\n",
      "train loss:0.003678293278\n",
      "train loss:0.000417808396564\n",
      "train loss:0.00257811687774\n",
      "train loss:0.00749817938506\n",
      "train loss:0.000742365704013\n",
      "train loss:0.00334029004387\n",
      "train loss:0.000786288373575\n",
      "train loss:0.00585618117504\n",
      "train loss:0.00533423544195\n",
      "train loss:0.00167128490773\n",
      "train loss:0.000772873877254\n",
      "train loss:0.00548590357743\n",
      "train loss:0.00317976303202\n",
      "train loss:0.000592454949058\n",
      "train loss:0.0035878308762\n",
      "train loss:0.000315518074373\n",
      "train loss:5.46260753197e-05\n",
      "train loss:0.000658692079563\n",
      "train loss:0.00124351503903\n",
      "train loss:0.000761742672189\n",
      "train loss:0.00196884698118\n",
      "train loss:0.00133020832243\n",
      "train loss:0.000992260342499\n",
      "train loss:0.000539382532477\n",
      "train loss:0.003895810007\n",
      "train loss:0.0012208132482\n",
      "train loss:0.000517903863716\n",
      "train loss:0.00250769945514\n",
      "train loss:0.000944883473142\n",
      "train loss:0.00407146926094\n",
      "train loss:0.0134305363705\n",
      "train loss:0.000226193594214\n",
      "train loss:0.00391349792059\n",
      "train loss:0.000154330904318\n",
      "train loss:0.00387369051462\n",
      "train loss:0.000418167120831\n",
      "train loss:0.00121389786875\n",
      "train loss:0.000661477029295\n",
      "train loss:0.00327856142303\n",
      "train loss:0.0306285493942\n",
      "train loss:0.00110443478598\n",
      "train loss:0.00288458451425\n",
      "train loss:0.000442734781332\n",
      "train loss:0.00070421913792\n",
      "train loss:0.00307470646779\n",
      "train loss:0.000345207814475\n",
      "train loss:0.00296556010452\n",
      "train loss:0.00168095734581\n",
      "train loss:0.00684389322969\n",
      "train loss:0.00570832574149\n",
      "train loss:0.000343912125214\n",
      "train loss:0.00124865500433\n",
      "train loss:0.00822904992764\n",
      "train loss:0.00516277438545\n",
      "train loss:0.0112586089123\n",
      "train loss:0.00392348886317\n",
      "train loss:0.00438475629842\n",
      "train loss:0.00392948185365\n",
      "train loss:0.000431988880333\n",
      "train loss:0.000231501422952\n",
      "train loss:0.00727047391094\n",
      "train loss:0.00880349985259\n",
      "train loss:0.00210518233511\n",
      "train loss:0.000914333827977\n",
      "train loss:0.000686636764915\n",
      "train loss:0.00125489366635\n",
      "train loss:0.01086400253\n",
      "train loss:0.00100626023748\n",
      "train loss:0.00728876706866\n",
      "train loss:0.00302191287931\n",
      "train loss:0.000364383970328\n",
      "train loss:0.00207765296342\n",
      "train loss:0.00140676519712\n",
      "train loss:0.00528939499489\n",
      "train loss:0.00169741017177\n",
      "train loss:0.00153012609011\n",
      "train loss:0.00835437238587\n",
      "train loss:0.00107243459812\n",
      "train loss:0.000841201396535\n",
      "train loss:0.0019883974097\n",
      "train loss:0.00216524163024\n",
      "train loss:0.000589819757383\n",
      "train loss:0.00508274848405\n",
      "train loss:0.00135328026151\n",
      "train loss:0.000407395916881\n",
      "train loss:0.00837863459229\n",
      "train loss:0.0578132268156\n",
      "train loss:0.00427147697454\n",
      "train loss:0.00189300394656\n",
      "train loss:0.00667270127012\n",
      "train loss:0.00221445065767\n",
      "train loss:0.00299033182922\n",
      "train loss:0.0015040783415\n",
      "train loss:0.00038050607435\n",
      "train loss:0.00379409520793\n",
      "train loss:0.000421459797672\n",
      "train loss:0.00238166733508\n",
      "train loss:0.00156884595095\n",
      "train loss:0.00202683228295\n",
      "train loss:0.00236610084788\n",
      "train loss:0.000601749278056\n",
      "train loss:0.00884544659166\n",
      "train loss:0.000400058789088\n",
      "train loss:0.00560926562826\n",
      "train loss:0.00174067483516\n",
      "train loss:0.00727260367172\n",
      "train loss:0.00398452508049\n",
      "train loss:0.000499884947253\n",
      "train loss:0.000612457729576\n",
      "train loss:0.00479536805829\n",
      "train loss:0.00331990883344\n",
      "train loss:0.000219980722033\n",
      "train loss:0.00242601497684\n",
      "train loss:0.0051615276899\n",
      "train loss:0.000646455410019\n",
      "train loss:0.00416762789697\n",
      "train loss:0.00378209086625\n",
      "train loss:0.00752253532931\n",
      "train loss:0.00141097580174\n",
      "train loss:0.00432782332214\n",
      "train loss:0.00380989533169\n",
      "train loss:0.00083557271768\n",
      "train loss:0.000282178535679\n",
      "train loss:0.00206881658846\n",
      "train loss:0.00137388890317\n",
      "train loss:0.000477370859536\n",
      "train loss:0.00771909703646\n",
      "train loss:0.00045036636746\n",
      "train loss:0.00280649454527\n",
      "train loss:0.00029211749565\n",
      "train loss:0.00113668140705\n",
      "train loss:0.0123277739067\n",
      "train loss:0.00772293483521\n",
      "train loss:0.000267553892792\n",
      "train loss:0.00350019426998\n",
      "train loss:0.00594537112094\n",
      "train loss:0.00154322028293\n",
      "train loss:0.00347144226452\n",
      "train loss:0.000366872153949\n",
      "train loss:0.00121248692648\n",
      "train loss:0.00124854649027\n",
      "train loss:0.00119745769215\n",
      "train loss:0.00114416183295\n",
      "train loss:0.00975800041178\n",
      "train loss:0.00422644793926\n",
      "train loss:9.72339256796e-05\n",
      "train loss:0.00470063650982\n",
      "train loss:0.000104106813933\n",
      "train loss:0.000309108505748\n",
      "train loss:0.000541551629435\n",
      "train loss:0.00335917163167\n",
      "train loss:0.00225297627362\n",
      "train loss:0.0129383093258\n",
      "train loss:0.00114861875092\n",
      "train loss:0.0130687769966\n",
      "train loss:0.000157314155248\n",
      "train loss:0.0029160425045\n",
      "train loss:0.000750107511662\n",
      "train loss:0.00413647941141\n",
      "train loss:0.000285485167339\n",
      "train loss:0.0103208091782\n",
      "train loss:0.00244233105084\n",
      "train loss:0.00229765448199\n",
      "train loss:0.000323318799028\n",
      "train loss:0.0018634690566\n",
      "train loss:0.000568594740063\n",
      "train loss:0.000421778913994\n",
      "train loss:0.00202228158311\n",
      "train loss:0.00628460068048\n",
      "train loss:0.000949810615031\n",
      "train loss:0.00935288896679\n",
      "train loss:0.000672345372681\n",
      "train loss:0.00637363012933\n",
      "train loss:0.00239715257864\n",
      "train loss:0.000402616477079\n",
      "train loss:0.00259208470426\n",
      "train loss:0.00291380576378\n",
      "train loss:0.000360220592116\n",
      "train loss:0.000215859592376\n",
      "train loss:0.000852153524083\n",
      "train loss:0.0029718790124\n",
      "train loss:0.000117450916348\n",
      "train loss:0.00131996045385\n",
      "train loss:0.00063422478395\n",
      "train loss:2.20940091203e-05\n",
      "train loss:0.00143305448963\n",
      "train loss:0.0228646665621\n",
      "train loss:0.00543960073819\n",
      "train loss:0.00086180183269\n",
      "train loss:0.000105811049484\n",
      "train loss:0.00347583248163\n",
      "train loss:0.00438234689448\n",
      "train loss:0.0011829421992\n",
      "train loss:0.00430826387873\n",
      "train loss:0.00285096525436\n",
      "train loss:0.00224356536929\n",
      "train loss:0.000990629144477\n",
      "train loss:0.000699564655735\n",
      "train loss:0.000345144865077\n",
      "train loss:0.00131515187481\n",
      "train loss:0.00431144902801\n",
      "train loss:0.000645745942483\n",
      "train loss:0.000644840402802\n",
      "train loss:0.000726370942796\n",
      "train loss:0.00371344314641\n",
      "train loss:0.000660253280365\n",
      "train loss:0.000350306793298\n",
      "train loss:0.00140365702868\n",
      "train loss:0.00125626505228\n",
      "train loss:0.00364645809946\n",
      "train loss:0.00069199280992\n",
      "train loss:0.0077634501837\n",
      "train loss:0.00432495526811\n",
      "train loss:0.0730007819385\n",
      "train loss:0.000681722203824\n",
      "train loss:0.000975368629179\n",
      "train loss:0.000161479147916\n",
      "train loss:0.000684885075794\n",
      "train loss:0.00385937315299\n",
      "train loss:0.0082058600758\n",
      "train loss:0.00055907677344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00369303576173\n",
      "train loss:0.00152099510008\n",
      "train loss:0.00412377414006\n",
      "train loss:0.0395784295165\n",
      "train loss:0.000471292679018\n",
      "train loss:0.00335405562039\n",
      "train loss:0.00405069054219\n",
      "train loss:0.000482956100915\n",
      "=== epoch:15, train acc:0.998, test acc:0.99 ===\n",
      "train loss:0.00312694499395\n",
      "train loss:0.00143616421971\n",
      "train loss:0.00582312260232\n",
      "train loss:0.000342664906162\n",
      "train loss:0.00208048089408\n",
      "train loss:0.000676373519913\n",
      "train loss:0.000640693408258\n",
      "train loss:0.000388791844478\n",
      "train loss:0.0151185231183\n",
      "train loss:0.0184555760612\n",
      "train loss:0.000372997556793\n",
      "train loss:0.000146151174204\n",
      "train loss:0.00294633760769\n",
      "train loss:0.00298917269326\n",
      "train loss:0.000135057964934\n",
      "train loss:0.000683510218869\n",
      "train loss:0.000461134094825\n",
      "train loss:0.00424674258666\n",
      "train loss:0.0011639882147\n",
      "train loss:0.00171157726525\n",
      "train loss:0.00568619835704\n",
      "train loss:0.000337728190281\n",
      "train loss:0.00239482387068\n",
      "train loss:0.00190956943202\n",
      "train loss:0.00479673963084\n",
      "train loss:0.000976597014371\n",
      "train loss:0.00322847682378\n",
      "train loss:0.000771993943069\n",
      "train loss:0.00372018164349\n",
      "train loss:0.00230395642272\n",
      "train loss:0.000738101400328\n",
      "train loss:0.00459196878597\n",
      "train loss:0.0127651615276\n",
      "train loss:0.00251218761908\n",
      "train loss:0.000185298701948\n",
      "train loss:0.000904876652673\n",
      "train loss:0.00959563872189\n",
      "train loss:0.0106063397552\n",
      "train loss:0.00852975845965\n",
      "train loss:0.000538070565857\n",
      "train loss:0.000429982105299\n",
      "train loss:0.00158948705811\n",
      "train loss:0.000967002121707\n",
      "train loss:0.00305777588705\n",
      "train loss:0.0040286071726\n",
      "train loss:0.0170039154053\n",
      "train loss:0.00415708846386\n",
      "train loss:0.00152191498757\n",
      "train loss:0.00664813686653\n",
      "train loss:0.00320950860633\n",
      "train loss:0.00274507894339\n",
      "train loss:0.0029692550737\n",
      "train loss:0.000727578162968\n",
      "train loss:0.000467398380641\n",
      "train loss:0.00937768443236\n",
      "train loss:0.000672551132805\n",
      "train loss:0.00429307396247\n",
      "train loss:0.00586320168691\n",
      "train loss:0.00583675436293\n",
      "train loss:0.00361358070764\n",
      "train loss:0.00210942496905\n",
      "train loss:0.00201504391961\n",
      "train loss:0.00088048145163\n",
      "train loss:0.00256068271651\n",
      "train loss:0.00044058339409\n",
      "train loss:0.00125709763472\n",
      "train loss:0.0102248698899\n",
      "train loss:0.000588404758948\n",
      "train loss:0.000760080703918\n",
      "train loss:0.00100321706581\n",
      "train loss:0.00370662548842\n",
      "train loss:0.00248295130635\n",
      "train loss:0.000976792666855\n",
      "train loss:0.000517902921907\n",
      "train loss:0.000888833444079\n",
      "train loss:0.000593446726711\n",
      "train loss:0.0020778333584\n",
      "train loss:0.00505894516599\n",
      "train loss:0.011435928836\n",
      "train loss:0.000145189736158\n",
      "train loss:0.00134149337617\n",
      "train loss:0.00339332590386\n",
      "train loss:0.000325835759942\n",
      "train loss:0.00384750668287\n",
      "train loss:0.00548942171298\n",
      "train loss:0.00426150489866\n",
      "train loss:0.000758126413319\n",
      "train loss:0.0139685195997\n",
      "train loss:0.00169008283385\n",
      "train loss:0.00159666138066\n",
      "train loss:0.0154313591401\n",
      "train loss:0.00460225474431\n",
      "train loss:0.00911944689412\n",
      "train loss:0.0236514786403\n",
      "train loss:0.000314468894487\n",
      "train loss:0.00203764749419\n",
      "train loss:0.00172762423907\n",
      "train loss:0.00264980361924\n",
      "train loss:0.00410570349313\n",
      "train loss:0.00228415118983\n",
      "train loss:0.00168859158501\n",
      "train loss:0.000422876342404\n",
      "train loss:0.000254821071477\n",
      "train loss:0.00733319647462\n",
      "train loss:0.00336059596066\n",
      "train loss:0.00391324887123\n",
      "train loss:0.00218573097265\n",
      "train loss:0.000972038746745\n",
      "train loss:0.0191651099665\n",
      "train loss:0.00220666571012\n",
      "train loss:0.000855451440797\n",
      "train loss:0.00265934929322\n",
      "train loss:0.0089324136389\n",
      "train loss:0.00743634307069\n",
      "train loss:0.000423288872326\n",
      "train loss:0.00243425335734\n",
      "train loss:0.00450190257403\n",
      "train loss:0.000140869764296\n",
      "train loss:0.00188858187525\n",
      "train loss:0.0166284865373\n",
      "train loss:0.0103256931765\n",
      "train loss:0.0213010102087\n",
      "train loss:0.000863888208851\n",
      "train loss:0.000529485707048\n",
      "train loss:0.000632818738126\n",
      "train loss:0.00250246151047\n",
      "train loss:0.00131460573389\n",
      "train loss:0.00237782554666\n",
      "train loss:0.00583200581644\n",
      "train loss:0.0118304052763\n",
      "train loss:0.0104161614176\n",
      "train loss:0.000584944038622\n",
      "train loss:0.00195614889225\n",
      "train loss:0.00335426932718\n",
      "train loss:0.0044375092085\n",
      "train loss:0.00307965362997\n",
      "train loss:0.0122428848328\n",
      "train loss:0.00676512564855\n",
      "train loss:0.00741097798177\n",
      "train loss:0.00940104369567\n",
      "train loss:0.0365653019076\n",
      "train loss:0.00236134166917\n",
      "train loss:0.00693372529865\n",
      "train loss:0.00291945051798\n",
      "train loss:0.00986930493377\n",
      "train loss:0.0126500714311\n",
      "train loss:0.00687921933732\n",
      "train loss:0.0083631242876\n",
      "train loss:0.00143601671629\n",
      "train loss:0.00265294637953\n",
      "train loss:0.00333229989908\n",
      "train loss:0.0044811288199\n",
      "train loss:0.00592554431633\n",
      "train loss:0.00825281217703\n",
      "train loss:0.00202797396004\n",
      "train loss:0.00493117195828\n",
      "train loss:0.000868019890434\n",
      "train loss:0.000605107257116\n",
      "train loss:0.00193569886816\n",
      "train loss:0.00163459127822\n",
      "train loss:0.00376881648005\n",
      "train loss:0.0004635873252\n",
      "train loss:0.00239756440488\n",
      "train loss:0.0023017642814\n",
      "train loss:0.00101221225484\n",
      "train loss:0.00145073905135\n",
      "train loss:0.00540648098589\n",
      "train loss:0.00172153845608\n",
      "train loss:0.00355760980483\n",
      "train loss:0.00132623889258\n",
      "train loss:0.000411591849396\n",
      "train loss:0.00932932454205\n",
      "train loss:0.000189850152596\n",
      "train loss:0.000459027805403\n",
      "train loss:0.00226532331942\n",
      "train loss:0.00647389497958\n",
      "train loss:0.00354451433385\n",
      "train loss:0.00147350306308\n",
      "train loss:0.00274007637462\n",
      "train loss:0.00156242291615\n",
      "train loss:0.0268611794527\n",
      "train loss:0.0062997064393\n",
      "train loss:0.0033990164504\n",
      "train loss:0.00298476425874\n",
      "train loss:0.0066824624199\n",
      "train loss:0.00338863005223\n",
      "train loss:0.00359447960547\n",
      "train loss:0.00116416574959\n",
      "train loss:0.00545831727281\n",
      "train loss:0.000243535440773\n",
      "train loss:0.00228974983052\n",
      "train loss:0.00412390960298\n",
      "train loss:0.000194430254272\n",
      "train loss:0.00349973998109\n",
      "train loss:0.0130748702419\n",
      "train loss:0.014845999156\n",
      "train loss:0.00190296748255\n",
      "train loss:0.00148019828735\n",
      "train loss:0.0126018123185\n",
      "train loss:0.000390764509646\n",
      "train loss:0.000594598998419\n",
      "train loss:0.00448691873809\n",
      "train loss:0.00253032817348\n",
      "train loss:0.00684415327591\n",
      "train loss:0.000625058291212\n",
      "train loss:0.00105657072486\n",
      "train loss:0.00735965832724\n",
      "train loss:0.00347134155831\n",
      "train loss:0.00466353338526\n",
      "train loss:0.000204252865064\n",
      "train loss:0.000720017355083\n",
      "train loss:0.00213554128671\n",
      "train loss:0.00498605783392\n",
      "train loss:0.000239726125096\n",
      "train loss:0.0154103738242\n",
      "train loss:0.000304821696273\n",
      "train loss:0.00288471967544\n",
      "train loss:0.00375366549454\n",
      "train loss:0.00326574242562\n",
      "train loss:0.00475433479247\n",
      "train loss:0.000941535610054\n",
      "train loss:0.00534812934003\n",
      "train loss:0.00272729543504\n",
      "train loss:0.000317032807662\n",
      "train loss:0.00196077253101\n",
      "train loss:0.000108777786624\n",
      "train loss:0.000218417559965\n",
      "train loss:0.00133032526571\n",
      "train loss:0.000434440096619\n",
      "train loss:0.00672750068242\n",
      "train loss:0.0032186401035\n",
      "train loss:0.00161864211292\n",
      "train loss:0.00157290634264\n",
      "train loss:0.0143318526337\n",
      "train loss:0.0025200159983\n",
      "train loss:0.00204323384005\n",
      "train loss:0.00118770353256\n",
      "train loss:0.000458993432686\n",
      "train loss:0.0057031562631\n",
      "train loss:0.00053157433846\n",
      "train loss:0.00138267732272\n",
      "train loss:0.00195467002494\n",
      "train loss:0.00368950149032\n",
      "train loss:0.000791597233268\n",
      "train loss:0.000547458313441\n",
      "train loss:0.00228180395987\n",
      "train loss:3.13033094825e-05\n",
      "train loss:0.000919518214914\n",
      "train loss:0.00016321562616\n",
      "train loss:0.00165595060481\n",
      "train loss:0.00207521808757\n",
      "train loss:0.00107701599643\n",
      "train loss:0.00254619803021\n",
      "train loss:0.00127512469284\n",
      "train loss:0.000781170740864\n",
      "train loss:7.19085997989e-05\n",
      "train loss:0.00313625986299\n",
      "train loss:0.000744056822605\n",
      "train loss:0.000767422598116\n",
      "train loss:0.000202022783632\n",
      "train loss:0.000337607256955\n",
      "train loss:0.000827035817298\n",
      "train loss:0.00238345897644\n",
      "train loss:0.00185836194531\n",
      "train loss:7.93284391164e-05\n",
      "train loss:0.00182957410847\n",
      "train loss:0.00190021508489\n",
      "train loss:0.00410432086533\n",
      "train loss:0.000402834832321\n",
      "train loss:0.0101789966496\n",
      "train loss:0.000923339252646\n",
      "train loss:0.00310929645182\n",
      "train loss:0.000229009786654\n",
      "train loss:0.000366618039703\n",
      "train loss:0.00550155158429\n",
      "train loss:0.00184284433978\n",
      "train loss:0.0012337386842\n",
      "train loss:0.00157984201268\n",
      "train loss:0.000325034817538\n",
      "train loss:0.0027392543246\n",
      "train loss:0.00578713193693\n",
      "train loss:0.001715459529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00552535860188\n",
      "train loss:7.23887146633e-05\n",
      "train loss:0.00603825251808\n",
      "train loss:0.000630696347871\n",
      "train loss:0.0018199720017\n",
      "train loss:0.00141429110099\n",
      "train loss:0.000253260599868\n",
      "train loss:0.000723153877598\n",
      "train loss:0.000310167723709\n",
      "train loss:0.00170279467773\n",
      "train loss:0.00126018249322\n",
      "train loss:0.00114988431232\n",
      "train loss:0.00234730321058\n",
      "train loss:0.0179672984674\n",
      "train loss:0.000731854278323\n",
      "train loss:0.0154904587518\n",
      "train loss:0.000854006908778\n",
      "train loss:0.00166259515163\n",
      "train loss:0.0118957149067\n",
      "train loss:0.00178598849223\n",
      "train loss:0.00168430365808\n",
      "train loss:0.00102170344671\n",
      "train loss:0.00721651376715\n",
      "train loss:0.0423573004298\n",
      "train loss:0.00138821038547\n",
      "train loss:0.0138251935162\n",
      "train loss:0.000474471792554\n",
      "train loss:0.0043258329496\n",
      "train loss:0.000904703128923\n",
      "train loss:0.00297019072229\n",
      "train loss:0.00079884985707\n",
      "train loss:0.00112062335221\n",
      "train loss:0.000353432462073\n",
      "train loss:0.00221926522033\n",
      "train loss:0.00374013875576\n",
      "train loss:0.000198433655217\n",
      "train loss:0.00115248074652\n",
      "train loss:0.000947001825893\n",
      "train loss:0.00196822444854\n",
      "train loss:0.00295904395334\n",
      "train loss:0.00166379213902\n",
      "train loss:0.00723630404217\n",
      "train loss:0.00156193737206\n",
      "train loss:0.00120313839461\n",
      "train loss:0.000467327070997\n",
      "train loss:0.00518714665327\n",
      "train loss:0.00121790552067\n",
      "train loss:0.00116596963314\n",
      "train loss:0.000437248630224\n",
      "train loss:0.00127281990581\n",
      "train loss:0.012252698516\n",
      "train loss:0.000319748677407\n",
      "train loss:0.00447842179085\n",
      "train loss:0.00376463550583\n",
      "train loss:0.00457385488319\n",
      "train loss:0.000177662467263\n",
      "train loss:0.00117355140965\n",
      "train loss:0.00120564282348\n",
      "train loss:0.004972031402\n",
      "train loss:0.00277071024081\n",
      "train loss:0.0335527076392\n",
      "train loss:0.000936752007379\n",
      "train loss:0.00393942199631\n",
      "train loss:0.00091570850327\n",
      "train loss:0.000150731093644\n",
      "train loss:0.00385817706379\n",
      "train loss:0.00626078124569\n",
      "train loss:0.00542970072523\n",
      "train loss:0.000363521034682\n",
      "train loss:0.00174896219168\n",
      "train loss:0.000981523298133\n",
      "train loss:0.00275333594609\n",
      "train loss:0.000137000933251\n",
      "train loss:0.00557522321193\n",
      "train loss:0.00118668667674\n",
      "train loss:0.000389058368476\n",
      "train loss:0.00236451600863\n",
      "train loss:0.000633196528307\n",
      "train loss:0.00122719953336\n",
      "train loss:0.00148438837816\n",
      "train loss:0.00366952640732\n",
      "train loss:0.000648573694754\n",
      "train loss:0.00509295861475\n",
      "train loss:0.000202701669485\n",
      "train loss:0.00040229674815\n",
      "train loss:0.000501677749388\n",
      "train loss:0.00112383945842\n",
      "train loss:0.0107646006665\n",
      "train loss:0.00299286995473\n",
      "train loss:0.000138624884747\n",
      "train loss:0.00259395129986\n",
      "train loss:0.000871968805657\n",
      "train loss:6.92035809398e-05\n",
      "train loss:0.000205633833041\n",
      "train loss:0.00429932243332\n",
      "train loss:0.000859673987951\n",
      "train loss:0.00309395094333\n",
      "train loss:0.000933707025145\n",
      "train loss:0.000655523275412\n",
      "train loss:0.00128181424688\n",
      "train loss:0.00082801162277\n",
      "train loss:0.00598324511194\n",
      "train loss:0.000264254938314\n",
      "train loss:0.0339571350132\n",
      "train loss:0.0117930608313\n",
      "train loss:0.000500949070595\n",
      "train loss:0.0023040130282\n",
      "train loss:0.00291420409473\n",
      "train loss:0.00891553127389\n",
      "train loss:0.00938069412673\n",
      "train loss:0.00368878998456\n",
      "train loss:0.00193768734679\n",
      "train loss:0.00140023897437\n",
      "train loss:0.00139878624062\n",
      "train loss:0.000115822964119\n",
      "train loss:0.00298522232378\n",
      "train loss:0.00180817096358\n",
      "train loss:0.000338641598741\n",
      "train loss:0.00104721214723\n",
      "train loss:0.00475179602174\n",
      "train loss:0.000899475389377\n",
      "train loss:0.00282537613646\n",
      "train loss:0.00420249033252\n",
      "train loss:0.00154691148815\n",
      "train loss:0.00414288966046\n",
      "train loss:0.000587757032858\n",
      "train loss:0.000339703186874\n",
      "train loss:0.000156581021202\n",
      "train loss:0.00166237196645\n",
      "train loss:0.0020570715416\n",
      "train loss:0.0097972431394\n",
      "train loss:0.00654501548337\n",
      "train loss:0.0227691012245\n",
      "train loss:0.00232922873811\n",
      "train loss:0.00057865562862\n",
      "train loss:0.00755505247036\n",
      "train loss:0.00266947070067\n",
      "train loss:0.00109106431702\n",
      "train loss:0.000461086774698\n",
      "train loss:0.000230421698955\n",
      "train loss:0.0026562518354\n",
      "train loss:0.00560282373848\n",
      "train loss:0.00159791338838\n",
      "train loss:0.000108077692952\n",
      "train loss:0.00261205026802\n",
      "train loss:0.00153878958427\n",
      "train loss:0.00105500668703\n",
      "train loss:0.00302614303221\n",
      "train loss:0.000452712657816\n",
      "train loss:0.00182777795689\n",
      "train loss:0.000314567907374\n",
      "train loss:0.000325183729568\n",
      "train loss:0.000846346112738\n",
      "train loss:0.000252712959041\n",
      "train loss:0.00331334875486\n",
      "train loss:0.00131581005384\n",
      "train loss:0.000272708766975\n",
      "train loss:0.00512322844367\n",
      "train loss:0.000432192337261\n",
      "train loss:0.00246896658546\n",
      "train loss:0.00355592637474\n",
      "train loss:0.000389055946785\n",
      "train loss:0.00226640532326\n",
      "train loss:0.00192421421716\n",
      "train loss:0.0518115001339\n",
      "train loss:0.00308927440003\n",
      "train loss:0.0116324931329\n",
      "train loss:0.00144042481096\n",
      "train loss:0.0227215221479\n",
      "train loss:0.000492322842305\n",
      "train loss:0.0110577734877\n",
      "train loss:0.000106595039096\n",
      "train loss:0.00657623983534\n",
      "train loss:0.000250052394247\n",
      "train loss:0.000547130801158\n",
      "train loss:0.0127612079592\n",
      "train loss:0.000973144380642\n",
      "train loss:0.00153063713373\n",
      "train loss:8.97587725079e-05\n",
      "train loss:0.00382275881356\n",
      "train loss:0.00513568326572\n",
      "train loss:0.0151666495396\n",
      "train loss:0.00535715638524\n",
      "train loss:0.00280171037699\n",
      "train loss:0.000823862751197\n",
      "train loss:0.00199423092054\n",
      "train loss:0.00500848035979\n",
      "train loss:0.0248392518168\n",
      "train loss:0.00501413198279\n",
      "train loss:0.000413005906148\n",
      "train loss:0.000799251481327\n",
      "train loss:0.0249590351057\n",
      "train loss:0.000873610267872\n",
      "train loss:0.00309850864382\n",
      "train loss:0.00164352371505\n",
      "train loss:0.00160000329567\n",
      "train loss:0.00135715170539\n",
      "train loss:0.00426106934813\n",
      "train loss:0.0006408638039\n",
      "train loss:0.00197673281866\n",
      "train loss:0.00250775324459\n",
      "train loss:0.00310787559628\n",
      "train loss:0.00126469234779\n",
      "train loss:0.0004981934733\n",
      "train loss:0.00290436456145\n",
      "train loss:0.00467941637738\n",
      "train loss:0.00729799457235\n",
      "train loss:0.00218935228795\n",
      "train loss:0.000692648190767\n",
      "train loss:0.00100079162818\n",
      "train loss:0.00158661855257\n",
      "train loss:0.000616899993038\n",
      "train loss:0.00187243927454\n",
      "train loss:0.001618056392\n",
      "train loss:0.00358251643875\n",
      "train loss:0.000211494574995\n",
      "train loss:0.0024079305934\n",
      "train loss:0.00385688756377\n",
      "train loss:0.00178552611195\n",
      "train loss:0.00106180318816\n",
      "train loss:0.000590044876736\n",
      "train loss:0.00695880718529\n",
      "train loss:0.00104578682224\n",
      "train loss:0.00201570720605\n",
      "train loss:0.00277053666932\n",
      "train loss:0.00154238974193\n",
      "train loss:0.0020337409343\n",
      "train loss:0.00304056762785\n",
      "train loss:0.00136613433049\n",
      "train loss:0.0031305287579\n",
      "train loss:0.00244672979054\n",
      "train loss:0.0172544570474\n",
      "train loss:0.00085665906615\n",
      "train loss:0.00159008034231\n",
      "train loss:0.00429915293009\n",
      "train loss:0.000748959727836\n",
      "train loss:0.00267139925174\n",
      "train loss:0.0029545154231\n",
      "train loss:0.00256260862512\n",
      "train loss:0.0020532387561\n",
      "train loss:0.00109448023976\n",
      "train loss:0.00102544081862\n",
      "train loss:0.00485854290388\n",
      "train loss:0.000639844144551\n",
      "train loss:0.000774152806166\n",
      "train loss:0.00113652057279\n",
      "train loss:0.00426176312473\n",
      "train loss:0.00129276213104\n",
      "train loss:0.00422481618604\n",
      "train loss:0.000577412909912\n",
      "train loss:0.00337871331441\n",
      "train loss:0.000266395288645\n",
      "train loss:0.00127825762806\n",
      "train loss:0.0109257656009\n",
      "train loss:0.000603358955495\n",
      "train loss:0.000846208543257\n",
      "train loss:0.00305029689499\n",
      "train loss:0.00102309495153\n",
      "train loss:0.000413130092435\n",
      "train loss:0.000893627021143\n",
      "train loss:0.00170917624849\n",
      "train loss:0.00226595161183\n",
      "train loss:0.00432134561392\n",
      "train loss:0.00501750750474\n",
      "train loss:0.00702547694308\n",
      "train loss:0.000817596630523\n",
      "train loss:0.000205640729238\n",
      "train loss:0.00173193629047\n",
      "train loss:0.00602053976366\n",
      "train loss:0.00169034728088\n",
      "train loss:0.00020350423375\n",
      "train loss:0.000743358247821\n",
      "train loss:0.00195170671455\n",
      "train loss:0.000553126636964\n",
      "train loss:0.000486937856129\n",
      "train loss:0.0018312723316\n",
      "train loss:0.00286383138933\n",
      "train loss:0.00386133884189\n",
      "train loss:0.000788366022703\n",
      "train loss:0.00111970611537\n",
      "train loss:0.000532963268228\n",
      "train loss:0.000152816200578\n",
      "train loss:0.00424430978473\n",
      "train loss:0.0047746789207\n",
      "train loss:0.000446768351687\n",
      "train loss:0.00474827082334\n",
      "train loss:0.00121602713786\n",
      "train loss:0.00376980026486\n",
      "train loss:0.00124549934995\n",
      "train loss:0.000723275711519\n",
      "train loss:0.000476491235842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00195233264576\n",
      "train loss:0.00152361784856\n",
      "train loss:0.00043399196078\n",
      "train loss:0.00196155610333\n",
      "train loss:0.000200215658127\n",
      "train loss:0.00042880465796\n",
      "train loss:0.000805008120382\n",
      "train loss:0.00364448158128\n",
      "train loss:0.000687010424685\n",
      "train loss:0.00112622509667\n",
      "train loss:0.00376272144956\n",
      "train loss:0.00163030612889\n",
      "train loss:0.00360716831915\n",
      "train loss:0.00253530192584\n",
      "train loss:0.000591853234598\n",
      "train loss:0.000528052399648\n",
      "train loss:0.000605208862076\n",
      "train loss:0.00148449653048\n",
      "train loss:0.000221407817036\n",
      "train loss:0.00191292566969\n",
      "train loss:0.00120067725605\n",
      "train loss:0.000976312017909\n",
      "train loss:0.00197455576592\n",
      "train loss:0.00164637425223\n",
      "train loss:0.000801139449884\n",
      "train loss:0.000651017827426\n",
      "train loss:0.00231128492711\n",
      "=== epoch:16, train acc:0.996, test acc:0.988 ===\n",
      "train loss:0.00182455829365\n",
      "train loss:0.00473892888104\n",
      "train loss:0.000386403158375\n",
      "train loss:0.00512425579557\n",
      "train loss:0.00133361600309\n",
      "train loss:0.0043097815819\n",
      "train loss:7.17576146737e-05\n",
      "train loss:0.000940583565152\n",
      "train loss:0.00773369953901\n",
      "train loss:0.00323003899221\n",
      "train loss:0.000901763476487\n",
      "train loss:0.000177030574078\n",
      "train loss:0.00530187620469\n",
      "train loss:6.22296244222e-05\n",
      "train loss:0.00178575944922\n",
      "train loss:0.000994274733614\n",
      "train loss:0.00171845642817\n",
      "train loss:0.00768034022673\n",
      "train loss:0.0024571606991\n",
      "train loss:0.00264871209512\n",
      "train loss:0.00134326360449\n",
      "train loss:0.000972675514802\n",
      "train loss:0.00144506614479\n",
      "train loss:0.000287963989217\n",
      "train loss:0.00321311196771\n",
      "train loss:0.000220434731242\n",
      "train loss:0.000223193555739\n",
      "train loss:0.00133979382021\n",
      "train loss:0.000856713497555\n",
      "train loss:0.000139519088302\n",
      "train loss:0.00384768962927\n",
      "train loss:0.000492106229532\n",
      "train loss:0.000585848136277\n",
      "train loss:0.00530596704617\n",
      "train loss:0.00022634198954\n",
      "train loss:0.00472463418969\n",
      "train loss:0.00092804985339\n",
      "train loss:0.000146068918637\n",
      "train loss:0.000793608278026\n",
      "train loss:8.71807697099e-05\n",
      "train loss:0.000498386876701\n",
      "train loss:0.0126451149516\n",
      "train loss:0.000179481751044\n",
      "train loss:0.00607292541007\n",
      "train loss:0.0010252063142\n",
      "train loss:0.000433888041363\n",
      "train loss:0.000310286971025\n",
      "train loss:0.00154711559435\n",
      "train loss:0.00446215284289\n",
      "train loss:0.00052367250086\n",
      "train loss:0.00134941039601\n",
      "train loss:0.00110716467802\n",
      "train loss:0.0107725432818\n",
      "train loss:0.00260930777791\n",
      "train loss:0.000445444163361\n",
      "train loss:0.00128247329879\n",
      "train loss:0.000474608629781\n",
      "train loss:0.00321496078163\n",
      "train loss:0.000512889857655\n",
      "train loss:0.00315947016589\n",
      "train loss:0.00303635571448\n",
      "train loss:0.0047916335779\n",
      "train loss:0.00113802271011\n",
      "train loss:0.000642397606077\n",
      "train loss:0.000569011068876\n",
      "train loss:0.00558120964428\n",
      "train loss:0.00208958780649\n",
      "train loss:0.00037845901761\n",
      "train loss:0.00209998533364\n",
      "train loss:0.00113648789188\n",
      "train loss:0.000237173059056\n",
      "train loss:0.00159328168351\n",
      "train loss:0.00132543626812\n",
      "train loss:0.000470143241793\n",
      "train loss:0.000356149910304\n",
      "train loss:2.67622803426e-05\n",
      "train loss:0.00103997600185\n",
      "train loss:0.000649928818679\n",
      "train loss:0.000123100931359\n",
      "train loss:0.000316826689698\n",
      "train loss:0.00607757532178\n",
      "train loss:0.0332618184776\n",
      "train loss:0.000436002406115\n",
      "train loss:0.00304509593641\n",
      "train loss:0.0291157630616\n",
      "train loss:0.00166415020306\n",
      "train loss:0.00300792208711\n",
      "train loss:0.00071644978877\n",
      "train loss:0.0123387774836\n",
      "train loss:0.000600548574419\n",
      "train loss:0.00217093155006\n",
      "train loss:0.00912028896311\n",
      "train loss:0.00123713018953\n",
      "train loss:0.000963658443609\n",
      "train loss:0.00644106701481\n",
      "train loss:0.00962642137958\n",
      "train loss:0.000959477876234\n",
      "train loss:0.000150196357606\n",
      "train loss:0.00118457538334\n",
      "train loss:0.000879606028385\n",
      "train loss:0.00183650067114\n",
      "train loss:0.000138588320158\n",
      "train loss:0.00092060036159\n",
      "train loss:0.000607560583877\n",
      "train loss:0.000142039363544\n",
      "train loss:4.90246859211e-05\n",
      "train loss:0.00327373439874\n",
      "train loss:0.000668869697788\n",
      "train loss:0.00367752895274\n",
      "train loss:0.000867055366149\n",
      "train loss:0.000255218419933\n",
      "train loss:0.00165217818955\n",
      "train loss:0.00142307372331\n",
      "train loss:6.24313301549e-05\n",
      "train loss:0.00292191576859\n",
      "train loss:0.000468325157996\n",
      "train loss:0.00702467119543\n",
      "train loss:0.00404776057109\n",
      "train loss:0.00430963013131\n",
      "train loss:0.00106340231372\n",
      "train loss:0.000882707268679\n",
      "train loss:0.00214635421206\n",
      "train loss:0.00659684522639\n",
      "train loss:0.00632639360799\n",
      "train loss:0.00134022059495\n",
      "train loss:0.000192948447313\n",
      "train loss:0.00208011293622\n",
      "train loss:0.000360077271773\n",
      "train loss:0.000379789675236\n",
      "train loss:0.000861314313742\n",
      "train loss:5.38117918804e-05\n",
      "train loss:0.0198134012973\n",
      "train loss:0.00116609261871\n",
      "train loss:0.000909067786067\n",
      "train loss:0.00164722760214\n",
      "train loss:0.00154904865234\n",
      "train loss:0.000280778945782\n",
      "train loss:0.00042231409266\n",
      "train loss:0.0048200312259\n",
      "train loss:0.00147469780523\n",
      "train loss:0.00206635023486\n",
      "train loss:0.0139932835534\n",
      "train loss:0.0011306581625\n",
      "train loss:0.000174541418892\n",
      "train loss:0.000547652030047\n",
      "train loss:0.00244163990873\n",
      "train loss:0.00129196160136\n",
      "train loss:0.00962287392898\n",
      "train loss:0.000109724960209\n",
      "train loss:0.000223054430757\n",
      "train loss:0.00250684766559\n",
      "train loss:0.000841545822612\n",
      "train loss:0.000516371801548\n",
      "train loss:0.00167999123273\n",
      "train loss:0.000239102065561\n",
      "train loss:0.000622073758644\n",
      "train loss:0.00137067238202\n",
      "train loss:0.00157618976469\n",
      "train loss:0.00385970766174\n",
      "train loss:8.6836086598e-05\n",
      "train loss:0.000823775221921\n",
      "train loss:0.000423595496111\n",
      "train loss:0.000932392495875\n",
      "train loss:0.000337527870121\n",
      "train loss:0.00012344407172\n",
      "train loss:0.000378304740472\n",
      "train loss:0.000780700167811\n",
      "train loss:0.000956644750201\n",
      "train loss:0.0376683589124\n",
      "train loss:0.00396691067132\n",
      "train loss:0.000314178332792\n",
      "train loss:0.00354016873085\n",
      "train loss:0.000871523175855\n",
      "train loss:0.00481765218122\n",
      "train loss:0.000576188917372\n",
      "train loss:0.00165790128145\n",
      "train loss:0.000624295432143\n",
      "train loss:0.00148031527177\n",
      "train loss:0.00108606661041\n",
      "train loss:0.00244048605766\n",
      "train loss:0.00058860825632\n",
      "train loss:0.00250197761291\n",
      "train loss:0.00424126114799\n",
      "train loss:0.0028642184305\n",
      "train loss:0.00232432969339\n",
      "train loss:0.000837296383214\n",
      "train loss:0.00271670750704\n",
      "train loss:0.000881290797871\n",
      "train loss:0.00195874581026\n",
      "train loss:0.00565585200076\n",
      "train loss:0.00140744058838\n",
      "train loss:0.000587792155035\n",
      "train loss:0.00129394224922\n",
      "train loss:0.0239014803532\n",
      "train loss:0.0039800805952\n",
      "train loss:0.000278972001804\n",
      "train loss:0.000658528003399\n",
      "train loss:0.00421227842944\n",
      "train loss:0.00708442041263\n",
      "train loss:0.000699929627733\n",
      "train loss:0.00155790969168\n",
      "train loss:0.00481274098013\n",
      "train loss:0.00235696576075\n",
      "train loss:0.0024284019321\n",
      "train loss:0.00118565510363\n",
      "train loss:0.00253878759809\n",
      "train loss:0.00198997851959\n",
      "train loss:0.00121885504622\n",
      "train loss:0.00102144730217\n",
      "train loss:0.00204523805444\n",
      "train loss:0.00291935075426\n",
      "train loss:0.00780305183305\n",
      "train loss:0.000959872015113\n",
      "train loss:0.000640142298093\n",
      "train loss:4.09531844585e-05\n",
      "train loss:0.000613565267747\n",
      "train loss:0.000926354028387\n",
      "train loss:0.000245111082993\n",
      "train loss:0.00123237014301\n",
      "train loss:0.000477796232512\n",
      "train loss:0.00203407185339\n",
      "train loss:0.000484389345869\n",
      "train loss:0.000566262203154\n",
      "train loss:0.000402146676361\n",
      "train loss:0.00082656891059\n",
      "train loss:4.79613787704e-05\n",
      "train loss:0.00165441167983\n",
      "train loss:0.000542569918348\n",
      "train loss:0.000408309427689\n",
      "train loss:0.000144281084643\n",
      "train loss:0.00310174854386\n",
      "train loss:0.000714843766667\n",
      "train loss:0.00271276300832\n",
      "train loss:0.000134452676837\n",
      "train loss:0.00173600377583\n",
      "train loss:0.000158992484566\n",
      "train loss:0.00150395049055\n",
      "train loss:0.000885652634117\n",
      "train loss:0.00141008232079\n",
      "train loss:0.000505780537558\n",
      "train loss:0.000371637694644\n",
      "train loss:2.18670125294e-05\n",
      "train loss:0.000123253508234\n",
      "train loss:0.000627236740482\n",
      "train loss:0.00160789908118\n",
      "train loss:0.000551905169392\n",
      "train loss:0.00275991758763\n",
      "train loss:0.000580096536651\n",
      "train loss:0.0028862753087\n",
      "train loss:4.79195919901e-05\n",
      "train loss:0.000196532900934\n",
      "train loss:0.00015780190773\n",
      "train loss:0.000346446226196\n",
      "train loss:0.000115962309425\n",
      "train loss:0.00134974012815\n",
      "train loss:0.000167357709842\n",
      "train loss:0.00077376068245\n",
      "train loss:0.00330897532095\n",
      "train loss:0.000104082447461\n",
      "train loss:0.00158226753435\n",
      "train loss:0.00036616395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:9.07524456964e-05\n",
      "train loss:0.00117764492208\n",
      "train loss:0.000431997784491\n",
      "train loss:0.000180881851372\n",
      "train loss:7.891994151e-05\n",
      "train loss:0.00159980270349\n",
      "train loss:0.00163800510789\n",
      "train loss:9.42529857476e-05\n",
      "train loss:0.00013395172528\n",
      "train loss:0.000162721916321\n",
      "train loss:0.000172326690815\n",
      "train loss:0.000814466295864\n",
      "train loss:2.1437086588e-05\n",
      "train loss:0.000740439177115\n",
      "train loss:0.000110154846701\n",
      "train loss:0.000113168728048\n",
      "train loss:0.000696138336954\n",
      "train loss:0.000238041460179\n",
      "train loss:0.00111242336428\n",
      "train loss:0.000357704990517\n",
      "train loss:0.00326244604397\n",
      "train loss:0.000715854472441\n",
      "train loss:0.000344537755166\n",
      "train loss:0.000743579007982\n",
      "train loss:0.00134449886926\n",
      "train loss:0.000175928166962\n",
      "train loss:0.000433645802987\n",
      "train loss:0.000182667964905\n",
      "train loss:0.000794429543463\n",
      "train loss:0.000257955978497\n",
      "train loss:0.000335904708918\n",
      "train loss:0.000467292610104\n",
      "train loss:0.000456292995384\n",
      "train loss:0.00046693979776\n",
      "train loss:0.000152456660949\n",
      "train loss:0.00017627591509\n",
      "train loss:0.000363651933504\n",
      "train loss:0.00479464401357\n",
      "train loss:0.00124302507577\n",
      "train loss:0.0025101506901\n",
      "train loss:0.00136001252069\n",
      "train loss:0.000927212122356\n",
      "train loss:0.00214995994509\n",
      "train loss:5.8222158985e-05\n",
      "train loss:0.00419480342778\n",
      "train loss:5.13623458813e-05\n",
      "train loss:0.00116420254151\n",
      "train loss:0.000859888269997\n",
      "train loss:5.74366600226e-05\n",
      "train loss:0.000148481450083\n",
      "train loss:0.000921036895729\n",
      "train loss:0.00641096377746\n",
      "train loss:0.0117616360262\n",
      "train loss:0.00215817488726\n",
      "train loss:0.00111861483252\n",
      "train loss:0.000907017323923\n",
      "train loss:0.0345154906919\n",
      "train loss:0.0036287508942\n",
      "train loss:0.000639410519842\n",
      "train loss:0.00226562577362\n",
      "train loss:0.000594370659259\n",
      "train loss:0.000631120612578\n",
      "train loss:0.00542540242181\n",
      "train loss:0.00185285131307\n",
      "train loss:0.000211418709843\n",
      "train loss:0.00584984348921\n",
      "train loss:0.00483078610807\n",
      "train loss:0.00390655856304\n",
      "train loss:0.000903340105576\n",
      "train loss:0.000187831929603\n",
      "train loss:0.000108310851737\n",
      "train loss:0.00266644041971\n",
      "train loss:9.27715354064e-05\n",
      "train loss:0.00184873584608\n",
      "train loss:0.000603748462538\n",
      "train loss:0.00230505367584\n",
      "train loss:0.000242102224415\n",
      "train loss:0.000254792316733\n",
      "train loss:0.000187505097519\n",
      "train loss:0.00116618520804\n",
      "train loss:0.00251645834628\n",
      "train loss:0.000685590679513\n",
      "train loss:0.000792535190712\n",
      "train loss:0.0232416474232\n",
      "train loss:0.000257651205105\n",
      "train loss:0.00337559326751\n",
      "train loss:0.00317888544519\n",
      "train loss:0.00032977979516\n",
      "train loss:0.000330853739327\n",
      "train loss:0.00193240367678\n",
      "train loss:0.000286171231216\n",
      "train loss:0.00123735312531\n",
      "train loss:0.00173845120153\n",
      "train loss:0.00277697582658\n",
      "train loss:0.00138983688201\n",
      "train loss:0.000113734039693\n",
      "train loss:0.00370273164249\n",
      "train loss:0.0157690208994\n",
      "train loss:0.00327729855183\n",
      "train loss:0.0189529086856\n",
      "train loss:0.0251611744413\n",
      "train loss:0.000131063159511\n",
      "train loss:1.06441124314e-05\n",
      "train loss:0.00181992497785\n",
      "train loss:0.00437037959358\n",
      "train loss:0.00113132684102\n",
      "train loss:0.00273472626853\n",
      "train loss:0.00040035248628\n",
      "train loss:0.00577825294421\n",
      "train loss:0.00438539941568\n",
      "train loss:0.000672781906054\n",
      "train loss:6.82595603375e-05\n",
      "train loss:0.00233256799552\n",
      "train loss:0.000418176741436\n",
      "train loss:0.000243447020111\n",
      "train loss:0.00117170991849\n",
      "train loss:0.00264655487042\n",
      "train loss:0.0055704949979\n",
      "train loss:0.000519707823809\n",
      "train loss:0.003180162752\n",
      "train loss:0.00411700556338\n",
      "train loss:0.000115334760369\n",
      "train loss:0.00408380477617\n",
      "train loss:0.000808667743544\n",
      "train loss:0.00511669339483\n",
      "train loss:0.0012696885452\n",
      "train loss:0.00028082174254\n",
      "train loss:9.12972340712e-05\n",
      "train loss:0.00510636612535\n",
      "train loss:0.0020387112515\n",
      "train loss:0.000780015073243\n",
      "train loss:0.000762893200318\n",
      "train loss:0.0252836021035\n",
      "train loss:0.000405645275468\n",
      "train loss:0.00439427216192\n",
      "train loss:0.000621351278171\n",
      "train loss:0.00284556902577\n",
      "train loss:0.00117398157036\n",
      "train loss:0.000628675935924\n",
      "train loss:0.000428302254757\n",
      "train loss:0.000427927454378\n",
      "train loss:0.00164957921606\n",
      "train loss:0.00116929775966\n",
      "train loss:0.00265929144263\n",
      "train loss:0.00313708111201\n",
      "train loss:0.000996113847015\n",
      "train loss:0.000709374481933\n",
      "train loss:8.93524381965e-05\n",
      "train loss:8.72242481412e-05\n",
      "train loss:0.00294966243077\n",
      "train loss:0.00270814543369\n",
      "train loss:0.000189409046653\n",
      "train loss:0.00573425347046\n",
      "train loss:0.000415998976683\n",
      "train loss:0.00172150960086\n",
      "train loss:0.00072810593165\n",
      "train loss:0.000828634745522\n",
      "train loss:0.0130967113025\n",
      "train loss:0.000299423433078\n",
      "train loss:0.000161510387214\n",
      "train loss:0.00253685405247\n",
      "train loss:5.49508604438e-05\n",
      "train loss:0.000194128185177\n",
      "train loss:0.00110393293809\n",
      "train loss:0.00369487460969\n",
      "train loss:0.000216138858832\n",
      "train loss:0.000497056035224\n",
      "train loss:0.000478278446344\n",
      "train loss:0.000780629812475\n",
      "train loss:0.00115566604093\n",
      "train loss:0.00190362317285\n",
      "train loss:0.000202408946625\n",
      "train loss:0.00037919080615\n",
      "train loss:0.00256487882093\n",
      "train loss:0.0015059237914\n",
      "train loss:0.00105343937482\n",
      "train loss:0.000630785561702\n",
      "train loss:0.00302748461028\n",
      "train loss:0.000135153592604\n",
      "train loss:0.000115172036502\n",
      "train loss:0.0158752149606\n",
      "train loss:0.000158996351207\n",
      "train loss:0.000115387263558\n",
      "train loss:0.000533649908786\n",
      "train loss:0.00135472310235\n",
      "train loss:0.00231619156499\n",
      "train loss:0.003339497769\n",
      "train loss:0.00103611822023\n",
      "train loss:0.000292767468562\n",
      "train loss:0.000788788172941\n",
      "train loss:0.00258084571222\n",
      "train loss:0.00209925147407\n",
      "train loss:0.000786363017124\n",
      "train loss:0.000582625557036\n",
      "train loss:0.00060426817292\n",
      "train loss:0.000848239200935\n",
      "train loss:0.00126949613952\n",
      "train loss:0.00214836591198\n",
      "train loss:0.00294913068286\n",
      "train loss:0.0012602112749\n",
      "train loss:0.00370778497581\n",
      "train loss:0.00137846081002\n",
      "train loss:0.00144486396301\n",
      "train loss:0.00161797152284\n",
      "train loss:0.0180233453862\n",
      "train loss:0.000939806699898\n",
      "train loss:0.000102930189735\n",
      "train loss:0.000205292541812\n",
      "train loss:0.000918084827344\n",
      "train loss:0.00312803776937\n",
      "train loss:0.00333073946649\n",
      "train loss:0.000879112571466\n",
      "train loss:0.0762183994982\n",
      "train loss:0.000187362724837\n",
      "train loss:0.00319252184059\n",
      "train loss:0.000606739828425\n",
      "train loss:0.000110041711746\n",
      "train loss:0.000201248642632\n",
      "train loss:0.000167271401291\n",
      "train loss:0.00287444927381\n",
      "train loss:0.000743378564534\n",
      "train loss:0.00269139807403\n",
      "train loss:0.00779856706042\n",
      "train loss:0.000537974934203\n",
      "train loss:0.00315318965633\n",
      "train loss:0.000468692526865\n",
      "train loss:0.00134824778186\n",
      "train loss:4.08687760221e-05\n",
      "train loss:0.000922850556648\n",
      "train loss:0.000669226976184\n",
      "train loss:0.000184852718499\n",
      "train loss:0.0010743435195\n",
      "train loss:0.00232562776073\n",
      "train loss:0.00424213247246\n",
      "train loss:1.40793698376e-05\n",
      "train loss:0.00528896461467\n",
      "train loss:0.0124707588036\n",
      "train loss:0.00341743717139\n",
      "train loss:0.000150215114036\n",
      "train loss:0.00146197279358\n",
      "train loss:0.00527612658654\n",
      "train loss:0.000812906833957\n",
      "train loss:0.00294758381048\n",
      "train loss:0.00554116589346\n",
      "train loss:0.000315807837453\n",
      "train loss:0.00108395122\n",
      "train loss:0.0472028382082\n",
      "train loss:0.00219663104742\n",
      "train loss:0.000745429338778\n",
      "train loss:0.000732279816859\n",
      "train loss:0.000786969492437\n",
      "train loss:0.000545510110324\n",
      "train loss:0.00621399591928\n",
      "train loss:0.000114356472768\n",
      "train loss:0.00410224200664\n",
      "train loss:0.00424983873456\n",
      "train loss:0.00133168492998\n",
      "train loss:0.000464804550941\n",
      "train loss:0.000815913309411\n",
      "train loss:0.00376213448782\n",
      "train loss:0.00163685094936\n",
      "train loss:0.00102745205973\n",
      "train loss:0.00113335474778\n",
      "train loss:0.00107221630335\n",
      "train loss:0.00432105006225\n",
      "train loss:0.00316234868622\n",
      "train loss:0.00295274408438\n",
      "train loss:0.000750721647666\n",
      "train loss:0.00437610674595\n",
      "train loss:0.000490886493314\n",
      "train loss:0.00297401938746\n",
      "train loss:0.00087095807376\n",
      "train loss:0.00148440298592\n",
      "train loss:0.000291797061695\n",
      "train loss:0.0128673549428\n",
      "train loss:0.000290032023584\n",
      "train loss:0.00671253245452\n",
      "train loss:0.000466935788704\n",
      "train loss:0.00137179319277\n",
      "train loss:0.000860775293124\n",
      "train loss:0.000550210885041\n",
      "train loss:0.00114416922387\n",
      "train loss:0.00890266337803\n",
      "train loss:0.000461135868262\n",
      "train loss:0.000703652302501\n",
      "train loss:0.000129990486995\n",
      "train loss:0.000739714490085\n",
      "train loss:0.00160514815208\n",
      "train loss:0.00196429297945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000266102201236\n",
      "train loss:0.000123526482282\n",
      "train loss:0.00182959839975\n",
      "train loss:0.00016273324853\n",
      "train loss:0.000801434359387\n",
      "train loss:0.000188752772086\n",
      "train loss:0.00193034681916\n",
      "train loss:0.000256724239633\n",
      "train loss:0.00550585995626\n",
      "train loss:0.00765399267876\n",
      "train loss:0.000143248945001\n",
      "train loss:0.000577325738479\n",
      "train loss:0.00800158267325\n",
      "train loss:0.00995403906218\n",
      "train loss:0.000493506947333\n",
      "train loss:0.00165539629102\n",
      "train loss:0.000486283368506\n",
      "train loss:0.000869063351345\n",
      "train loss:0.00207706771566\n",
      "train loss:0.00301166629222\n",
      "train loss:0.00271841308302\n",
      "train loss:0.000190670173831\n",
      "train loss:0.000165120633988\n",
      "train loss:0.00251110020919\n",
      "train loss:0.00367400370001\n",
      "train loss:0.000375822122726\n",
      "train loss:0.000178067519854\n",
      "train loss:0.00012048649841\n",
      "train loss:0.000564456830197\n",
      "train loss:0.000659537781557\n",
      "train loss:0.00447329618878\n",
      "train loss:0.00177528912663\n",
      "train loss:0.00245998889833\n",
      "train loss:0.00148169122333\n",
      "train loss:0.00415201441413\n",
      "train loss:0.00805770230901\n",
      "train loss:0.005177107116\n",
      "train loss:0.00544008943018\n",
      "train loss:0.00045197969947\n",
      "train loss:0.00193485836838\n",
      "train loss:0.0175217131745\n",
      "train loss:0.00109979123692\n",
      "train loss:0.000432977957082\n",
      "train loss:0.00222301592238\n",
      "train loss:0.00530200571029\n",
      "train loss:0.00024881981699\n",
      "train loss:0.00290627605817\n",
      "train loss:0.00318656397918\n",
      "train loss:0.00325575375957\n",
      "train loss:0.000503270508071\n",
      "=== epoch:17, train acc:0.994, test acc:0.986 ===\n",
      "train loss:0.00442637420513\n",
      "train loss:0.0501279974897\n",
      "train loss:0.0222346481467\n",
      "train loss:0.0208241471769\n",
      "train loss:0.000200303130021\n",
      "train loss:0.000360239022036\n",
      "train loss:0.00072391872506\n",
      "train loss:0.00251189565403\n",
      "train loss:0.00846099682219\n",
      "train loss:0.0105415192491\n",
      "train loss:0.000469556258752\n",
      "train loss:0.00279261039944\n",
      "train loss:0.0082297247889\n",
      "train loss:0.00150051740466\n",
      "train loss:0.00124346914771\n",
      "train loss:0.00104728370823\n",
      "train loss:0.00718666957961\n",
      "train loss:0.0180300573929\n",
      "train loss:0.000558670401474\n",
      "train loss:0.0087534609848\n",
      "train loss:0.000498136732275\n",
      "train loss:0.0030325537174\n",
      "train loss:0.00158125487827\n",
      "train loss:0.00470379578123\n",
      "train loss:0.00710958773354\n",
      "train loss:0.00276995230499\n",
      "train loss:0.00167405257369\n",
      "train loss:0.00338922975226\n",
      "train loss:0.000629043003745\n",
      "train loss:6.69670903391e-05\n",
      "train loss:0.00119052300305\n",
      "train loss:0.00022603533443\n",
      "train loss:0.000668340459072\n",
      "train loss:0.0027201908768\n",
      "train loss:0.0132630779552\n",
      "train loss:0.00412030610202\n",
      "train loss:0.00712152929521\n",
      "train loss:0.00640907037805\n",
      "train loss:0.00233703085389\n",
      "train loss:0.00178604411403\n",
      "train loss:0.00265705938727\n",
      "train loss:0.000996775611341\n",
      "train loss:0.00498219275601\n",
      "train loss:0.0074137530289\n",
      "train loss:0.00325482407107\n",
      "train loss:0.00171699192624\n",
      "train loss:0.00391665435193\n",
      "train loss:0.00169558990039\n",
      "train loss:0.00115287452246\n",
      "train loss:0.0107517556512\n",
      "train loss:0.00112642342777\n",
      "train loss:0.00475939955065\n",
      "train loss:0.00722122589177\n",
      "train loss:0.000730425404447\n",
      "train loss:0.00171176196731\n",
      "train loss:0.0321268641199\n",
      "train loss:0.0492529076704\n",
      "train loss:8.81317375842e-05\n",
      "train loss:0.00272158803811\n",
      "train loss:0.0069565910125\n",
      "train loss:0.000914598667543\n",
      "train loss:0.00163622114783\n",
      "train loss:0.000347964350585\n",
      "train loss:6.61678774765e-05\n",
      "train loss:0.000553303058009\n",
      "train loss:0.000776511922227\n",
      "train loss:0.00015257440611\n",
      "train loss:0.000648897412488\n",
      "train loss:0.00270911691273\n",
      "train loss:0.00067900875251\n",
      "train loss:0.00154612848005\n",
      "train loss:0.00120302687222\n",
      "train loss:0.000648396344509\n",
      "train loss:0.00237094664304\n",
      "train loss:0.000166887882076\n",
      "train loss:0.000212634250771\n",
      "train loss:2.92636076486e-05\n",
      "train loss:0.00224810426474\n",
      "train loss:0.000643457554614\n",
      "train loss:0.00126918767533\n",
      "train loss:0.00395073635995\n",
      "train loss:0.000492220478176\n",
      "train loss:0.0285903266791\n",
      "train loss:0.00209732159541\n",
      "train loss:0.000620669454323\n",
      "train loss:0.00064925656706\n",
      "train loss:0.00184272360477\n",
      "train loss:0.00561019999811\n",
      "train loss:0.00232442892483\n",
      "train loss:0.00157938850554\n",
      "train loss:0.00468159466545\n",
      "train loss:0.000157375043905\n",
      "train loss:0.00440877064762\n",
      "train loss:0.00133652038645\n",
      "train loss:0.000756397515378\n",
      "train loss:0.00875059532278\n",
      "train loss:0.000476182830958\n",
      "train loss:0.000114941833234\n",
      "train loss:0.00253598759474\n",
      "train loss:0.00201532343106\n",
      "train loss:0.00129789727907\n",
      "train loss:0.0278683532103\n",
      "train loss:0.00536192893915\n",
      "train loss:0.00104009394585\n",
      "train loss:0.00142235860983\n",
      "train loss:0.000231527693851\n",
      "train loss:0.000717428356253\n",
      "train loss:0.000531486702247\n",
      "train loss:0.00102652837634\n",
      "train loss:0.00215109328468\n",
      "train loss:0.000434840721819\n",
      "train loss:0.000729654567852\n",
      "train loss:0.00176589243762\n",
      "train loss:0.000901470097238\n",
      "train loss:0.000987403215911\n",
      "train loss:0.0275734229973\n",
      "train loss:0.000121243340885\n",
      "train loss:0.000664577565161\n",
      "train loss:0.000213094347352\n",
      "train loss:0.00388860091263\n",
      "train loss:0.00373482821624\n",
      "train loss:0.00242054131964\n",
      "train loss:0.00037884574461\n",
      "train loss:0.0107601285736\n",
      "train loss:0.00142078165485\n",
      "train loss:0.00346799439028\n",
      "train loss:0.003107505743\n",
      "train loss:0.00156472765295\n",
      "train loss:0.00607927801102\n",
      "train loss:0.00216874167584\n",
      "train loss:5.78485817883e-05\n",
      "train loss:0.00546589481698\n",
      "train loss:0.00583585738807\n",
      "train loss:0.0014968716596\n",
      "train loss:0.00183808248206\n",
      "train loss:0.0039408968424\n",
      "train loss:0.000223032842953\n",
      "train loss:0.00591085465783\n",
      "train loss:0.00160987022567\n",
      "train loss:0.00480597415622\n",
      "train loss:0.00228721081777\n",
      "train loss:0.0122013489751\n",
      "train loss:0.000789245391123\n",
      "train loss:0.00157062422597\n",
      "train loss:0.00869461397559\n",
      "train loss:0.00441132531364\n",
      "train loss:0.00151685235449\n",
      "train loss:0.00158666218198\n",
      "train loss:0.00016229732332\n",
      "train loss:8.6328737689e-05\n",
      "train loss:0.00136080733164\n",
      "train loss:0.0120393526484\n",
      "train loss:0.000951252812486\n",
      "train loss:0.00135222938809\n",
      "train loss:0.00139341512663\n",
      "train loss:0.000267917115026\n",
      "train loss:0.000420946041878\n",
      "train loss:0.0128630116273\n",
      "train loss:0.000147926780981\n",
      "train loss:0.00287366078321\n",
      "train loss:0.00349008231636\n",
      "train loss:0.000933225026271\n",
      "train loss:0.0203906915786\n",
      "train loss:0.00239727115544\n",
      "train loss:0.00272623149564\n",
      "train loss:0.00292028039623\n",
      "train loss:0.0059411297681\n",
      "train loss:0.00152816747655\n",
      "train loss:0.000122805508405\n",
      "train loss:0.000263935618637\n",
      "train loss:0.00083221016855\n",
      "train loss:0.00256545141593\n",
      "train loss:0.000531546744335\n",
      "train loss:0.00116929839266\n",
      "train loss:0.00129914229255\n",
      "train loss:0.000935682865619\n",
      "train loss:0.00135709861707\n",
      "train loss:0.00164899069165\n",
      "train loss:0.00140991195122\n",
      "train loss:0.000159460315231\n",
      "train loss:0.00166066653078\n",
      "train loss:0.000370229888904\n",
      "train loss:0.00363154924244\n",
      "train loss:0.000608229475644\n",
      "train loss:0.00697513890895\n",
      "train loss:0.000395361811449\n",
      "train loss:0.00179563364228\n",
      "train loss:0.000401791149268\n",
      "train loss:0.00137207775202\n",
      "train loss:0.000999327675047\n",
      "train loss:0.000903692448845\n",
      "train loss:0.00189307750476\n",
      "train loss:0.00940458977036\n",
      "train loss:0.00361079831513\n",
      "train loss:0.00398894256282\n",
      "train loss:0.00357259286399\n",
      "train loss:0.00653854447581\n",
      "train loss:0.00690221151061\n",
      "train loss:0.000250966072753\n",
      "train loss:0.00210739423716\n",
      "train loss:0.000934906047369\n",
      "train loss:0.000231850962386\n",
      "train loss:0.00187184721873\n",
      "train loss:0.00214300156377\n",
      "train loss:0.00160886431517\n",
      "train loss:0.00694054080632\n",
      "train loss:0.00289626489847\n",
      "train loss:0.000829656318449\n",
      "train loss:0.00381203027811\n",
      "train loss:0.00161021646029\n",
      "train loss:0.00387759063279\n",
      "train loss:0.00344817257056\n",
      "train loss:0.00312492709649\n",
      "train loss:6.71024387359e-05\n",
      "train loss:0.00181257423251\n",
      "train loss:0.000132534861213\n",
      "train loss:0.00408076484185\n",
      "train loss:0.00424075854966\n",
      "train loss:0.00198093702414\n",
      "train loss:0.000817108549963\n",
      "train loss:0.000310633107349\n",
      "train loss:0.00044895773649\n",
      "train loss:0.000288765071257\n",
      "train loss:0.000856366411454\n",
      "train loss:0.000155058872839\n",
      "train loss:0.00182177800579\n",
      "train loss:0.000985800311424\n",
      "train loss:0.00217471940461\n",
      "train loss:0.00082527901304\n",
      "train loss:0.000526871712388\n",
      "train loss:0.000273210687637\n",
      "train loss:0.00134602421774\n",
      "train loss:0.00180061847687\n",
      "train loss:0.00144102939963\n",
      "train loss:0.00227687136542\n",
      "train loss:0.00370066523517\n",
      "train loss:0.00978187689797\n",
      "train loss:0.00250910615916\n",
      "train loss:0.00221115865032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:8.53624531866e-05\n",
      "train loss:0.00751716574642\n",
      "train loss:0.00107740219133\n",
      "train loss:0.000918935123275\n",
      "train loss:4.04581821876e-05\n",
      "train loss:0.00621267581972\n",
      "train loss:0.00156832215791\n",
      "train loss:0.00101303756294\n",
      "train loss:0.00355357160374\n",
      "train loss:0.000674002383635\n",
      "train loss:0.00228296550059\n",
      "train loss:0.00145258282423\n",
      "train loss:0.00145512026434\n",
      "train loss:0.00170604922855\n",
      "train loss:0.00591765505711\n",
      "train loss:0.00189014575537\n",
      "train loss:0.000246669497404\n",
      "train loss:0.00189960785384\n",
      "train loss:0.000114450353162\n",
      "train loss:0.00102092696112\n",
      "train loss:0.00123014982361\n",
      "train loss:0.000125055514416\n",
      "train loss:0.000806981627856\n",
      "train loss:0.000696356971041\n",
      "train loss:0.00181370703608\n",
      "train loss:0.0037075765199\n",
      "train loss:0.00524174978473\n",
      "train loss:0.000366889171031\n",
      "train loss:0.000241174050327\n",
      "train loss:0.00294322499985\n",
      "train loss:0.000439133423523\n",
      "train loss:0.000589564620369\n",
      "train loss:0.00215199018684\n",
      "train loss:0.00646118246389\n",
      "train loss:0.00484740787309\n",
      "train loss:0.0013145378971\n",
      "train loss:0.000118987760102\n",
      "train loss:0.000849621894808\n",
      "train loss:0.000569876151965\n",
      "train loss:0.000225120255878\n",
      "train loss:0.0290906192412\n",
      "train loss:0.000926610321752\n",
      "train loss:4.39622485109e-05\n",
      "train loss:0.00193016052481\n",
      "train loss:0.0013081078634\n",
      "train loss:0.00263982704906\n",
      "train loss:0.0036305737126\n",
      "train loss:0.00183796402651\n",
      "train loss:0.000286963185126\n",
      "train loss:0.000942336951155\n",
      "train loss:0.000265137982625\n",
      "train loss:0.000185516338583\n",
      "train loss:0.000108612197662\n",
      "train loss:0.0174156400002\n",
      "train loss:0.000238012611524\n",
      "train loss:0.00160703633634\n",
      "train loss:0.00351254233293\n",
      "train loss:0.000472573582343\n",
      "train loss:0.00322164803623\n",
      "train loss:0.00202412363588\n",
      "train loss:0.000714747607883\n",
      "train loss:0.00143921017467\n",
      "train loss:0.00319074029895\n",
      "train loss:0.00103464375626\n",
      "train loss:0.000112870881013\n",
      "train loss:0.00228694305274\n",
      "train loss:0.000945141562953\n",
      "train loss:0.00129641480877\n",
      "train loss:2.06369427145e-05\n",
      "train loss:0.000321909659865\n",
      "train loss:0.00229583446891\n",
      "train loss:0.000279360405144\n",
      "train loss:7.2242878725e-05\n",
      "train loss:0.00169963739961\n",
      "train loss:0.000570690812281\n",
      "train loss:0.00285544228714\n",
      "train loss:0.000994901659225\n",
      "train loss:0.000473557655462\n",
      "train loss:0.0011383648689\n",
      "train loss:0.00330308860632\n",
      "train loss:0.000119418181946\n",
      "train loss:0.000693165102067\n",
      "train loss:0.00308667792637\n",
      "train loss:0.000626000205589\n",
      "train loss:0.00204018314935\n",
      "train loss:0.00221485892875\n",
      "train loss:0.000218901128425\n",
      "train loss:0.0010720171995\n",
      "train loss:0.00701428044333\n",
      "train loss:0.00028817912093\n",
      "train loss:4.8064610709e-05\n",
      "train loss:0.000192558505111\n",
      "train loss:0.000749206889103\n",
      "train loss:0.00683533810432\n",
      "train loss:0.00219621231293\n",
      "train loss:0.000142459450339\n",
      "train loss:0.00366541734165\n",
      "train loss:0.00215605504247\n",
      "train loss:0.000317015690165\n",
      "train loss:0.000737299490733\n",
      "train loss:0.000106609109259\n",
      "train loss:0.000611318019238\n",
      "train loss:0.000537820579453\n",
      "train loss:0.000297908525061\n",
      "train loss:0.000945594905506\n",
      "train loss:0.0014157760786\n",
      "train loss:0.00471221643346\n",
      "train loss:0.000711029404417\n",
      "train loss:0.000189718839972\n",
      "train loss:0.00034843115546\n",
      "train loss:0.000556828278897\n",
      "train loss:0.00269614535083\n",
      "train loss:0.00120740740228\n",
      "train loss:0.00388199486725\n",
      "train loss:0.000721550061782\n",
      "train loss:0.00010522840305\n",
      "train loss:0.00191685027843\n",
      "train loss:0.000631290361613\n",
      "train loss:0.013829275175\n",
      "train loss:0.0009376275316\n",
      "train loss:0.000833539889247\n",
      "train loss:0.00280735317834\n",
      "train loss:0.000547377596962\n",
      "train loss:0.000154711471237\n",
      "train loss:0.00112246681943\n",
      "train loss:0.000482838042036\n",
      "train loss:0.00149013931244\n",
      "train loss:0.00048701421591\n",
      "train loss:0.00418123154041\n",
      "train loss:0.0051968909232\n",
      "train loss:5.25170167218e-05\n",
      "train loss:0.000516196086094\n",
      "train loss:0.000637415422992\n",
      "train loss:0.00116339450795\n",
      "train loss:0.00113419690519\n",
      "train loss:0.000346720493576\n",
      "train loss:0.00800186080468\n",
      "train loss:0.0015285984511\n",
      "train loss:0.00402194079428\n",
      "train loss:0.0011293358855\n",
      "train loss:0.0103667629701\n",
      "train loss:5.13315783777e-05\n",
      "train loss:0.000558463217877\n",
      "train loss:0.000910572322883\n",
      "train loss:0.00183506015147\n",
      "train loss:0.00123125784592\n",
      "train loss:0.000434412524006\n",
      "train loss:0.00018557116969\n",
      "train loss:0.00241816668088\n",
      "train loss:0.000558874783446\n",
      "train loss:0.000104832592781\n",
      "train loss:0.000783623861655\n",
      "train loss:0.000635488288662\n",
      "train loss:0.00014883037691\n",
      "train loss:0.000549103890847\n",
      "train loss:0.000281246547315\n",
      "train loss:0.00210258227234\n",
      "train loss:0.00586932440553\n",
      "train loss:0.00418338497333\n",
      "train loss:0.00110209689323\n",
      "train loss:0.00320033347254\n",
      "train loss:0.000414682952645\n",
      "train loss:0.000121593703367\n",
      "train loss:0.000216354945528\n",
      "train loss:0.000477258252798\n",
      "train loss:0.0042170320662\n",
      "train loss:7.76529579142e-05\n",
      "train loss:0.00194693042674\n",
      "train loss:0.00730735973411\n",
      "train loss:0.000608415713567\n",
      "train loss:0.00116675161867\n",
      "train loss:0.00551826145587\n",
      "train loss:0.00204900570883\n",
      "train loss:7.47698279255e-05\n",
      "train loss:0.00167806764751\n",
      "train loss:0.000101390177227\n",
      "train loss:0.00115803827764\n",
      "train loss:0.00114034216263\n",
      "train loss:0.0231646100958\n",
      "train loss:0.000332846886515\n",
      "train loss:0.00131477591033\n",
      "train loss:0.000255807739657\n",
      "train loss:0.00132304331923\n",
      "train loss:0.000224023207967\n",
      "train loss:0.00168796247911\n",
      "train loss:2.43121934754e-05\n",
      "train loss:0.013636013476\n",
      "train loss:0.000443143622444\n",
      "train loss:0.00134383475039\n",
      "train loss:0.00152557171468\n",
      "train loss:0.0013192665559\n",
      "train loss:0.00470734334585\n",
      "train loss:0.000905613546835\n",
      "train loss:0.000318280743549\n",
      "train loss:0.00120160320153\n",
      "train loss:0.000132699534404\n",
      "train loss:0.000184454830621\n",
      "train loss:0.000930274363426\n",
      "train loss:0.00156252834805\n",
      "train loss:0.000557266446503\n",
      "train loss:0.00148449470083\n",
      "train loss:0.000541442845752\n",
      "train loss:1.88157270414e-05\n",
      "train loss:0.00469470929208\n",
      "train loss:0.000513646174067\n",
      "train loss:0.000857225552202\n",
      "train loss:0.000682478111636\n",
      "train loss:0.0010664663927\n",
      "train loss:0.00238140458079\n",
      "train loss:0.00108067134583\n",
      "train loss:0.0131451664984\n",
      "train loss:0.000144754588113\n",
      "train loss:0.00275116657866\n",
      "train loss:0.00102079014249\n",
      "train loss:0.0038559902715\n",
      "train loss:8.02515624991e-05\n",
      "train loss:0.00415475659562\n",
      "train loss:0.00170873276477\n",
      "train loss:9.40427265681e-05\n",
      "train loss:0.000539125810617\n",
      "train loss:0.00520638099846\n",
      "train loss:0.00511380541652\n",
      "train loss:0.000342191154116\n",
      "train loss:0.000145982496354\n",
      "train loss:0.00597224063888\n",
      "train loss:0.000779568291971\n",
      "train loss:0.000967098252569\n",
      "train loss:0.0442590587446\n",
      "train loss:0.000129137627624\n",
      "train loss:0.000640277086145\n",
      "train loss:0.000245344840986\n",
      "train loss:0.000406232571188\n",
      "train loss:0.0156744101346\n",
      "train loss:0.00103804331139\n",
      "train loss:0.0136576100295\n",
      "train loss:0.00085183607752\n",
      "train loss:0.000475191441984\n",
      "train loss:0.00229595550688\n",
      "train loss:0.00152156779698\n",
      "train loss:0.000503440476199\n",
      "train loss:0.000485191528938\n",
      "train loss:0.0379389034213\n",
      "train loss:0.0035039163273\n",
      "train loss:0.0266707334273\n",
      "train loss:0.0129769107874\n",
      "train loss:0.00254269962388\n",
      "train loss:0.00194112321546\n",
      "train loss:0.000916587783236\n",
      "train loss:0.00133339098709\n",
      "train loss:0.000178751915792\n",
      "train loss:0.00189025586489\n",
      "train loss:0.00102959483219\n",
      "train loss:0.00197221217565\n",
      "train loss:0.00437190173258\n",
      "train loss:0.00242403956531\n",
      "train loss:0.00169982025\n",
      "train loss:0.000122128890151\n",
      "train loss:0.00146440095226\n",
      "train loss:0.0047101758899\n",
      "train loss:0.000571337971387\n",
      "train loss:0.00292990306804\n",
      "train loss:0.00173741465445\n",
      "train loss:0.000561981000708\n",
      "train loss:0.00335173108968\n",
      "train loss:0.000656312625461\n",
      "train loss:0.00141861150697\n",
      "train loss:0.000931212241712\n",
      "train loss:0.00244801155884\n",
      "train loss:0.0033276685467\n",
      "train loss:0.00261154161283\n",
      "train loss:0.000879954464593\n",
      "train loss:0.00128968030007\n",
      "train loss:0.000161581780542\n",
      "train loss:0.00398849375224\n",
      "train loss:0.00234677267911\n",
      "train loss:0.00222184125614\n",
      "train loss:0.000841056826362\n",
      "train loss:0.0010766305317\n",
      "train loss:0.00120648762029\n",
      "train loss:0.000715401450477\n",
      "train loss:0.0138245514614\n",
      "train loss:0.000270381935491\n",
      "train loss:0.000137892919852\n",
      "train loss:0.000292462762736\n",
      "train loss:0.00243011837712\n",
      "train loss:0.00082536305994\n",
      "train loss:0.000511418817519\n",
      "train loss:0.00316482226725\n",
      "train loss:0.00036367138485\n",
      "train loss:0.00277739274631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00359706391934\n",
      "train loss:0.00198806852166\n",
      "train loss:0.000228839341383\n",
      "train loss:0.00266895556483\n",
      "train loss:0.000490672701458\n",
      "train loss:0.000216954841317\n",
      "train loss:2.9737761798e-05\n",
      "train loss:0.000360925970793\n",
      "train loss:0.00954331539348\n",
      "train loss:0.00108268291967\n",
      "train loss:0.00396707551052\n",
      "train loss:0.00277426512962\n",
      "train loss:0.00163701051813\n",
      "train loss:0.000421882500948\n",
      "train loss:0.000253912944024\n",
      "train loss:0.00279753512991\n",
      "train loss:0.000267365411258\n",
      "train loss:5.96779537763e-05\n",
      "train loss:0.00958853341767\n",
      "train loss:0.000678747172802\n",
      "train loss:3.88434294697e-05\n",
      "train loss:0.000477094755393\n",
      "train loss:0.000101965051867\n",
      "train loss:0.00279626667473\n",
      "train loss:0.045520385407\n",
      "train loss:0.00557516161915\n",
      "train loss:0.000523791384048\n",
      "train loss:0.00465597609888\n",
      "train loss:0.0014007451593\n",
      "train loss:0.00103082451271\n",
      "train loss:0.00161797390696\n",
      "train loss:0.000227496255776\n",
      "train loss:0.000881935568178\n",
      "train loss:0.00202993829293\n",
      "train loss:0.000659199324851\n",
      "train loss:0.0176678594563\n",
      "train loss:0.0116586826674\n",
      "train loss:0.000464542662307\n",
      "train loss:0.0171912371143\n",
      "train loss:0.000611523127236\n",
      "train loss:0.0136681633361\n",
      "train loss:0.000884068070005\n",
      "train loss:0.0018572551843\n",
      "train loss:0.00049787461939\n",
      "train loss:0.00353250000966\n",
      "train loss:0.00972395447319\n",
      "train loss:0.00195639153899\n",
      "train loss:0.00234223823194\n",
      "train loss:0.00112072432069\n",
      "train loss:0.000500194523197\n",
      "train loss:0.00157707092074\n",
      "train loss:0.00138066598477\n",
      "train loss:0.00284081439035\n",
      "train loss:0.000145598839465\n",
      "train loss:0.0041244844199\n",
      "train loss:0.00167489603309\n",
      "train loss:0.0256000761865\n",
      "train loss:0.000414854224126\n",
      "train loss:7.25378658395e-05\n",
      "train loss:0.00309579178806\n",
      "train loss:0.000256144301678\n",
      "train loss:0.00824854009442\n",
      "train loss:0.00122420693193\n",
      "train loss:0.00670443134935\n",
      "train loss:0.00228520073256\n",
      "train loss:0.002921049366\n",
      "train loss:0.000108664930981\n",
      "train loss:0.000517692098699\n",
      "train loss:0.000388101079048\n",
      "train loss:0.000634011334119\n",
      "train loss:0.000586953124823\n",
      "=== epoch:18, train acc:0.999, test acc:0.985 ===\n",
      "train loss:0.000245579421581\n",
      "train loss:3.94014826173e-05\n",
      "train loss:0.00226966872449\n",
      "train loss:0.00111912194834\n",
      "train loss:0.00306408719073\n",
      "train loss:0.0073270685442\n",
      "train loss:0.0106781422598\n",
      "train loss:0.0200343141807\n",
      "train loss:0.00228059767737\n",
      "train loss:0.00416852094361\n",
      "train loss:0.00652340598683\n",
      "train loss:0.00016059526543\n",
      "train loss:0.00134037806534\n",
      "train loss:0.00143200384796\n",
      "train loss:0.00135307188852\n",
      "train loss:0.00337397218171\n",
      "train loss:0.00170919428178\n",
      "train loss:0.000898284593752\n",
      "train loss:0.00412183611276\n",
      "train loss:0.0233464592766\n",
      "train loss:0.00556871033931\n",
      "train loss:0.000546383690665\n",
      "train loss:0.000192454736613\n",
      "train loss:0.00481233798815\n",
      "train loss:0.000544793601433\n",
      "train loss:0.000153628597304\n",
      "train loss:0.00074460508977\n",
      "train loss:0.000278347895469\n",
      "train loss:0.00161821845882\n",
      "train loss:0.00233764436469\n",
      "train loss:0.000376786416834\n",
      "train loss:0.00134341051216\n",
      "train loss:0.00157517941491\n",
      "train loss:0.00151987944192\n",
      "train loss:0.000973623543685\n",
      "train loss:0.00024485726262\n",
      "train loss:0.0051897283853\n",
      "train loss:0.000600438631669\n",
      "train loss:0.00259668008853\n",
      "train loss:0.00135756495958\n",
      "train loss:0.0627965133349\n",
      "train loss:0.00286959571041\n",
      "train loss:0.000487895189134\n",
      "train loss:0.00863797546367\n",
      "train loss:0.00669498452656\n",
      "train loss:0.00395043361172\n",
      "train loss:0.000381767945625\n",
      "train loss:0.00375983473532\n",
      "train loss:0.00277736723005\n",
      "train loss:0.00756100998584\n",
      "train loss:0.000806365471547\n",
      "train loss:0.00268803739648\n",
      "train loss:0.00114936534981\n",
      "train loss:0.00145049860601\n",
      "train loss:0.00189541939779\n",
      "train loss:0.00103174816442\n",
      "train loss:0.00123826853414\n",
      "train loss:0.00583925224369\n",
      "train loss:0.00582531148384\n",
      "train loss:0.00044996262559\n",
      "train loss:0.000441826809202\n",
      "train loss:0.000872759173794\n",
      "train loss:0.000619165561612\n",
      "train loss:0.000343015396785\n",
      "train loss:0.00029221894154\n",
      "train loss:0.0030952515831\n",
      "train loss:0.0219266433476\n",
      "train loss:0.000479993171495\n",
      "train loss:0.000746769323464\n",
      "train loss:0.000565492420968\n",
      "train loss:0.00116401589625\n",
      "train loss:0.00317322930705\n",
      "train loss:0.000920075711357\n",
      "train loss:0.00748563120107\n",
      "train loss:0.00120662723811\n",
      "train loss:0.00469314439993\n",
      "train loss:0.000973054212702\n",
      "train loss:0.00399289155603\n",
      "train loss:0.00640812770118\n",
      "train loss:0.00123193134068\n",
      "train loss:0.00064010912204\n",
      "train loss:0.000670793485964\n",
      "train loss:0.000510537046971\n",
      "train loss:0.00388649002456\n",
      "train loss:0.00083323570204\n",
      "train loss:0.00768253390528\n",
      "train loss:0.00357070235243\n",
      "train loss:0.0049331592455\n",
      "train loss:0.00117191206268\n",
      "train loss:9.4604651434e-05\n",
      "train loss:0.0025563757131\n",
      "train loss:0.00271266770245\n",
      "train loss:0.00267872943173\n",
      "train loss:0.00297542225011\n",
      "train loss:0.00683836591026\n",
      "train loss:0.00104241518743\n",
      "train loss:0.000769889024861\n",
      "train loss:0.00121948493753\n",
      "train loss:0.000338868732444\n",
      "train loss:0.000182286324043\n",
      "train loss:0.0452650711007\n",
      "train loss:0.00245744223454\n",
      "train loss:0.000513026166269\n",
      "train loss:0.00258020383515\n",
      "train loss:0.00177086119056\n",
      "train loss:0.00103460892137\n",
      "train loss:0.00688153618464\n",
      "train loss:0.00163672767555\n",
      "train loss:0.00328732456827\n",
      "train loss:0.00194109111768\n",
      "train loss:0.00279644461736\n",
      "train loss:0.000203724545876\n",
      "train loss:0.00128188091251\n",
      "train loss:0.000420340890795\n",
      "train loss:0.00427729406671\n",
      "train loss:0.000192624733639\n",
      "train loss:0.00016683370047\n",
      "train loss:0.0173274836539\n",
      "train loss:0.00339318859565\n",
      "train loss:0.000485065584541\n",
      "train loss:0.00457866293626\n",
      "train loss:0.000937449995505\n",
      "train loss:0.00161494096276\n",
      "train loss:0.000423688290742\n",
      "train loss:0.00252355440794\n",
      "train loss:0.00162216499027\n",
      "train loss:0.00127781201981\n",
      "train loss:0.000713365483728\n",
      "train loss:0.000463831575191\n",
      "train loss:0.00241928808421\n",
      "train loss:0.000537582476923\n",
      "train loss:0.000262510459574\n",
      "train loss:0.00110853083395\n",
      "train loss:0.00506649971037\n",
      "train loss:0.00139937964567\n",
      "train loss:0.00146560481837\n",
      "train loss:0.00113196189089\n",
      "train loss:0.00191272130982\n",
      "train loss:0.00176361134099\n",
      "train loss:0.000675537180381\n",
      "train loss:0.000831981194294\n",
      "train loss:0.00158408336129\n",
      "train loss:0.000192701620849\n",
      "train loss:0.00534244212148\n",
      "train loss:0.00181677483433\n",
      "train loss:0.000317898009491\n",
      "train loss:0.00103923750057\n",
      "train loss:0.000532894167849\n",
      "train loss:0.000819022387362\n",
      "train loss:0.00128713700121\n",
      "train loss:0.000527650883889\n",
      "train loss:0.000355981181348\n",
      "train loss:5.42513001562e-05\n",
      "train loss:0.00136328753202\n",
      "train loss:0.00591671734395\n",
      "train loss:0.000633248504433\n",
      "train loss:0.00117876713511\n",
      "train loss:0.000497365810581\n",
      "train loss:0.00121186879518\n",
      "train loss:0.00019455714769\n",
      "train loss:3.06362006148e-05\n",
      "train loss:0.000254034138778\n",
      "train loss:0.000436594852287\n",
      "train loss:0.00884855746671\n",
      "train loss:0.00166907755433\n",
      "train loss:0.000173277187918\n",
      "train loss:0.000512693305819\n",
      "train loss:0.00175892909288\n",
      "train loss:0.0011653884549\n",
      "train loss:0.00186304295551\n",
      "train loss:0.000623932340154\n",
      "train loss:0.00045924962512\n",
      "train loss:0.000125745309455\n",
      "train loss:0.000243782874028\n",
      "train loss:6.34755246775e-05\n",
      "train loss:0.000280236879433\n",
      "train loss:0.00222472288087\n",
      "train loss:0.000491615630246\n",
      "train loss:0.000978532142131\n",
      "train loss:0.00111500626819\n",
      "train loss:0.00435937417364\n",
      "train loss:0.000263534000453\n",
      "train loss:0.00445263528608\n",
      "train loss:0.000634769005161\n",
      "train loss:3.51461978147e-05\n",
      "train loss:0.00134098995713\n",
      "train loss:0.00151443906516\n",
      "train loss:0.000855015192507\n",
      "train loss:0.000940292437079\n",
      "train loss:0.000778206720017\n",
      "train loss:3.07943715613e-05\n",
      "train loss:0.000225854198189\n",
      "train loss:0.000160412926312\n",
      "train loss:0.000157080324362\n",
      "train loss:0.000669475837107\n",
      "train loss:0.000728389176199\n",
      "train loss:0.000157159014707\n",
      "train loss:0.000529188271403\n",
      "train loss:0.000860806722587\n",
      "train loss:0.000188098366282\n",
      "train loss:0.000175550809348\n",
      "train loss:0.00779317378772\n",
      "train loss:0.000104481435023\n",
      "train loss:0.00023438581731\n",
      "train loss:0.00159977030449\n",
      "train loss:0.0020382075644\n",
      "train loss:0.00111852232341\n",
      "train loss:0.00120426639547\n",
      "train loss:0.014941703367\n",
      "train loss:0.00169940044192\n",
      "train loss:0.00292397491247\n",
      "train loss:0.000621100735926\n",
      "train loss:0.000169503423555\n",
      "train loss:0.00144330843331\n",
      "train loss:0.000432333073851\n",
      "train loss:0.00078291346857\n",
      "train loss:0.000131826755228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000304777681671\n",
      "train loss:6.67425249385e-05\n",
      "train loss:4.62029612402e-05\n",
      "train loss:0.00310045172078\n",
      "train loss:0.00160843408881\n",
      "train loss:0.00122140416683\n",
      "train loss:0.00993715279259\n",
      "train loss:0.000304128089322\n",
      "train loss:0.000915409293307\n",
      "train loss:0.000706711194506\n",
      "train loss:0.00073768279769\n",
      "train loss:0.0342484066119\n",
      "train loss:0.00147747368715\n",
      "train loss:0.0104509711535\n",
      "train loss:0.000510351606978\n",
      "train loss:0.00201137764614\n",
      "train loss:0.00198024888645\n",
      "train loss:0.000681852400761\n",
      "train loss:2.47501999568e-05\n",
      "train loss:0.0012493888464\n",
      "train loss:0.00539811792223\n",
      "train loss:0.000194057375184\n",
      "train loss:3.58727415418e-05\n",
      "train loss:0.000897408301505\n",
      "train loss:0.000740482904989\n",
      "train loss:0.000449024892049\n",
      "train loss:0.00143246640122\n",
      "train loss:0.000935183769647\n",
      "train loss:0.00199790026429\n",
      "train loss:0.0022060796798\n",
      "train loss:0.00210027609292\n",
      "train loss:0.0025483295688\n",
      "train loss:0.000274257425198\n",
      "train loss:0.0122973725048\n",
      "train loss:0.00137264174777\n",
      "train loss:0.00176987974943\n",
      "train loss:0.0021281307854\n",
      "train loss:0.0148438295468\n",
      "train loss:0.00486793095226\n",
      "train loss:0.00050607997612\n",
      "train loss:0.0014111194874\n",
      "train loss:0.00299979486705\n",
      "train loss:0.000238083328992\n",
      "train loss:0.00108356478104\n",
      "train loss:0.00773812254202\n",
      "train loss:0.00505453261882\n",
      "train loss:0.000552664642423\n",
      "train loss:0.000601642034649\n",
      "train loss:0.000785410343763\n",
      "train loss:0.00442189210926\n",
      "train loss:0.00144541972187\n",
      "train loss:0.000367731844061\n",
      "train loss:0.00011532034334\n",
      "train loss:0.00317023846813\n",
      "train loss:0.00176385430327\n",
      "train loss:0.000768004318183\n",
      "train loss:0.00859899728292\n",
      "train loss:0.00238645646892\n",
      "train loss:0.00312955044459\n",
      "train loss:0.000774665636899\n",
      "train loss:0.000410340783596\n",
      "train loss:0.00147159004809\n",
      "train loss:0.000149585144312\n",
      "train loss:0.000585325635923\n",
      "train loss:0.00399248051658\n",
      "train loss:0.00212429538712\n",
      "train loss:0.00793670041765\n",
      "train loss:0.00424259706722\n",
      "train loss:0.00116962126924\n",
      "train loss:0.00256925439523\n",
      "train loss:0.00113290263724\n",
      "train loss:0.000787544356508\n",
      "train loss:0.000818238543642\n",
      "train loss:0.00304435216189\n",
      "train loss:0.000521962615602\n",
      "train loss:0.000401824192491\n",
      "train loss:0.000675834959536\n",
      "train loss:0.000180559998031\n",
      "train loss:0.000608991820915\n",
      "train loss:0.000439793790756\n",
      "train loss:0.000634051820604\n",
      "train loss:0.000250550530233\n",
      "train loss:0.000378001315208\n",
      "train loss:0.00117251643005\n",
      "train loss:0.000712105569723\n",
      "train loss:0.00326747183129\n",
      "train loss:0.000262595453725\n",
      "train loss:0.000378265035469\n",
      "train loss:8.96567243169e-05\n",
      "train loss:0.000630435780822\n",
      "train loss:0.000119050326091\n",
      "train loss:0.000640570832579\n",
      "train loss:0.00273081566978\n",
      "train loss:0.0025172510465\n",
      "train loss:0.00238034500875\n",
      "train loss:0.00581107308947\n",
      "train loss:0.000974320471698\n",
      "train loss:0.0020381428161\n",
      "train loss:7.92618212845e-05\n",
      "train loss:0.000601260139701\n",
      "train loss:0.000157318071762\n",
      "train loss:0.00822782929732\n",
      "train loss:0.00411368052176\n",
      "train loss:0.000384842713638\n",
      "train loss:3.33222838797e-05\n",
      "train loss:0.0106161291783\n",
      "train loss:0.00325736366921\n",
      "train loss:9.70288708236e-05\n",
      "train loss:0.00128390863388\n",
      "train loss:0.00275271140553\n",
      "train loss:0.00273430118622\n",
      "train loss:0.00207917214043\n",
      "train loss:0.00749201322872\n",
      "train loss:0.00998314826161\n",
      "train loss:0.000356588391118\n",
      "train loss:0.0121505379228\n",
      "train loss:0.00127212296507\n",
      "train loss:0.00440778943467\n",
      "train loss:0.00295713383265\n",
      "train loss:0.00010534103344\n",
      "train loss:0.00324464953066\n",
      "train loss:0.000666885883835\n",
      "train loss:0.00315151781306\n",
      "train loss:0.00112468895738\n",
      "train loss:0.000704907930904\n",
      "train loss:0.00138509537279\n",
      "train loss:0.00043045549176\n",
      "train loss:0.00925058908994\n",
      "train loss:0.00258736510627\n",
      "train loss:0.00214860162022\n",
      "train loss:0.0151905951617\n",
      "train loss:0.000808033887757\n",
      "train loss:4.46210542884e-05\n",
      "train loss:0.00167685442637\n",
      "train loss:0.000776970744745\n",
      "train loss:0.000599618670563\n",
      "train loss:0.000321279590881\n",
      "train loss:0.000914775672649\n",
      "train loss:0.00647966111248\n",
      "train loss:0.00321547981003\n",
      "train loss:0.0009211690148\n",
      "train loss:0.000892488983672\n",
      "train loss:0.00185298241698\n",
      "train loss:0.00119111082331\n",
      "train loss:0.00799566834294\n",
      "train loss:0.00617591804224\n",
      "train loss:0.00032604178335\n",
      "train loss:0.00288845567735\n",
      "train loss:0.00263733678973\n",
      "train loss:0.000647166341399\n",
      "train loss:0.000660589047744\n",
      "train loss:0.00107972258887\n",
      "train loss:0.00234822344025\n",
      "train loss:0.000189893706758\n",
      "train loss:0.00432167407187\n",
      "train loss:0.000973621636839\n",
      "train loss:0.00525970921571\n",
      "train loss:0.00210816321366\n",
      "train loss:0.00940792964017\n",
      "train loss:0.0103314707983\n",
      "train loss:0.00263443837262\n",
      "train loss:0.00305231442609\n",
      "train loss:0.00194916306796\n",
      "train loss:0.00245228460767\n",
      "train loss:0.00187394828607\n",
      "train loss:0.00520583435712\n",
      "train loss:0.00100841024759\n",
      "train loss:0.000383498300377\n",
      "train loss:0.00096378315617\n",
      "train loss:0.00160865136158\n",
      "train loss:0.00198302529887\n",
      "train loss:0.00868022209495\n",
      "train loss:0.0131315378651\n",
      "train loss:0.000352165126004\n",
      "train loss:0.00582879878678\n",
      "train loss:0.00819101659991\n",
      "train loss:0.000293447232208\n",
      "train loss:0.000217822765576\n",
      "train loss:0.000761202574136\n",
      "train loss:0.00291071567955\n",
      "train loss:0.000476939514174\n",
      "train loss:0.0117870471238\n",
      "train loss:0.00155216028764\n",
      "train loss:0.00476381057449\n",
      "train loss:0.000385202418348\n",
      "train loss:0.00419033268331\n",
      "train loss:0.00107110622383\n",
      "train loss:0.00377171718317\n",
      "train loss:0.00226075038271\n",
      "train loss:0.00396386677446\n",
      "train loss:0.00117311628374\n",
      "train loss:0.0252742725987\n",
      "train loss:0.00029559560182\n",
      "train loss:9.98708716587e-05\n",
      "train loss:0.00302520073014\n",
      "train loss:0.00288371589373\n",
      "train loss:0.00326578991053\n",
      "train loss:0.0126504025466\n",
      "train loss:0.00179120700084\n",
      "train loss:0.00954686857401\n",
      "train loss:0.00247798589647\n",
      "train loss:0.00222038292257\n",
      "train loss:0.00508673059715\n",
      "train loss:0.00527723218107\n",
      "train loss:0.000382633071643\n",
      "train loss:0.00754420699991\n",
      "train loss:0.00703513709681\n",
      "train loss:0.00352441339668\n",
      "train loss:0.00187895546835\n",
      "train loss:0.00399130270498\n",
      "train loss:0.00208368711414\n",
      "train loss:0.00180624582389\n",
      "train loss:0.000626832433823\n",
      "train loss:0.0152443567705\n",
      "train loss:0.00656691934255\n",
      "train loss:0.00108608158623\n",
      "train loss:0.000516186144506\n",
      "train loss:0.00163237915569\n",
      "train loss:0.00265033585012\n",
      "train loss:0.00259557425041\n",
      "train loss:0.000808714243901\n",
      "train loss:0.00183499058109\n",
      "train loss:0.00229167891039\n",
      "train loss:0.00690703285793\n",
      "train loss:0.000187893247729\n",
      "train loss:0.0026570967972\n",
      "train loss:0.00320594838541\n",
      "train loss:5.31360979582e-05\n",
      "train loss:0.0019539453415\n",
      "train loss:0.00353708568448\n",
      "train loss:0.0292573756398\n",
      "train loss:0.000921980612335\n",
      "train loss:0.000259904716254\n",
      "train loss:0.00174908008302\n",
      "train loss:0.000324854355167\n",
      "train loss:0.00153894197824\n",
      "train loss:0.0103058074545\n",
      "train loss:0.0043397886646\n",
      "train loss:0.00289686974745\n",
      "train loss:0.000361119690761\n",
      "train loss:0.00517799019854\n",
      "train loss:0.00267639974142\n",
      "train loss:0.000749252443109\n",
      "train loss:0.00931895133973\n",
      "train loss:0.00582766373824\n",
      "train loss:0.000590395881426\n",
      "train loss:0.00103893045512\n",
      "train loss:8.52096514051e-06\n",
      "train loss:0.00369766224894\n",
      "train loss:0.00540209078645\n",
      "train loss:0.0026230354434\n",
      "train loss:0.00202101437541\n",
      "train loss:0.00115053901999\n",
      "train loss:0.00704116551409\n",
      "train loss:0.000670860592093\n",
      "train loss:0.0326174027166\n",
      "train loss:0.00260278956871\n",
      "train loss:0.000212890606325\n",
      "train loss:0.00397188281951\n",
      "train loss:0.00575586987126\n",
      "train loss:0.000442590816975\n",
      "train loss:0.0065132020291\n",
      "train loss:0.00359137191747\n",
      "train loss:0.000145665857322\n",
      "train loss:0.00125734675355\n",
      "train loss:0.000669025631535\n",
      "train loss:0.00527567119677\n",
      "train loss:0.000505288501765\n",
      "train loss:0.000279914393595\n",
      "train loss:0.000791411621405\n",
      "train loss:0.00183766343921\n",
      "train loss:0.00355524667359\n",
      "train loss:0.00320307352025\n",
      "train loss:0.00113103570434\n",
      "train loss:0.000141546089786\n",
      "train loss:0.00187635973581\n",
      "train loss:0.00119745782254\n",
      "train loss:0.000376261909432\n",
      "train loss:0.0172732853195\n",
      "train loss:0.000887057952898\n",
      "train loss:0.000349560939708\n",
      "train loss:0.00293501011245\n",
      "train loss:0.00608800793539\n",
      "train loss:0.00227174946422\n",
      "train loss:0.00377038014964\n",
      "train loss:0.00188469576863\n",
      "train loss:0.000273743986003\n",
      "train loss:0.00442129685795\n",
      "train loss:0.000130361331935\n",
      "train loss:0.000702496012397\n",
      "train loss:0.000208492343013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00291506172252\n",
      "train loss:0.000602774641429\n",
      "train loss:0.000615274096419\n",
      "train loss:0.000561519879525\n",
      "train loss:0.006880743229\n",
      "train loss:0.00143492348935\n",
      "train loss:0.0299460835697\n",
      "train loss:0.00059965825022\n",
      "train loss:0.000177661091879\n",
      "train loss:0.000383252741994\n",
      "train loss:0.00183723628959\n",
      "train loss:0.00104115863328\n",
      "train loss:0.00223411971581\n",
      "train loss:0.00134548320136\n",
      "train loss:0.00323853114398\n",
      "train loss:0.000223749261876\n",
      "train loss:0.00171016812089\n",
      "train loss:0.00182572598808\n",
      "train loss:0.00172139378954\n",
      "train loss:0.0222130162404\n",
      "train loss:0.000766813341969\n",
      "train loss:0.00043920635089\n",
      "train loss:0.00274095366609\n",
      "train loss:0.00256203287951\n",
      "train loss:0.00261844701471\n",
      "train loss:0.0129613628359\n",
      "train loss:0.0032174916776\n",
      "train loss:0.00390571076214\n",
      "train loss:0.0011406894116\n",
      "train loss:0.000391444206222\n",
      "train loss:0.00434307201787\n",
      "train loss:0.00563369390536\n",
      "train loss:0.0017720096285\n",
      "train loss:0.00276870573038\n",
      "train loss:0.00188963729715\n",
      "train loss:0.000177853332781\n",
      "train loss:0.000710257669495\n",
      "train loss:0.00106331325552\n",
      "train loss:0.00601689361389\n",
      "train loss:0.00036719008427\n",
      "train loss:0.0064689918409\n",
      "train loss:0.00455678864421\n",
      "train loss:0.0114449366883\n",
      "train loss:0.000636133457313\n",
      "train loss:0.000321999675148\n",
      "train loss:0.00273071513088\n",
      "train loss:0.00297284221166\n",
      "train loss:0.0131910833214\n",
      "train loss:0.000186905625706\n",
      "train loss:0.00041704738178\n",
      "train loss:0.00110952344091\n",
      "train loss:0.00265856467213\n",
      "train loss:0.000271261235599\n",
      "train loss:0.00316448598781\n",
      "train loss:0.000963706285098\n",
      "train loss:0.000462172868979\n",
      "train loss:0.00166272000415\n",
      "train loss:0.000729070015177\n",
      "train loss:0.00380546304431\n",
      "train loss:0.00300762342076\n",
      "train loss:0.00225229775266\n",
      "train loss:0.00390335779826\n",
      "train loss:0.00020755497429\n",
      "train loss:0.0287451087052\n",
      "train loss:0.001832999899\n",
      "train loss:0.000124405353104\n",
      "train loss:0.000376796770682\n",
      "train loss:0.00486157109884\n",
      "train loss:0.00435077477209\n",
      "train loss:0.00509738277494\n",
      "train loss:0.00110009571013\n",
      "train loss:0.000155314944869\n",
      "train loss:0.000753986832153\n",
      "train loss:0.000134421384202\n",
      "train loss:0.000374608935793\n",
      "train loss:0.000444869120557\n",
      "train loss:0.000301787623125\n",
      "train loss:0.0449033086701\n",
      "train loss:0.000895064462021\n",
      "train loss:0.000409291634789\n",
      "train loss:0.000800558896242\n",
      "train loss:0.00151622497573\n",
      "train loss:0.000230572120859\n",
      "train loss:5.09456155709e-05\n",
      "train loss:0.00799451704646\n",
      "train loss:0.000299682772136\n",
      "train loss:7.48213793032e-05\n",
      "train loss:0.0040033991124\n",
      "train loss:0.00107129580901\n",
      "train loss:7.89232864825e-05\n",
      "train loss:0.0023838021811\n",
      "train loss:0.0060741195444\n",
      "=== epoch:19, train acc:0.994, test acc:0.987 ===\n",
      "train loss:0.00332945508263\n",
      "train loss:0.000447238759537\n",
      "train loss:0.00663214290479\n",
      "train loss:0.0017104447637\n",
      "train loss:0.0059920214155\n",
      "train loss:0.00199514632053\n",
      "train loss:0.00127643794557\n",
      "train loss:0.00306564873512\n",
      "train loss:0.000642264093784\n",
      "train loss:0.00138233743334\n",
      "train loss:0.00747578613535\n",
      "train loss:0.000458268523053\n",
      "train loss:0.00332441880107\n",
      "train loss:0.00206874713749\n",
      "train loss:0.000697290674221\n",
      "train loss:0.000889819848954\n",
      "train loss:0.00237005474528\n",
      "train loss:0.00432721922196\n",
      "train loss:0.00238537793036\n",
      "train loss:0.003809466408\n",
      "train loss:0.000522494969865\n",
      "train loss:9.1626397277e-05\n",
      "train loss:0.00273373581204\n",
      "train loss:0.000216814150679\n",
      "train loss:0.00160306676588\n",
      "train loss:0.000471739337863\n",
      "train loss:0.00159132838007\n",
      "train loss:0.00150409283893\n",
      "train loss:0.00443013952619\n",
      "train loss:0.000109712493781\n",
      "train loss:0.000794406041044\n",
      "train loss:0.000231868172277\n",
      "train loss:0.00812097546426\n",
      "train loss:9.99372637434e-05\n",
      "train loss:0.000261044013597\n",
      "train loss:0.00504258975645\n",
      "train loss:0.000449867994242\n",
      "train loss:0.000791628820317\n",
      "train loss:0.00058046524122\n",
      "train loss:5.25330303395e-05\n",
      "train loss:0.000105555583257\n",
      "train loss:0.00248250410038\n",
      "train loss:0.00255006182255\n",
      "train loss:0.00373842597879\n",
      "train loss:0.00196610570379\n",
      "train loss:0.000362076378056\n",
      "train loss:0.00124640860079\n",
      "train loss:0.000246709327219\n",
      "train loss:0.00103970299566\n",
      "train loss:0.000885932623045\n",
      "train loss:0.00107013780575\n",
      "train loss:0.00226547166341\n",
      "train loss:0.00431306655577\n",
      "train loss:0.000983159099593\n",
      "train loss:0.000677497054438\n",
      "train loss:0.00112851233975\n",
      "train loss:0.000242460249258\n",
      "train loss:0.000222608992885\n",
      "train loss:0.000814888020296\n",
      "train loss:0.00513834017502\n",
      "train loss:0.000558843818897\n",
      "train loss:0.00425397843852\n",
      "train loss:0.00177588203292\n",
      "train loss:0.000308167826178\n",
      "train loss:0.00166831901396\n",
      "train loss:0.000137143508754\n",
      "train loss:0.00139183010318\n",
      "train loss:0.000329638070739\n",
      "train loss:0.00270482672582\n",
      "train loss:0.00372380344597\n",
      "train loss:0.000293405230505\n",
      "train loss:0.00140817990821\n",
      "train loss:0.00425877930645\n",
      "train loss:0.00384892000239\n",
      "train loss:0.00166588790063\n",
      "train loss:0.000201351877595\n",
      "train loss:0.00298848314171\n",
      "train loss:0.00147251502553\n",
      "train loss:0.000628772606895\n",
      "train loss:0.0261799330096\n",
      "train loss:0.000567160337016\n",
      "train loss:0.000178196673674\n",
      "train loss:0.0032389832182\n",
      "train loss:0.00540596612458\n",
      "train loss:0.000348135116303\n",
      "train loss:0.000362754227875\n",
      "train loss:0.00103571921773\n",
      "train loss:0.000634183250857\n",
      "train loss:0.000453012075468\n",
      "train loss:0.00182440841519\n",
      "train loss:0.00128435038743\n",
      "train loss:0.00223387116123\n",
      "train loss:0.000248239837741\n",
      "train loss:0.00077587758506\n",
      "train loss:0.00119611425523\n",
      "train loss:0.000459985733083\n",
      "train loss:0.00118250808359\n",
      "train loss:0.000232805904396\n",
      "train loss:0.00122234181551\n",
      "train loss:2.74076356782e-05\n",
      "train loss:0.00058651051283\n",
      "train loss:0.00137275982918\n",
      "train loss:0.00514545174897\n",
      "train loss:0.000465316189988\n",
      "train loss:0.000367220369135\n",
      "train loss:0.00936449070619\n",
      "train loss:4.89925463308e-05\n",
      "train loss:0.00233614122535\n",
      "train loss:0.000433523333823\n",
      "train loss:0.0028717990983\n",
      "train loss:0.000184636578513\n",
      "train loss:0.000268109502883\n",
      "train loss:0.00118858705513\n",
      "train loss:0.000333753943339\n",
      "train loss:0.000322901630758\n",
      "train loss:0.000636488604916\n",
      "train loss:0.00218279386378\n",
      "train loss:0.000440475980792\n",
      "train loss:0.000302336921347\n",
      "train loss:0.00227412271103\n",
      "train loss:6.55574042952e-05\n",
      "train loss:0.00237853787795\n",
      "train loss:0.00235270565804\n",
      "train loss:0.000319255216982\n",
      "train loss:0.000831382234579\n",
      "train loss:0.00211084220517\n",
      "train loss:0.000224383931549\n",
      "train loss:9.72711092577e-05\n",
      "train loss:0.000433745425645\n",
      "train loss:0.00344287677116\n",
      "train loss:0.00335776520504\n",
      "train loss:0.000535256750375\n",
      "train loss:0.000911028681922\n",
      "train loss:0.000148439735732\n",
      "train loss:0.00449025879864\n",
      "train loss:0.000339576459666\n",
      "train loss:0.000263809165853\n",
      "train loss:0.000456194541532\n",
      "train loss:0.000606846248332\n",
      "train loss:0.000501770963146\n",
      "train loss:0.000943374227221\n",
      "train loss:0.00175341456947\n",
      "train loss:0.000338168904369\n",
      "train loss:0.000191417723121\n",
      "train loss:0.0010142211944\n",
      "train loss:4.36227940105e-05\n",
      "train loss:0.000196911208596\n",
      "train loss:0.00322007378069\n",
      "train loss:0.00124095917802\n",
      "train loss:0.00164856969753\n",
      "train loss:0.00868155571909\n",
      "train loss:0.00110873163098\n",
      "train loss:0.00031591370382\n",
      "train loss:0.000647008410241\n",
      "train loss:0.00129997853556\n",
      "train loss:0.000431980169181\n",
      "train loss:0.00052376663314\n",
      "train loss:0.00011800142981\n",
      "train loss:0.000656866761845\n",
      "train loss:0.00230252626459\n",
      "train loss:0.00133396279486\n",
      "train loss:0.00199455735183\n",
      "train loss:0.00132803901916\n",
      "train loss:0.000120763120138\n",
      "train loss:0.00038581360618\n",
      "train loss:0.00148818245367\n",
      "train loss:0.00146565263752\n",
      "train loss:0.00109551397612\n",
      "train loss:0.00823537033557\n",
      "train loss:0.000196001165608\n",
      "train loss:0.00119262198201\n",
      "train loss:5.15440888718e-05\n",
      "train loss:0.000463772104766\n",
      "train loss:0.000162003680831\n",
      "train loss:0.000399516818695\n",
      "train loss:0.000836423702084\n",
      "train loss:0.000682999080053\n",
      "train loss:0.000349101588681\n",
      "train loss:0.000113479197831\n",
      "train loss:0.00181466605881\n",
      "train loss:0.0010237799741\n",
      "train loss:0.0038039996005\n",
      "train loss:0.000406384108497\n",
      "train loss:0.00227874964989\n",
      "train loss:0.000895257645012\n",
      "train loss:0.000709741642237\n",
      "train loss:6.55382442553e-06\n",
      "train loss:0.00488869811232\n",
      "train loss:0.000768633126122\n",
      "train loss:0.000661564397997\n",
      "train loss:1.8138453857e-05\n",
      "train loss:0.000256361640147\n",
      "train loss:0.000616406386161\n",
      "train loss:7.2161136005e-05\n",
      "train loss:0.00011122042142\n",
      "train loss:2.76227714076e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00118237534405\n",
      "train loss:0.00179820848922\n",
      "train loss:0.000219514728722\n",
      "train loss:0.00154347527129\n",
      "train loss:0.000408225364674\n",
      "train loss:0.001284522046\n",
      "train loss:0.00025290443384\n",
      "train loss:0.000885851987164\n",
      "train loss:0.000916455921058\n",
      "train loss:0.000275449039003\n",
      "train loss:0.000427225707669\n",
      "train loss:0.0018156130133\n",
      "train loss:0.00070125083104\n",
      "train loss:0.000634859966673\n",
      "train loss:0.000161130938379\n",
      "train loss:0.000753157585712\n",
      "train loss:0.00197264372829\n",
      "train loss:0.000462764193419\n",
      "train loss:0.000318639744695\n",
      "train loss:0.00754885571359\n",
      "train loss:0.000350916327953\n",
      "train loss:0.000222108342907\n",
      "train loss:0.000335284386852\n",
      "train loss:0.00187479924374\n",
      "train loss:0.000938134615661\n",
      "train loss:0.000935846135186\n",
      "train loss:0.000104563179947\n",
      "train loss:0.00143196887373\n",
      "train loss:0.000234406530671\n",
      "train loss:0.000410860294807\n",
      "train loss:0.000127105982799\n",
      "train loss:0.00170178979547\n",
      "train loss:0.00111493213734\n",
      "train loss:0.00105809548924\n",
      "train loss:0.000167257975289\n",
      "train loss:0.00100437539287\n",
      "train loss:0.000974678675537\n",
      "train loss:7.47209654636e-05\n",
      "train loss:0.00123713043801\n",
      "train loss:0.000933002491668\n",
      "train loss:0.00341651963963\n",
      "train loss:0.00113858922729\n",
      "train loss:0.000418950583466\n",
      "train loss:0.0011161167337\n",
      "train loss:0.000561579294082\n",
      "train loss:0.000274242762201\n",
      "train loss:0.00185595730388\n",
      "train loss:0.000261932512603\n",
      "train loss:0.00165678689057\n",
      "train loss:0.000686442398513\n",
      "train loss:0.000499168523969\n",
      "train loss:0.00132851885139\n",
      "train loss:0.000325500764596\n",
      "train loss:0.000413178323873\n",
      "train loss:0.00101220762663\n",
      "train loss:0.000477391646677\n",
      "train loss:0.00172394837024\n",
      "train loss:4.89768728913e-05\n",
      "train loss:0.00333473087123\n",
      "train loss:0.000405239805141\n",
      "train loss:0.00119923568947\n",
      "train loss:0.0169779263423\n",
      "train loss:0.000462353279035\n",
      "train loss:0.00100609552802\n",
      "train loss:0.00102037890726\n",
      "train loss:0.00154960813026\n",
      "train loss:0.000632016195165\n",
      "train loss:8.28701191631e-05\n",
      "train loss:0.000726036595089\n",
      "train loss:0.000667959802037\n",
      "train loss:0.000532162506281\n",
      "train loss:0.000223185852326\n",
      "train loss:4.58544548198e-05\n",
      "train loss:0.000630806715895\n",
      "train loss:0.000631371456715\n",
      "train loss:4.57563738051e-05\n",
      "train loss:0.000168740992917\n",
      "train loss:0.000476444105475\n",
      "train loss:0.04602341715\n",
      "train loss:6.14482786826e-05\n",
      "train loss:0.00160436718563\n",
      "train loss:0.00175814727367\n",
      "train loss:0.00126509159485\n",
      "train loss:0.00152801988843\n",
      "train loss:0.000296047684292\n",
      "train loss:0.000491634815861\n",
      "train loss:0.00120175192655\n",
      "train loss:0.00657446735248\n",
      "train loss:0.00178444792969\n",
      "train loss:0.00405288771231\n",
      "train loss:0.000971571334841\n",
      "train loss:0.0008079261519\n",
      "train loss:9.72463581169e-05\n",
      "train loss:0.000386033120053\n",
      "train loss:0.00108880109779\n",
      "train loss:0.000198273231747\n",
      "train loss:0.00250437171485\n",
      "train loss:0.00205440428203\n",
      "train loss:0.00193424494362\n",
      "train loss:0.00012016692855\n",
      "train loss:0.0013489372865\n",
      "train loss:0.00016432962445\n",
      "train loss:0.000950534388362\n",
      "train loss:0.000138874534122\n",
      "train loss:0.00275544419229\n",
      "train loss:0.000137364578786\n",
      "train loss:0.00264844600252\n",
      "train loss:0.00126041313615\n",
      "train loss:0.000357414929624\n",
      "train loss:0.000311156483075\n",
      "train loss:0.000704776680873\n",
      "train loss:0.000217699807655\n",
      "train loss:0.000183247758246\n",
      "train loss:9.92945820035e-05\n",
      "train loss:3.4428189873e-05\n",
      "train loss:0.029620444243\n",
      "train loss:5.0819279235e-05\n",
      "train loss:0.00246953787055\n",
      "train loss:0.000526673452829\n",
      "train loss:0.000439249086029\n",
      "train loss:0.000152167581541\n",
      "train loss:9.34825567399e-05\n",
      "train loss:0.000126446429625\n",
      "train loss:0.00223006964502\n",
      "train loss:0.000128358572993\n",
      "train loss:0.00333839761662\n",
      "train loss:0.000895440050467\n",
      "train loss:0.000266153394998\n",
      "train loss:0.00023761433557\n",
      "train loss:0.00222954241117\n",
      "train loss:0.000514740309564\n",
      "train loss:0.00170032957741\n",
      "train loss:0.000461563334997\n",
      "train loss:0.00306120392551\n",
      "train loss:0.00113703608297\n",
      "train loss:0.00411779753456\n",
      "train loss:0.000571874592698\n",
      "train loss:0.00199632976209\n",
      "train loss:0.00267778108984\n",
      "train loss:0.00110187959261\n",
      "train loss:0.000722968274364\n",
      "train loss:0.00192049677875\n",
      "train loss:0.000840799336594\n",
      "train loss:0.000153326552044\n",
      "train loss:0.00315707619872\n",
      "train loss:0.000315856570791\n",
      "train loss:5.35216226495e-06\n",
      "train loss:0.000259131356883\n",
      "train loss:0.00104651832874\n",
      "train loss:0.000270812280141\n",
      "train loss:0.000431699303142\n",
      "train loss:0.000570752527044\n",
      "train loss:1.63083341028e-05\n",
      "train loss:0.000137098014575\n",
      "train loss:1.48085300812e-05\n",
      "train loss:0.000903275597195\n",
      "train loss:0.00101344180801\n",
      "train loss:0.00229063326274\n",
      "train loss:0.00150480756487\n",
      "train loss:0.00143952114621\n",
      "train loss:0.000300492292952\n",
      "train loss:0.000407079630297\n",
      "train loss:0.000412272949988\n",
      "train loss:2.64726670109e-05\n",
      "train loss:6.63735370583e-05\n",
      "train loss:5.11596581871e-05\n",
      "train loss:0.00141698133636\n",
      "train loss:0.00190454914422\n",
      "train loss:0.000923483935315\n",
      "train loss:0.0003756315733\n",
      "train loss:0.000866698346916\n",
      "train loss:0.000118522581318\n",
      "train loss:0.000308889261261\n",
      "train loss:0.000673625207167\n",
      "train loss:7.17340050889e-05\n",
      "train loss:0.0013667189792\n",
      "train loss:0.000736625542753\n",
      "train loss:1.82584335048e-05\n",
      "train loss:0.00152513175441\n",
      "train loss:7.22867326539e-05\n",
      "train loss:0.000107654789464\n",
      "train loss:0.000710886734042\n",
      "train loss:0.000116963558551\n",
      "train loss:0.00122126125679\n",
      "train loss:3.64801768193e-05\n",
      "train loss:8.38139134518e-05\n",
      "train loss:0.00236160673118\n",
      "train loss:0.000417041497771\n",
      "train loss:0.000122051180374\n",
      "train loss:0.000499783703437\n",
      "train loss:0.0150216116429\n",
      "train loss:3.25524842318e-05\n",
      "train loss:0.000709643619398\n",
      "train loss:0.000451680700239\n",
      "train loss:0.00209933560632\n",
      "train loss:0.000223921502461\n",
      "train loss:0.000395817545035\n",
      "train loss:0.000452465697036\n",
      "train loss:0.000545502549852\n",
      "train loss:0.000164614554609\n",
      "train loss:0.000449696137982\n",
      "train loss:0.00394969687826\n",
      "train loss:0.000659017021112\n",
      "train loss:0.00139586236241\n",
      "train loss:0.000339346732098\n",
      "train loss:0.000727826346296\n",
      "train loss:0.000181629645647\n",
      "train loss:0.000645350328808\n",
      "train loss:0.000848685102758\n",
      "train loss:0.000103502818094\n",
      "train loss:0.0010697801053\n",
      "train loss:0.000976162157133\n",
      "train loss:4.16975934824e-05\n",
      "train loss:5.28477186521e-05\n",
      "train loss:0.000307619000777\n",
      "train loss:4.23629482538e-05\n",
      "train loss:0.000639647495941\n",
      "train loss:0.00118227999132\n",
      "train loss:0.000735498141947\n",
      "train loss:0.000470124174239\n",
      "train loss:0.00033348045778\n",
      "train loss:0.00229409972734\n",
      "train loss:5.83368294198e-05\n",
      "train loss:9.57820332908e-05\n",
      "train loss:3.70911250122e-05\n",
      "train loss:0.00105774612874\n",
      "train loss:0.000193661542238\n",
      "train loss:0.000927060738256\n",
      "train loss:0.000558354527946\n",
      "train loss:0.000182455533108\n",
      "train loss:0.00258592972338\n",
      "train loss:0.00026023451695\n",
      "train loss:0.00455815559643\n",
      "train loss:0.00239058863367\n",
      "train loss:0.0003662273452\n",
      "train loss:0.000184347030513\n",
      "train loss:0.00100857656261\n",
      "train loss:0.000235218348815\n",
      "train loss:0.000618978730251\n",
      "train loss:0.00018153276444\n",
      "train loss:0.000413139219043\n",
      "train loss:0.000741253537308\n",
      "train loss:0.00159611206303\n",
      "train loss:4.61608651294e-05\n",
      "train loss:5.5525813338e-05\n",
      "train loss:0.000407572068587\n",
      "train loss:0.000195194487295\n",
      "train loss:0.00126370488191\n",
      "train loss:0.00130257175773\n",
      "train loss:0.000167098291295\n",
      "train loss:1.19069519738e-05\n",
      "train loss:0.000339397985626\n",
      "train loss:0.000177630131078\n",
      "train loss:0.000277065531391\n",
      "train loss:0.000326597578874\n",
      "train loss:0.000113752162045\n",
      "train loss:0.00231326450762\n",
      "train loss:3.3313881527e-05\n",
      "train loss:0.00160662849351\n",
      "train loss:0.00130746637691\n",
      "train loss:0.000734447741211\n",
      "train loss:3.25957072732e-05\n",
      "train loss:0.00112271943907\n",
      "train loss:0.000189719992134\n",
      "train loss:5.93228521653e-05\n",
      "train loss:0.00034524216293\n",
      "train loss:3.08080085802e-05\n",
      "train loss:0.00114003601923\n",
      "train loss:0.000281644337873\n",
      "train loss:0.000172393899531\n",
      "train loss:0.000184298784526\n",
      "train loss:0.00012444193061\n",
      "train loss:0.000102459712583\n",
      "train loss:0.000177919880495\n",
      "train loss:0.000151582644742\n",
      "train loss:0.000441617834272\n",
      "train loss:0.0021273391229\n",
      "train loss:0.000719614118809\n",
      "train loss:0.00061725404382\n",
      "train loss:0.000403548321836\n",
      "train loss:0.000297246719236\n",
      "train loss:0.000635182014274\n",
      "train loss:0.000399865600767\n",
      "train loss:6.77842932916e-05\n",
      "train loss:0.000780596054128\n",
      "train loss:7.12748224206e-05\n",
      "train loss:0.00169790534827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00032444402115\n",
      "train loss:0.00039917257158\n",
      "train loss:9.00094930121e-05\n",
      "train loss:0.000176407796219\n",
      "train loss:3.93503323211e-05\n",
      "train loss:2.39788600425e-05\n",
      "train loss:0.000344140604103\n",
      "train loss:0.000141057801505\n",
      "train loss:0.00157777645423\n",
      "train loss:0.000341365886163\n",
      "train loss:5.62960016895e-05\n",
      "train loss:0.00350661352034\n",
      "train loss:0.000134653230308\n",
      "train loss:0.0168917614527\n",
      "train loss:0.000157859167075\n",
      "train loss:4.48985074049e-05\n",
      "train loss:0.00140038228683\n",
      "train loss:0.000549843615304\n",
      "train loss:0.000564913083633\n",
      "train loss:0.000130916028126\n",
      "train loss:0.00247693605984\n",
      "train loss:2.91063813326e-05\n",
      "train loss:0.00127704312512\n",
      "train loss:0.000107134894115\n",
      "train loss:0.0014623288064\n",
      "train loss:6.62887776408e-05\n",
      "train loss:0.000896289153005\n",
      "train loss:9.09436672302e-05\n",
      "train loss:0.00078266418559\n",
      "train loss:0.00251381857152\n",
      "train loss:7.22971174604e-05\n",
      "train loss:0.00287358039284\n",
      "train loss:0.00145744620928\n",
      "train loss:0.00193203778583\n",
      "train loss:0.000390326183707\n",
      "train loss:9.69691739495e-05\n",
      "train loss:0.000600014362675\n",
      "train loss:0.000532081926708\n",
      "train loss:0.000135734870532\n",
      "train loss:0.00124344545247\n",
      "train loss:0.00102255380083\n",
      "train loss:0.00136761511163\n",
      "train loss:0.000263780632794\n",
      "train loss:0.00180566793147\n",
      "train loss:2.66227186314e-05\n",
      "train loss:0.00277947634353\n",
      "train loss:0.000564147141354\n",
      "train loss:0.00105117803771\n",
      "train loss:0.000289028983103\n",
      "train loss:0.00032757418754\n",
      "train loss:0.000948133337375\n",
      "train loss:3.82198578132e-05\n",
      "train loss:4.18194697988e-05\n",
      "train loss:0.000732083688675\n",
      "train loss:0.000796151710328\n",
      "train loss:0.000196136766582\n",
      "train loss:0.00115765665197\n",
      "train loss:7.43705277776e-05\n",
      "train loss:0.000155632689062\n",
      "train loss:0.000882992980463\n",
      "train loss:0.00148269572093\n",
      "train loss:6.34718534611e-05\n",
      "train loss:0.000436603073916\n",
      "train loss:4.83903781116e-05\n",
      "train loss:3.4979432791e-05\n",
      "train loss:0.000450125579336\n",
      "train loss:0.00113547148093\n",
      "train loss:0.00335723516889\n",
      "train loss:1.72795821291e-05\n",
      "train loss:0.000931438241713\n",
      "train loss:0.000391324105671\n",
      "train loss:0.000100196012175\n",
      "train loss:0.000620950209308\n",
      "train loss:5.85424834613e-05\n",
      "train loss:0.0018423993039\n",
      "train loss:0.000458150926589\n",
      "train loss:0.000569262840671\n",
      "train loss:0.000867321856935\n",
      "train loss:3.34359025782e-05\n",
      "train loss:0.00038555595748\n",
      "train loss:0.000451866701513\n",
      "train loss:0.00026215528208\n",
      "train loss:0.000527249348202\n",
      "train loss:0.000331847958261\n",
      "train loss:0.000171008794618\n",
      "train loss:8.57428349404e-05\n",
      "train loss:0.000739409920361\n",
      "train loss:0.000275716799207\n",
      "train loss:0.000210941076481\n",
      "train loss:8.82672807914e-05\n",
      "train loss:0.000799644503405\n",
      "train loss:0.000217064446113\n",
      "train loss:0.00132490308862\n",
      "train loss:0.000485555037319\n",
      "train loss:0.000913977550522\n",
      "train loss:0.000162740751453\n",
      "train loss:0.00013206495558\n",
      "train loss:1.3809895745e-05\n",
      "train loss:0.000325389835613\n",
      "train loss:0.000145383451275\n",
      "train loss:0.00110714254728\n",
      "train loss:0.000384770118328\n",
      "train loss:0.000233883620197\n",
      "train loss:0.000155261852635\n",
      "train loss:0.002979271315\n",
      "train loss:0.000340621868433\n",
      "train loss:0.00023270428927\n",
      "train loss:9.90421778023e-05\n",
      "train loss:0.000520385121371\n",
      "train loss:0.000131288780235\n",
      "train loss:0.000636123384466\n",
      "train loss:0.000179535709837\n",
      "train loss:0.000161855128532\n",
      "train loss:0.000621062686845\n",
      "train loss:4.60355244728e-05\n",
      "train loss:0.000253103294441\n",
      "train loss:0.000574438197428\n",
      "=== epoch:20, train acc:0.997, test acc:0.99 ===\n",
      "train loss:0.000219235878563\n",
      "train loss:0.000122463247435\n",
      "train loss:0.000172100040577\n",
      "train loss:2.27931568741e-05\n",
      "train loss:0.000137657549777\n",
      "train loss:0.00134241099005\n",
      "train loss:0.00112691134963\n",
      "train loss:0.0011911014264\n",
      "train loss:0.000901927083622\n",
      "train loss:0.00207814609787\n",
      "train loss:0.0020609465215\n",
      "train loss:6.62532622583e-05\n",
      "train loss:0.000875206618864\n",
      "train loss:0.00020763948746\n",
      "train loss:0.000217518580011\n",
      "train loss:9.90377687987e-05\n",
      "train loss:0.000390439241153\n",
      "train loss:0.00116970896518\n",
      "train loss:0.000260356333711\n",
      "train loss:0.000415908954654\n",
      "train loss:0.00292023863444\n",
      "train loss:0.000185907457067\n",
      "train loss:3.17613226081e-05\n",
      "train loss:0.00113963449843\n",
      "train loss:0.000327960140234\n",
      "train loss:0.00145114817669\n",
      "train loss:0.000997195262002\n",
      "train loss:0.00366416761547\n",
      "train loss:0.00320863987223\n",
      "train loss:0.000598378072361\n",
      "train loss:0.000847270427426\n",
      "train loss:9.86662868426e-05\n",
      "train loss:0.00113874566049\n",
      "train loss:0.000631701068185\n",
      "train loss:0.00015435584559\n",
      "train loss:0.00095233229086\n",
      "train loss:0.00576172516952\n",
      "train loss:4.59876887584e-05\n",
      "train loss:2.59955509385e-05\n",
      "train loss:0.00536871302773\n",
      "train loss:0.00113305908559\n",
      "train loss:0.000128821782957\n",
      "train loss:0.000178513020835\n",
      "train loss:0.00180666358153\n",
      "train loss:0.00214564726461\n",
      "train loss:0.000713918511773\n",
      "train loss:0.00015640387784\n",
      "train loss:0.000800009749089\n",
      "train loss:0.000450478453969\n",
      "train loss:0.000300585933115\n",
      "train loss:0.0017008097646\n",
      "train loss:0.000176312907091\n",
      "train loss:0.000327739988351\n",
      "train loss:0.00860593328619\n",
      "train loss:0.000152928671156\n",
      "train loss:0.000165294758756\n",
      "train loss:0.000631480991057\n",
      "train loss:0.000933531930974\n",
      "train loss:0.00124221502536\n",
      "train loss:0.0015065982248\n",
      "train loss:0.000384119632434\n",
      "train loss:0.0012205926877\n",
      "train loss:2.1024625779e-05\n",
      "train loss:0.000934499782501\n",
      "train loss:0.00467546585891\n",
      "train loss:0.00125524317187\n",
      "train loss:0.000935220450597\n",
      "train loss:0.00569388457294\n",
      "train loss:0.00016663315996\n",
      "train loss:0.000310886272351\n",
      "train loss:0.00048332749589\n",
      "train loss:0.00189751816026\n",
      "train loss:0.000164734145408\n",
      "train loss:0.00123440266024\n",
      "train loss:3.46659133158e-05\n",
      "train loss:0.000204518545499\n",
      "train loss:0.00169537898116\n",
      "train loss:7.07870453719e-05\n",
      "train loss:0.000365038240279\n",
      "train loss:0.00310090861101\n",
      "train loss:0.000437248541542\n",
      "train loss:0.00248398603129\n",
      "train loss:0.00443903893688\n",
      "train loss:0.00173032209513\n",
      "train loss:0.00315304379879\n",
      "train loss:0.0012216514433\n",
      "train loss:0.00147285922778\n",
      "train loss:0.00144797759343\n",
      "train loss:0.00634056575494\n",
      "train loss:0.000436018664303\n",
      "train loss:0.00217379649935\n",
      "train loss:2.825189422e-05\n",
      "train loss:0.000547500906785\n",
      "train loss:0.00829551978897\n",
      "train loss:5.02205198702e-05\n",
      "train loss:3.74158874895e-06\n",
      "train loss:0.00112047669367\n",
      "train loss:0.00150794606021\n",
      "train loss:0.000510732142172\n",
      "train loss:0.00534832130191\n",
      "train loss:0.000423692318773\n",
      "train loss:0.000825815051082\n",
      "train loss:0.000406738457724\n",
      "train loss:0.00764372927251\n",
      "train loss:0.000860864150457\n",
      "train loss:0.00336159205138\n",
      "train loss:0.000183511304196\n",
      "train loss:0.0103181712024\n",
      "train loss:0.00390958172057\n",
      "train loss:0.000285439568461\n",
      "train loss:0.000398697865811\n",
      "train loss:0.00101542642058\n",
      "train loss:0.00182189853825\n",
      "train loss:0.000779131805796\n",
      "train loss:0.0029778348659\n",
      "train loss:0.000171501212526\n",
      "train loss:0.00979861091875\n",
      "train loss:0.000556864703122\n",
      "train loss:0.000391394132956\n",
      "train loss:0.000588531463938\n",
      "train loss:0.0011174314851\n",
      "train loss:0.00353357042562\n",
      "train loss:2.15332838037e-05\n",
      "train loss:0.00182169878261\n",
      "train loss:6.64247140927e-05\n",
      "train loss:0.00635103617214\n",
      "train loss:0.000382188406802\n",
      "train loss:0.000415159609007\n",
      "train loss:0.00224980492288\n",
      "train loss:0.000151336725186\n",
      "train loss:0.00527370238469\n",
      "train loss:0.000510997142698\n",
      "train loss:0.000342807073013\n",
      "train loss:0.000131919863007\n",
      "train loss:0.00020889867393\n",
      "train loss:0.00133869406522\n",
      "train loss:0.000205457289991\n",
      "train loss:8.2140198011e-05\n",
      "train loss:0.00147723815574\n",
      "train loss:0.00199750667202\n",
      "train loss:0.000140655309996\n",
      "train loss:0.000967728864879\n",
      "train loss:0.000860539302183\n",
      "train loss:0.000577621499589\n",
      "train loss:1.08746495636e-05\n",
      "train loss:0.00175848811578\n",
      "train loss:0.00035358389823\n",
      "train loss:6.52184641311e-05\n",
      "train loss:0.00105932777716\n",
      "train loss:0.000696067048756\n",
      "train loss:0.00146179568843\n",
      "train loss:0.000643873738457\n",
      "train loss:0.000540345025931\n",
      "train loss:0.000257312942673\n",
      "train loss:4.52958501934e-05\n",
      "train loss:0.000505145615019\n",
      "train loss:0.00218799026611\n",
      "train loss:3.05145173641e-05\n",
      "train loss:0.000227427351024\n",
      "train loss:0.00333659154314\n",
      "train loss:0.000823529561163\n",
      "train loss:1.97332378384e-05\n",
      "train loss:1.84914888877e-05\n",
      "train loss:0.000309898362826\n",
      "train loss:0.000301276211917\n",
      "train loss:0.000331874570817\n",
      "train loss:0.00124209833342\n",
      "train loss:0.000540953779009\n",
      "train loss:0.000196394145258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00104954610938\n",
      "train loss:0.000962013583343\n",
      "train loss:0.00011781831123\n",
      "train loss:0.000704795870065\n",
      "train loss:0.000187830017116\n",
      "train loss:0.00139124297614\n",
      "train loss:0.00166885283962\n",
      "train loss:0.00028949445259\n",
      "train loss:0.000625621742159\n",
      "train loss:0.000656199868001\n",
      "train loss:0.000878621332404\n",
      "train loss:2.41078337233e-05\n",
      "train loss:0.0002512193818\n",
      "train loss:0.000767346841529\n",
      "train loss:6.54541807484e-05\n",
      "train loss:0.000192662554003\n",
      "train loss:0.0101387412083\n",
      "train loss:0.00168032385243\n",
      "train loss:0.000206877625612\n",
      "train loss:0.00120936454511\n",
      "train loss:0.00163073484386\n",
      "train loss:0.000647735595949\n",
      "train loss:0.00219685967407\n",
      "train loss:0.000131133815066\n",
      "train loss:0.000177479407475\n",
      "train loss:0.00159582342387\n",
      "train loss:0.00544929248439\n",
      "train loss:0.000656678462528\n",
      "train loss:0.000703677780215\n",
      "train loss:0.000225485921524\n",
      "train loss:0.000258263236204\n",
      "train loss:0.000312809154024\n",
      "train loss:0.000572793667405\n",
      "train loss:0.0038347668082\n",
      "train loss:0.00194641532632\n",
      "train loss:0.00141362034464\n",
      "train loss:0.00162115230092\n",
      "train loss:0.000273807685047\n",
      "train loss:0.00149148101022\n",
      "train loss:0.000349237404482\n",
      "train loss:4.48906160368e-05\n",
      "train loss:0.00587567734304\n",
      "train loss:0.000955575627142\n",
      "train loss:0.00088888915266\n",
      "train loss:0.00319443468871\n",
      "train loss:0.000387608844825\n",
      "train loss:0.000537363035974\n",
      "train loss:0.000478481613266\n",
      "train loss:0.000281467292737\n",
      "train loss:0.00287463199567\n",
      "train loss:0.00158312458162\n",
      "train loss:0.00050992976644\n",
      "train loss:0.00243937368447\n",
      "train loss:0.000295486182926\n",
      "train loss:0.00221317590056\n",
      "train loss:0.00116050528467\n",
      "train loss:0.000482581941598\n",
      "train loss:0.000122665396415\n",
      "train loss:0.00085917500463\n",
      "train loss:0.000777044330908\n",
      "train loss:0.000680950965608\n",
      "train loss:0.000145425621924\n",
      "train loss:4.83868915524e-05\n",
      "train loss:4.83206158806e-05\n",
      "train loss:0.00313288449087\n",
      "train loss:0.000124932215138\n",
      "train loss:0.000197957952821\n",
      "train loss:0.00361551550197\n",
      "train loss:0.00162287146555\n",
      "train loss:0.00120869278748\n",
      "train loss:0.00234775017646\n",
      "train loss:6.72307601602e-05\n",
      "train loss:0.0011863612005\n",
      "train loss:0.000268762704383\n",
      "train loss:0.00116241670565\n",
      "train loss:0.00105942411496\n",
      "train loss:0.00126184691459\n",
      "train loss:0.00251515949437\n",
      "train loss:0.000343365081539\n",
      "train loss:0.000109892142859\n",
      "train loss:9.01704651515e-05\n",
      "train loss:0.00111002724908\n",
      "train loss:0.00317651653299\n",
      "train loss:0.000171518188505\n",
      "train loss:0.000377717472208\n",
      "train loss:0.000328215656081\n",
      "train loss:0.00935115704319\n",
      "train loss:0.000235830311277\n",
      "train loss:0.00156884962241\n",
      "train loss:0.000449826490931\n",
      "train loss:0.000176192725547\n",
      "train loss:3.20979158436e-05\n",
      "train loss:0.00976762154062\n",
      "train loss:0.000188404397729\n",
      "train loss:0.000614174357313\n",
      "train loss:0.000613468681269\n",
      "train loss:0.000660576233627\n",
      "train loss:0.00228519382688\n",
      "train loss:4.09622404634e-05\n",
      "train loss:9.74295901048e-05\n",
      "train loss:0.000203526896645\n",
      "train loss:0.000907053033809\n",
      "train loss:0.000706181680085\n",
      "train loss:3.51467562293e-05\n",
      "train loss:0.00176809484214\n",
      "train loss:0.00389357408216\n",
      "train loss:0.000790464737873\n",
      "train loss:0.00203991650393\n",
      "train loss:0.000199296761362\n",
      "train loss:0.000878594035028\n",
      "train loss:0.00179755489817\n",
      "train loss:0.00167397362427\n",
      "train loss:0.0016226297826\n",
      "train loss:0.00315280586688\n",
      "train loss:0.00165220426903\n",
      "train loss:4.73209373022e-05\n",
      "train loss:0.00123974045732\n",
      "train loss:0.00177716853916\n",
      "train loss:0.00160797386303\n",
      "train loss:0.000351053609793\n",
      "train loss:0.000719687882812\n",
      "train loss:9.69533863661e-05\n",
      "train loss:0.00122236523756\n",
      "train loss:0.000910602293961\n",
      "train loss:0.000818853390488\n",
      "train loss:0.000186162366631\n",
      "train loss:0.00161881791553\n",
      "train loss:4.87174649369e-05\n",
      "train loss:0.00152042968539\n",
      "train loss:0.000521395492336\n",
      "train loss:0.000518001476809\n",
      "train loss:0.00077746367218\n",
      "train loss:0.000187903619564\n",
      "train loss:0.000318624690184\n",
      "train loss:0.000334557846295\n",
      "train loss:0.000206065075864\n",
      "train loss:0.0008440862133\n",
      "train loss:0.00276243350623\n",
      "train loss:0.000448565020743\n",
      "train loss:0.00260048680186\n",
      "train loss:0.00121689100769\n",
      "train loss:3.65823302269e-05\n",
      "train loss:0.000537639227574\n",
      "train loss:6.15368260675e-05\n",
      "train loss:0.000741448920351\n",
      "train loss:0.00066132764711\n",
      "train loss:0.000284099312548\n",
      "train loss:0.0027422646669\n",
      "train loss:0.0015558247918\n",
      "train loss:0.00147266067999\n",
      "train loss:0.000823813575681\n",
      "train loss:9.62269420528e-05\n",
      "train loss:0.00287539383385\n",
      "train loss:0.0013102563341\n",
      "train loss:0.000392072338594\n",
      "train loss:0.000857223298515\n",
      "train loss:0.000779392907809\n",
      "train loss:9.59418556093e-05\n",
      "train loss:0.000195148764819\n",
      "train loss:0.0014742913234\n",
      "train loss:0.001551511447\n",
      "train loss:0.00371433294663\n",
      "train loss:0.00153136993145\n",
      "train loss:3.60378063965e-05\n",
      "train loss:0.00016306491646\n",
      "train loss:0.000348016913361\n",
      "train loss:0.00117784811009\n",
      "train loss:0.000459356124879\n",
      "train loss:0.00212379092295\n",
      "train loss:0.000434912156544\n",
      "train loss:0.000120277587577\n",
      "train loss:0.000808569006235\n",
      "train loss:5.75888192625e-05\n",
      "train loss:0.000220652631795\n",
      "train loss:0.0031481387103\n",
      "train loss:0.000858143161029\n",
      "train loss:0.000995089897309\n",
      "train loss:0.000631138086967\n",
      "train loss:0.0168331722014\n",
      "train loss:0.00224550312429\n",
      "train loss:0.000515949349799\n",
      "train loss:0.000222129215407\n",
      "train loss:0.00163255256106\n",
      "train loss:0.00198930956162\n",
      "train loss:0.00217759404745\n",
      "train loss:0.00103541695031\n",
      "train loss:0.000180649128645\n",
      "train loss:0.0176926098188\n",
      "train loss:0.00195187638335\n",
      "train loss:8.4546861681e-05\n",
      "train loss:0.00232198316942\n",
      "train loss:0.000178872555114\n",
      "train loss:0.00356178216277\n",
      "train loss:0.00137109680698\n",
      "train loss:0.000103757022063\n",
      "train loss:0.000312923876252\n",
      "train loss:0.000218959284053\n",
      "train loss:0.00116689528041\n",
      "train loss:0.000829232986078\n",
      "train loss:0.000204342634569\n",
      "train loss:0.00242258314047\n",
      "train loss:0.00800020493838\n",
      "train loss:0.0025295580241\n",
      "train loss:0.00116270996089\n",
      "train loss:0.000877345682394\n",
      "train loss:0.000783244481336\n",
      "train loss:0.000259290177204\n",
      "train loss:0.0016319528703\n",
      "train loss:6.95239430666e-05\n",
      "train loss:0.000160212337019\n",
      "train loss:0.012232809151\n",
      "train loss:0.000260996051235\n",
      "train loss:0.00047679648712\n",
      "train loss:0.0361152376165\n",
      "train loss:0.000337759177422\n",
      "train loss:0.000531933294248\n",
      "train loss:0.0069460237965\n",
      "train loss:0.000192936256341\n",
      "train loss:0.000268728278234\n",
      "train loss:0.000505262782353\n",
      "train loss:0.00115157669861\n",
      "train loss:0.0089832757502\n",
      "train loss:0.0011627914093\n",
      "train loss:0.000264051560822\n",
      "train loss:0.000585753089939\n",
      "train loss:0.000789327863459\n",
      "train loss:0.000496547116165\n",
      "train loss:0.000850495132592\n",
      "train loss:0.000217041307746\n",
      "train loss:0.000498676846676\n",
      "train loss:0.000272158297286\n",
      "train loss:0.00146954376939\n",
      "train loss:0.000443585847024\n",
      "train loss:0.000886209556904\n",
      "train loss:0.000141181098319\n",
      "train loss:0.00347513470925\n",
      "train loss:0.00223302863016\n",
      "train loss:0.00010964815936\n",
      "train loss:0.00670100661828\n",
      "train loss:0.00160936879835\n",
      "train loss:0.000290324138155\n",
      "train loss:8.43969928271e-05\n",
      "train loss:0.000679571583813\n",
      "train loss:0.000980836506516\n",
      "train loss:0.00123329772424\n",
      "train loss:2.67143050711e-05\n",
      "train loss:0.000345091093251\n",
      "train loss:0.00523643517633\n",
      "train loss:0.000754426004007\n",
      "train loss:0.001479031922\n",
      "train loss:0.00128267659402\n",
      "train loss:0.000885399320199\n",
      "train loss:0.00114178257887\n",
      "train loss:0.00282035382681\n",
      "train loss:0.000624176543814\n",
      "train loss:0.00497663701688\n",
      "train loss:0.00196509932915\n",
      "train loss:0.0322881918388\n",
      "train loss:0.00263916028161\n",
      "train loss:0.00184059758103\n",
      "train loss:0.00210540099421\n",
      "train loss:5.95234655825e-05\n",
      "train loss:0.00173840699242\n",
      "train loss:0.000719684421921\n",
      "train loss:0.000143261912848\n",
      "train loss:0.000826117909062\n",
      "train loss:0.000669906859076\n",
      "train loss:0.00224647515213\n",
      "train loss:0.000429536779689\n",
      "train loss:0.00234373584365\n",
      "train loss:0.000250840873085\n",
      "train loss:0.000590242833208\n",
      "train loss:0.000256298148968\n",
      "train loss:0.00196575137317\n",
      "train loss:0.00385702499439\n",
      "train loss:0.000175844906813\n",
      "train loss:0.000928951660036\n",
      "train loss:0.0100347198657\n",
      "train loss:0.00136325306442\n",
      "train loss:0.00108818518901\n",
      "train loss:0.000543655193642\n",
      "train loss:0.00316859054759\n",
      "train loss:0.0188660553828\n",
      "train loss:0.000299819368635\n",
      "train loss:0.00016548253053\n",
      "train loss:0.00179348512367\n",
      "train loss:0.00316312579076\n",
      "train loss:0.000117062420373\n",
      "train loss:9.13621298577e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00322627278975\n",
      "train loss:0.00427173647605\n",
      "train loss:0.0016301572154\n",
      "train loss:0.00263067730433\n",
      "train loss:0.00180392893688\n",
      "train loss:0.00634917113086\n",
      "train loss:0.00210980443773\n",
      "train loss:0.000145572123199\n",
      "train loss:0.00043281347683\n",
      "train loss:0.000113676967743\n",
      "train loss:0.00169860532701\n",
      "train loss:0.00256155781045\n",
      "train loss:0.00144756139733\n",
      "train loss:0.00156085292139\n",
      "train loss:0.000137412349809\n",
      "train loss:0.00221326451939\n",
      "train loss:0.000386493066362\n",
      "train loss:0.00202140722827\n",
      "train loss:0.00117975757413\n",
      "train loss:0.0257336773163\n",
      "train loss:0.00796402377978\n",
      "train loss:0.0138739768622\n",
      "train loss:0.00113373036675\n",
      "train loss:8.21858845435e-05\n",
      "train loss:0.00161098757962\n",
      "train loss:0.00103522776915\n",
      "train loss:0.0215332108293\n",
      "train loss:0.00330312787815\n",
      "train loss:0.00189095008409\n",
      "train loss:0.000725124961602\n",
      "train loss:0.00381723935335\n",
      "train loss:0.000864480563566\n",
      "train loss:0.000169998174129\n",
      "train loss:0.00382144501747\n",
      "train loss:0.0364954336082\n",
      "train loss:0.000695044715376\n",
      "train loss:1.38667888942e-05\n",
      "train loss:0.00570714275062\n",
      "train loss:0.0011406343271\n",
      "train loss:0.0033077364719\n",
      "train loss:3.00957262298e-05\n",
      "train loss:0.001327233055\n",
      "train loss:0.0049468112729\n",
      "train loss:0.0014674791219\n",
      "train loss:0.000155211633017\n",
      "train loss:0.000217778001872\n",
      "train loss:0.000350544635324\n",
      "train loss:0.0023288360801\n",
      "train loss:0.000463172740503\n",
      "train loss:0.00153897212809\n",
      "train loss:0.000439570002209\n",
      "train loss:0.000850171141814\n",
      "train loss:0.00180514100837\n",
      "train loss:0.0319193075254\n",
      "train loss:8.60498323163e-05\n",
      "train loss:0.0043511273458\n",
      "train loss:0.0030014099575\n",
      "train loss:0.000580609545054\n",
      "train loss:0.00413382967637\n",
      "train loss:0.00175017758336\n",
      "train loss:0.00526308489001\n",
      "train loss:0.00164590664801\n",
      "train loss:0.000376709759134\n",
      "train loss:0.000618321566745\n",
      "train loss:0.00260755559417\n",
      "train loss:0.000667634372693\n",
      "train loss:0.000265934847559\n",
      "train loss:0.000131676369822\n",
      "train loss:0.00325560996164\n",
      "train loss:0.000297887300626\n",
      "train loss:0.00718664017392\n",
      "train loss:0.00175205067975\n",
      "train loss:0.000310871844276\n",
      "train loss:0.0004703915828\n",
      "train loss:6.64596875611e-05\n",
      "train loss:0.000401771002293\n",
      "train loss:0.00156524317819\n",
      "train loss:0.000402164037409\n",
      "train loss:0.000213712913322\n",
      "train loss:0.00270206513666\n",
      "train loss:0.000640271821427\n",
      "train loss:0.000833503325223\n",
      "train loss:0.000481934751946\n",
      "train loss:0.000262890634093\n",
      "train loss:7.50348703679e-05\n",
      "train loss:0.00125082452096\n",
      "train loss:0.00020617080264\n",
      "train loss:0.000847340577714\n",
      "train loss:0.0108278863803\n",
      "train loss:0.000669683214943\n",
      "train loss:0.000997133124077\n",
      "train loss:0.000291246209895\n",
      "train loss:0.00200726404028\n",
      "train loss:3.77351079872e-05\n",
      "train loss:0.000134876864759\n",
      "train loss:0.000655701131711\n",
      "train loss:0.00509767085542\n",
      "train loss:0.000638461983119\n",
      "train loss:0.00483824424188\n",
      "train loss:0.000395913688063\n",
      "train loss:0.0013387440592\n",
      "train loss:0.000147280802795\n",
      "train loss:0.00132710252706\n",
      "train loss:0.000379258867158\n",
      "train loss:0.00326162935466\n",
      "train loss:0.00236606052999\n",
      "train loss:5.67987612149e-05\n",
      "train loss:8.13921334339e-05\n",
      "train loss:0.000145409269249\n",
      "train loss:0.000112775591911\n",
      "train loss:0.00112645833275\n",
      "train loss:0.00178423164036\n",
      "train loss:0.00073373743872\n",
      "train loss:0.00354704380398\n",
      "train loss:0.00104135432539\n",
      "train loss:0.000796841465911\n",
      "train loss:0.00109563110457\n",
      "train loss:0.000339720030134\n",
      "train loss:5.18402082689e-05\n",
      "train loss:0.000440994253936\n",
      "train loss:0.00128345172421\n",
      "train loss:0.00105003262107\n",
      "train loss:0.000397076976038\n",
      "train loss:0.000150743042181\n",
      "train loss:0.00100074487248\n",
      "train loss:0.000205529724111\n",
      "train loss:0.000485277594303\n",
      "train loss:0.00273905700535\n",
      "train loss:0.000129925920882\n",
      "train loss:0.00759919329708\n",
      "train loss:7.06852151798e-05\n",
      "train loss:0.000104875621081\n",
      "train loss:0.000170092228763\n",
      "train loss:0.00457604800495\n",
      "train loss:0.000759768247008\n",
      "train loss:0.00201445697775\n",
      "train loss:0.000518069483219\n",
      "train loss:0.00152560437133\n",
      "train loss:0.00250437261441\n",
      "train loss:0.0116343717029\n",
      "train loss:0.000592221913366\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.989\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZe5XA6NyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5cb3400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load train_convnet.py\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 读入数据\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 处理花费时间较长的情况下减少数据 \n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 保存参数\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 绘制图形\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right') #显示图例\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 3.81513748478e-08\n",
      "b1 1.43780165313e-06\n",
      "W2 3.67238892518e-11\n",
      "b2 3.11152520819e-09\n",
      "W3 1.34977702247e-10\n",
      "b3 1.79909564323e-07\n"
     ]
    }
   ],
   "source": [
    "# %load gradient_check.py\n",
    "import numpy as np\n",
    "from simple_convnet import SimpleConvNet\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,10, 10), \n",
    "                        conv_param = {'filter_num':10, 'filter_size':3, 'pad':0, 'stride':1},\n",
    "                        hidden_size=10, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "X = np.random.rand(100).reshape((1, 1, 10, 10))\n",
    "T = np.array([1]).reshape((1,1))\n",
    "\n",
    "grad_num = network.numerical_gradient(X, T)\n",
    "grad = network.gradient(X, T)\n",
    "\n",
    "for key, val in grad_num.items():\n",
    "    print(key, np.abs(grad_num[key] - grad[key]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAE1CAYAAAClaOSUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5c250b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAADuCAYAAABf005JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5c25dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load apply_filter.py\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from simple_convnet import SimpleConvNet\n",
    "from matplotlib.image import imread\n",
    "from common.layers import Convolution\n",
    "\n",
    "def filter_show(filters, nx=4, show_num=16):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(show_num / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(show_num):\n",
    "        ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "# 学习后的权重\n",
    "network.load_params(\"params.pkl\")\n",
    "\n",
    "filter_show(network.params['W1'], 16)\n",
    "\n",
    "img = imread('../dataset/lena_gray.png')\n",
    "img = img.reshape(1, 1, *img.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "w_idx = 1\n",
    "\n",
    "for i in range(16):\n",
    "    w = network.params['W1'][i]\n",
    "    b = 0  # network.params['b1'][i]\n",
    "\n",
    "    w = w.reshape(1, *w.shape)\n",
    "    #b = b.reshape(1, *b.shape)\n",
    "    conv_layer = Convolution(w, b) \n",
    "    out = conv_layer.forward(img)\n",
    "    out = out.reshape(out.shape[2], out.shape[3])\n",
    "    \n",
    "    ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(out, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAEjCAYAAABD3BobAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUIoAADiUIgAADqUIAIBDKQIA4PwXvBIZboxTjb4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x94cacf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAEjCAYAAABD3BobAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x59ae630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load visualize_filter.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "#第一层卷积层的权重形状（30,1,5,5）\n",
    "network = SimpleConvNet()\n",
    "# 随机进行初始化后的权重\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 学习后的权重\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
